{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network imports\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt('voice-emotion-database.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.          0.          0.          7.244975   -8.158391   -6.804606\n",
      "   -5.95105    16.04601     4.259685    2.918404    3.899431   -8.787468\n",
      "    2.029931   -9.035371   -1.614401   -9.214661    0.          5.\n",
      "    1.          4.       ]\n",
      " [  1.          0.          0.          3.385026    9.644617   -3.468472\n",
      "    6.205656   13.31692     4.477325   -3.002632  -21.12964    -4.892778\n",
      "  -11.55352     6.817298    5.058506  -30.31255     0.          5.\n",
      "    1.          4.       ]\n",
      " [  2.          0.          0.          5.719598    5.727946    6.571836\n",
      "   19.76121    17.95665    12.09366    -0.2149866  -4.745448   -3.547788\n",
      "   -9.468735   -1.699346   -1.552975  -29.19722     0.          5.\n",
      "    1.          1.       ]]\n",
      "(1066, 20)\n"
     ]
    }
   ],
   "source": [
    "# See dataset details\n",
    "print(dataset[:3])\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.244975   -8.158391   -6.804606   -5.95105    16.04601     4.259685\n",
      "    2.918404    3.899431   -8.787468    2.029931   -9.035371   -1.614401\n",
      "   -9.214661 ]\n",
      " [  3.385026    9.644617   -3.468472    6.205656   13.31692     4.477325\n",
      "   -3.002632  -21.12964    -4.892778  -11.55352     6.817298    5.058506\n",
      "  -30.31255  ]\n",
      " [  5.719598    5.727946    6.571836   19.76121    17.95665    12.09366\n",
      "   -0.2149866  -4.745448   -3.547788   -9.468735   -1.699346   -1.552975\n",
      "  -29.19722  ]]\n",
      "(1066, 13)\n",
      "[4. 4. 1.]\n",
      "(1066,)\n"
     ]
    }
   ],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,3:16] # Only the MFCC features\n",
    "y = dataset[:,19] # Emotion label\n",
    "\n",
    "# See X and y details\n",
    "print(X[:3])\n",
    "print(X.shape)\n",
    "\n",
    "print(y[:3])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "[[ 10.86021    -0.1504712  -7.050648  -13.34398    -3.762597  -10.07538\n",
      "   -4.320255    0.8074002   1.662185   -3.852825  -13.26163     3.004174\n",
      "  -23.76107  ]\n",
      " [-20.17031     7.688166   -6.902145   15.45029     9.552048   -1.200928\n",
      "   13.72213    -2.49684    11.76603    -6.941161    1.724953    6.110147\n",
      "  -21.93117  ]\n",
      " [ -2.741963   -5.573832    1.295266    6.534232    8.063975    7.205008\n",
      "   10.84907     2.744319    2.135926   -0.7263327   7.643946    3.96128\n",
      "  -10.77666  ]]\n",
      "(746, 13)\n",
      "\n",
      "X_test:\n",
      "\n",
      "[[ 6.632766e+00  6.211563e+00  6.034946e+00  3.301121e+01 -2.390878e+00\n",
      "   8.948273e+00 -7.841763e+00 -7.805614e+00 -3.095579e+00  4.398633e+00\n",
      "  -1.238064e+00 -1.834961e+01 -4.059555e+00]\n",
      " [-2.587318e-01 -5.702300e+00  7.713166e+00  1.141300e+01  6.923450e+00\n",
      "   9.285526e+00  1.123824e+01  1.753032e+00  8.851054e+00  2.128385e+00\n",
      "   2.319431e-02 -2.441559e+00 -1.552758e+01]\n",
      " [ 1.152659e+00  2.549862e+00 -4.846608e+00  2.665312e+00 -1.144581e-01\n",
      "   2.994903e+00  1.578110e+00  3.419013e+00  2.142924e+01 -7.646084e+00\n",
      "  -6.290819e+00  3.350859e+00 -2.529436e+01]]\n",
      "(320, 13)\n",
      "\n",
      "y_train:\n",
      "\n",
      "[3. 4. 6.]\n",
      "(746,)\n",
      "\n",
      "y_test:\n",
      "\n",
      "[0. 3. 6.]\n",
      "(320,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # to split dataset into train and test\n",
    "\n",
    "# Split the dataset in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3)\n",
    "\n",
    "# See Details\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train[:3])\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(X_test[:3])\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"\\ny_train:\\n\")\n",
    "print(y_train[:3])\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\ny_test:\\n\")\n",
    "print(y_test[:3])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_train:\n",
      "\n",
      "[[0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1]]\n",
      "(746, 7)\n",
      "\n",
      "y_test:\n",
      "\n",
      "[[1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1]]\n",
      "(320, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Binarize labels\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.fit_transform(y_test)\n",
    "\n",
    "# See Details\n",
    "print(\"\\ny_train:\\n\")\n",
    "print(y_train[:3])\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\ny_test:\\n\")\n",
    "print(y_test[:3])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, activation='relu')) #input_dim = number of features. Hidden layer has 50, 20. Output layer has 7 (because of binarize)\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(7, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bath and epochs\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 746 samples, validate on 320 samples\n",
      "Epoch 1/100\n",
      "746/746 [==============================] - 0s 377us/step - loss: 1.1036 - accuracy: 0.6771 - val_loss: 0.9278 - val_accuracy: 0.6871\n",
      "Epoch 2/100\n",
      "746/746 [==============================] - 0s 60us/step - loss: 0.8592 - accuracy: 0.7129 - val_loss: 0.7486 - val_accuracy: 0.7286\n",
      "Epoch 3/100\n",
      "746/746 [==============================] - 0s 48us/step - loss: 0.7288 - accuracy: 0.7384 - val_loss: 0.6564 - val_accuracy: 0.7487\n",
      "Epoch 4/100\n",
      "746/746 [==============================] - 0s 61us/step - loss: 0.6525 - accuracy: 0.7556 - val_loss: 0.6051 - val_accuracy: 0.7692\n",
      "Epoch 5/100\n",
      "746/746 [==============================] - 0s 63us/step - loss: 0.6046 - accuracy: 0.7717 - val_loss: 0.5686 - val_accuracy: 0.7777\n",
      "Epoch 6/100\n",
      "746/746 [==============================] - 0s 61us/step - loss: 0.5674 - accuracy: 0.7832 - val_loss: 0.5415 - val_accuracy: 0.7866\n",
      "Epoch 7/100\n",
      "746/746 [==============================] - 0s 67us/step - loss: 0.5402 - accuracy: 0.7945 - val_loss: 0.5211 - val_accuracy: 0.7996\n",
      "Epoch 8/100\n",
      "746/746 [==============================] - 0s 61us/step - loss: 0.5183 - accuracy: 0.7999 - val_loss: 0.5059 - val_accuracy: 0.8062\n",
      "Epoch 9/100\n",
      "746/746 [==============================] - 0s 56us/step - loss: 0.5013 - accuracy: 0.8119 - val_loss: 0.4937 - val_accuracy: 0.8134\n",
      "Epoch 10/100\n",
      "746/746 [==============================] - 0s 69us/step - loss: 0.4870 - accuracy: 0.8209 - val_loss: 0.4834 - val_accuracy: 0.8219\n",
      "Epoch 11/100\n",
      "746/746 [==============================] - 0s 66us/step - loss: 0.4755 - accuracy: 0.8257 - val_loss: 0.4758 - val_accuracy: 0.8286\n",
      "Epoch 12/100\n",
      "746/746 [==============================] - 0s 38us/step - loss: 0.4667 - accuracy: 0.8324 - val_loss: 0.4703 - val_accuracy: 0.8277\n",
      "Epoch 13/100\n",
      "746/746 [==============================] - 0s 63us/step - loss: 0.4591 - accuracy: 0.8351 - val_loss: 0.4657 - val_accuracy: 0.8313\n",
      "Epoch 14/100\n",
      "746/746 [==============================] - 0s 54us/step - loss: 0.4529 - accuracy: 0.8388 - val_loss: 0.4605 - val_accuracy: 0.8362\n",
      "Epoch 15/100\n",
      "746/746 [==============================] - 0s 53us/step - loss: 0.4472 - accuracy: 0.8416 - val_loss: 0.4574 - val_accuracy: 0.8366\n",
      "Epoch 16/100\n",
      "746/746 [==============================] - 0s 65us/step - loss: 0.4427 - accuracy: 0.8443 - val_loss: 0.4543 - val_accuracy: 0.8366\n",
      "Epoch 17/100\n",
      "746/746 [==============================] - 0s 65us/step - loss: 0.4377 - accuracy: 0.8455 - val_loss: 0.4522 - val_accuracy: 0.8411\n",
      "Epoch 18/100\n",
      "746/746 [==============================] - 0s 56us/step - loss: 0.4334 - accuracy: 0.8474 - val_loss: 0.4497 - val_accuracy: 0.8438\n",
      "Epoch 19/100\n",
      "746/746 [==============================] - 0s 67us/step - loss: 0.4297 - accuracy: 0.8487 - val_loss: 0.4473 - val_accuracy: 0.8446\n",
      "Epoch 20/100\n",
      "746/746 [==============================] - 0s 54us/step - loss: 0.4262 - accuracy: 0.8504 - val_loss: 0.4453 - val_accuracy: 0.8433\n",
      "Epoch 21/100\n",
      "746/746 [==============================] - 0s 53us/step - loss: 0.4233 - accuracy: 0.8506 - val_loss: 0.4440 - val_accuracy: 0.8455\n",
      "Epoch 22/100\n",
      "746/746 [==============================] - 0s 55us/step - loss: 0.4205 - accuracy: 0.8520 - val_loss: 0.4424 - val_accuracy: 0.8455\n",
      "Epoch 23/100\n",
      "746/746 [==============================] - 0s 62us/step - loss: 0.4176 - accuracy: 0.8533 - val_loss: 0.4410 - val_accuracy: 0.8460\n",
      "Epoch 24/100\n",
      "746/746 [==============================] - 0s 49us/step - loss: 0.4156 - accuracy: 0.8527 - val_loss: 0.4402 - val_accuracy: 0.8473\n",
      "Epoch 25/100\n",
      "746/746 [==============================] - 0s 58us/step - loss: 0.4134 - accuracy: 0.8531 - val_loss: 0.4393 - val_accuracy: 0.8473\n",
      "Epoch 26/100\n",
      "746/746 [==============================] - 0s 57us/step - loss: 0.4110 - accuracy: 0.8537 - val_loss: 0.4378 - val_accuracy: 0.8469\n",
      "Epoch 27/100\n",
      "746/746 [==============================] - 0s 51us/step - loss: 0.4089 - accuracy: 0.8545 - val_loss: 0.4372 - val_accuracy: 0.8478\n",
      "Epoch 28/100\n",
      "746/746 [==============================] - 0s 68us/step - loss: 0.4073 - accuracy: 0.8550 - val_loss: 0.4364 - val_accuracy: 0.8478\n",
      "Epoch 29/100\n",
      "746/746 [==============================] - 0s 58us/step - loss: 0.4058 - accuracy: 0.8547 - val_loss: 0.4359 - val_accuracy: 0.8491\n",
      "Epoch 30/100\n",
      "746/746 [==============================] - 0s 68us/step - loss: 0.4038 - accuracy: 0.8547 - val_loss: 0.4353 - val_accuracy: 0.8491\n",
      "Epoch 31/100\n",
      "746/746 [==============================] - 0s 57us/step - loss: 0.4021 - accuracy: 0.8554 - val_loss: 0.4345 - val_accuracy: 0.8500\n",
      "Epoch 32/100\n",
      "746/746 [==============================] - 0s 58us/step - loss: 0.4005 - accuracy: 0.8550 - val_loss: 0.4344 - val_accuracy: 0.8504\n",
      "Epoch 33/100\n",
      "746/746 [==============================] - 0s 49us/step - loss: 0.3992 - accuracy: 0.8556 - val_loss: 0.4340 - val_accuracy: 0.8504\n",
      "Epoch 34/100\n",
      "746/746 [==============================] - 0s 51us/step - loss: 0.3978 - accuracy: 0.8554 - val_loss: 0.4335 - val_accuracy: 0.8509\n",
      "Epoch 35/100\n",
      "746/746 [==============================] - 0s 50us/step - loss: 0.3966 - accuracy: 0.8556 - val_loss: 0.4330 - val_accuracy: 0.8500\n",
      "Epoch 36/100\n",
      "746/746 [==============================] - 0s 56us/step - loss: 0.3953 - accuracy: 0.8556 - val_loss: 0.4332 - val_accuracy: 0.8496\n",
      "Epoch 37/100\n",
      "746/746 [==============================] - 0s 61us/step - loss: 0.3945 - accuracy: 0.8556 - val_loss: 0.4323 - val_accuracy: 0.8504\n",
      "Epoch 38/100\n",
      "746/746 [==============================] - 0s 42us/step - loss: 0.3931 - accuracy: 0.8552 - val_loss: 0.4320 - val_accuracy: 0.8513\n",
      "Epoch 39/100\n",
      "746/746 [==============================] - 0s 43us/step - loss: 0.3926 - accuracy: 0.8554 - val_loss: 0.4309 - val_accuracy: 0.8522\n",
      "Epoch 40/100\n",
      "746/746 [==============================] - 0s 61us/step - loss: 0.3919 - accuracy: 0.8558 - val_loss: 0.4315 - val_accuracy: 0.8504\n",
      "Epoch 41/100\n",
      "746/746 [==============================] - 0s 40us/step - loss: 0.3899 - accuracy: 0.8554 - val_loss: 0.4305 - val_accuracy: 0.8509\n",
      "Epoch 42/100\n",
      "746/746 [==============================] - 0s 55us/step - loss: 0.3887 - accuracy: 0.8560 - val_loss: 0.4301 - val_accuracy: 0.8513\n",
      "Epoch 43/100\n",
      "746/746 [==============================] - 0s 32us/step - loss: 0.3878 - accuracy: 0.8560 - val_loss: 0.4301 - val_accuracy: 0.8518\n",
      "Epoch 44/100\n",
      "746/746 [==============================] - 0s 48us/step - loss: 0.3865 - accuracy: 0.8560 - val_loss: 0.4298 - val_accuracy: 0.8509\n",
      "Epoch 45/100\n",
      "746/746 [==============================] - 0s 43us/step - loss: 0.3855 - accuracy: 0.8560 - val_loss: 0.4300 - val_accuracy: 0.8518\n",
      "Epoch 46/100\n",
      "746/746 [==============================] - 0s 58us/step - loss: 0.3849 - accuracy: 0.8558 - val_loss: 0.4300 - val_accuracy: 0.8513\n",
      "Epoch 47/100\n",
      "746/746 [==============================] - 0s 44us/step - loss: 0.3838 - accuracy: 0.8566 - val_loss: 0.4301 - val_accuracy: 0.8509\n",
      "Epoch 48/100\n",
      "746/746 [==============================] - 0s 53us/step - loss: 0.3828 - accuracy: 0.8564 - val_loss: 0.4301 - val_accuracy: 0.8513\n",
      "Epoch 49/100\n",
      "746/746 [==============================] - 0s 35us/step - loss: 0.3818 - accuracy: 0.8566 - val_loss: 0.4300 - val_accuracy: 0.8513\n",
      "Epoch 50/100\n",
      "746/746 [==============================] - 0s 39us/step - loss: 0.3813 - accuracy: 0.8571 - val_loss: 0.4297 - val_accuracy: 0.8513\n",
      "Epoch 51/100\n",
      "746/746 [==============================] - 0s 42us/step - loss: 0.3813 - accuracy: 0.8571 - val_loss: 0.4296 - val_accuracy: 0.8509\n",
      "Epoch 52/100\n",
      "746/746 [==============================] - 0s 70us/step - loss: 0.3796 - accuracy: 0.8575 - val_loss: 0.4298 - val_accuracy: 0.8509\n",
      "Epoch 53/100\n",
      "746/746 [==============================] - 0s 63us/step - loss: 0.3785 - accuracy: 0.8570 - val_loss: 0.4302 - val_accuracy: 0.8504\n",
      "Epoch 54/100\n",
      "746/746 [==============================] - 0s 62us/step - loss: 0.3778 - accuracy: 0.8570 - val_loss: 0.4298 - val_accuracy: 0.8522\n",
      "Epoch 55/100\n",
      "746/746 [==============================] - 0s 65us/step - loss: 0.3769 - accuracy: 0.8581 - val_loss: 0.4298 - val_accuracy: 0.8518\n",
      "Epoch 56/100\n",
      "746/746 [==============================] - 0s 67us/step - loss: 0.3761 - accuracy: 0.8573 - val_loss: 0.4301 - val_accuracy: 0.8513\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 0s 48us/step - loss: 0.3759 - accuracy: 0.8577 - val_loss: 0.4296 - val_accuracy: 0.8509\n",
      "Epoch 58/100\n",
      "746/746 [==============================] - 0s 45us/step - loss: 0.3748 - accuracy: 0.8577 - val_loss: 0.4297 - val_accuracy: 0.8509\n",
      "Epoch 59/100\n",
      "746/746 [==============================] - 0s 55us/step - loss: 0.3739 - accuracy: 0.8585 - val_loss: 0.4297 - val_accuracy: 0.8513\n",
      "Epoch 60/100\n",
      "746/746 [==============================] - 0s 49us/step - loss: 0.3735 - accuracy: 0.8577 - val_loss: 0.4297 - val_accuracy: 0.8513\n",
      "Epoch 61/100\n",
      "746/746 [==============================] - 0s 36us/step - loss: 0.3727 - accuracy: 0.8583 - val_loss: 0.4298 - val_accuracy: 0.8518\n",
      "Epoch 62/100\n",
      "746/746 [==============================] - 0s 53us/step - loss: 0.3717 - accuracy: 0.8577 - val_loss: 0.4298 - val_accuracy: 0.8513\n",
      "Epoch 63/100\n",
      "746/746 [==============================] - 0s 41us/step - loss: 0.3708 - accuracy: 0.8581 - val_loss: 0.4295 - val_accuracy: 0.8509\n",
      "Epoch 64/100\n",
      "746/746 [==============================] - 0s 44us/step - loss: 0.3700 - accuracy: 0.8579 - val_loss: 0.4301 - val_accuracy: 0.8509\n",
      "Epoch 65/100\n",
      "746/746 [==============================] - 0s 42us/step - loss: 0.3697 - accuracy: 0.8583 - val_loss: 0.4297 - val_accuracy: 0.8509\n",
      "Epoch 66/100\n",
      "746/746 [==============================] - 0s 45us/step - loss: 0.3697 - accuracy: 0.8585 - val_loss: 0.4297 - val_accuracy: 0.8509\n",
      "Epoch 67/100\n",
      "746/746 [==============================] - 0s 57us/step - loss: 0.3687 - accuracy: 0.8589 - val_loss: 0.4298 - val_accuracy: 0.8513\n",
      "Epoch 68/100\n",
      "746/746 [==============================] - 0s 40us/step - loss: 0.3673 - accuracy: 0.8587 - val_loss: 0.4294 - val_accuracy: 0.8509\n",
      "Epoch 69/100\n",
      "746/746 [==============================] - 0s 46us/step - loss: 0.3671 - accuracy: 0.8585 - val_loss: 0.4299 - val_accuracy: 0.8500\n",
      "Epoch 70/100\n",
      "746/746 [==============================] - 0s 53us/step - loss: 0.3664 - accuracy: 0.8591 - val_loss: 0.4298 - val_accuracy: 0.8504\n",
      "Epoch 71/100\n",
      "746/746 [==============================] - 0s 49us/step - loss: 0.3658 - accuracy: 0.8591 - val_loss: 0.4299 - val_accuracy: 0.8496\n",
      "Epoch 72/100\n",
      "746/746 [==============================] - 0s 63us/step - loss: 0.3645 - accuracy: 0.8596 - val_loss: 0.4299 - val_accuracy: 0.8491\n",
      "Epoch 73/100\n",
      "746/746 [==============================] - 0s 80us/step - loss: 0.3638 - accuracy: 0.8596 - val_loss: 0.4300 - val_accuracy: 0.8491\n",
      "Epoch 74/100\n",
      "746/746 [==============================] - 0s 68us/step - loss: 0.3630 - accuracy: 0.8598 - val_loss: 0.4297 - val_accuracy: 0.8473\n",
      "Epoch 75/100\n",
      "746/746 [==============================] - 0s 46us/step - loss: 0.3627 - accuracy: 0.8604 - val_loss: 0.4297 - val_accuracy: 0.8487\n",
      "Epoch 76/100\n",
      "746/746 [==============================] - 0s 46us/step - loss: 0.3621 - accuracy: 0.8587 - val_loss: 0.4300 - val_accuracy: 0.8491\n",
      "Epoch 77/100\n",
      "746/746 [==============================] - 0s 58us/step - loss: 0.3610 - accuracy: 0.8602 - val_loss: 0.4302 - val_accuracy: 0.8482\n",
      "Epoch 78/100\n",
      "746/746 [==============================] - 0s 45us/step - loss: 0.3607 - accuracy: 0.8604 - val_loss: 0.4308 - val_accuracy: 0.8478\n",
      "Epoch 79/100\n",
      "746/746 [==============================] - 0s 49us/step - loss: 0.3606 - accuracy: 0.8610 - val_loss: 0.4308 - val_accuracy: 0.8491\n",
      "Epoch 80/100\n",
      "746/746 [==============================] - 0s 44us/step - loss: 0.3599 - accuracy: 0.8604 - val_loss: 0.4303 - val_accuracy: 0.8473\n",
      "Epoch 81/100\n",
      "746/746 [==============================] - 0s 45us/step - loss: 0.3585 - accuracy: 0.8606 - val_loss: 0.4305 - val_accuracy: 0.8482\n",
      "Epoch 82/100\n",
      "746/746 [==============================] - 0s 63us/step - loss: 0.3581 - accuracy: 0.8602 - val_loss: 0.4306 - val_accuracy: 0.8473\n",
      "Epoch 83/100\n",
      "746/746 [==============================] - 0s 68us/step - loss: 0.3575 - accuracy: 0.8615 - val_loss: 0.4306 - val_accuracy: 0.8491\n",
      "Epoch 84/100\n",
      "746/746 [==============================] - 0s 76us/step - loss: 0.3565 - accuracy: 0.8608 - val_loss: 0.4309 - val_accuracy: 0.8487\n",
      "Epoch 85/100\n",
      "746/746 [==============================] - 0s 62us/step - loss: 0.3560 - accuracy: 0.8612 - val_loss: 0.4307 - val_accuracy: 0.8487\n",
      "Epoch 86/100\n",
      "746/746 [==============================] - 0s 42us/step - loss: 0.3559 - accuracy: 0.8615 - val_loss: 0.4304 - val_accuracy: 0.8482\n",
      "Epoch 87/100\n",
      "746/746 [==============================] - 0s 54us/step - loss: 0.3550 - accuracy: 0.8619 - val_loss: 0.4310 - val_accuracy: 0.8500\n",
      "Epoch 88/100\n",
      "746/746 [==============================] - 0s 49us/step - loss: 0.3541 - accuracy: 0.8621 - val_loss: 0.4305 - val_accuracy: 0.8482\n",
      "Epoch 89/100\n",
      "746/746 [==============================] - 0s 50us/step - loss: 0.3539 - accuracy: 0.8619 - val_loss: 0.4308 - val_accuracy: 0.8491\n",
      "Epoch 90/100\n",
      "746/746 [==============================] - 0s 61us/step - loss: 0.3530 - accuracy: 0.8617 - val_loss: 0.4318 - val_accuracy: 0.8491\n",
      "Epoch 91/100\n",
      "746/746 [==============================] - 0s 59us/step - loss: 0.3522 - accuracy: 0.8619 - val_loss: 0.4325 - val_accuracy: 0.8482\n",
      "Epoch 92/100\n",
      "746/746 [==============================] - 0s 66us/step - loss: 0.3517 - accuracy: 0.8625 - val_loss: 0.4321 - val_accuracy: 0.8496\n",
      "Epoch 93/100\n",
      "746/746 [==============================] - 0s 75us/step - loss: 0.3511 - accuracy: 0.8621 - val_loss: 0.4324 - val_accuracy: 0.8482\n",
      "Epoch 94/100\n",
      "746/746 [==============================] - 0s 64us/step - loss: 0.3509 - accuracy: 0.8623 - val_loss: 0.4332 - val_accuracy: 0.8491\n",
      "Epoch 95/100\n",
      "746/746 [==============================] - 0s 53us/step - loss: 0.3495 - accuracy: 0.8625 - val_loss: 0.4331 - val_accuracy: 0.8473\n",
      "Epoch 96/100\n",
      "746/746 [==============================] - 0s 32us/step - loss: 0.3496 - accuracy: 0.8623 - val_loss: 0.4336 - val_accuracy: 0.8482\n",
      "Epoch 97/100\n",
      "746/746 [==============================] - 0s 71us/step - loss: 0.3488 - accuracy: 0.8621 - val_loss: 0.4340 - val_accuracy: 0.8482\n",
      "Epoch 98/100\n",
      "746/746 [==============================] - 0s 82us/step - loss: 0.3479 - accuracy: 0.8627 - val_loss: 0.4339 - val_accuracy: 0.8491\n",
      "Epoch 99/100\n",
      "746/746 [==============================] - 0s 72us/step - loss: 0.3472 - accuracy: 0.8631 - val_loss: 0.4340 - val_accuracy: 0.8482\n",
      "Epoch 100/100\n",
      "746/746 [==============================] - 0s 66us/step - loss: 0.3469 - accuracy: 0.8627 - val_loss: 0.4344 - val_accuracy: 0.8491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f85a8ffd2e8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 44us/step\n",
      "Test loss: 0.4343851327896118\n",
      "Test accuracy: 0.8491071462631226\n"
     ]
    }
   ],
   "source": [
    "# Score Model\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 30)                420       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 7)                 112       \n",
      "=================================================================\n",
      "Total params: 997\n",
      "Trainable params: 997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
