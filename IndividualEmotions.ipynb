{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import json\n",
    "from modules.dataset_loader import DatasetLoader\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTION_NUMBERS = [0,1,2,3,4,5,6]\n",
    "\n",
    "def add_padding(X,y):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    max_len = len(X[0])\n",
    "    for row in X:\n",
    "        if len(row) > max_len:\n",
    "            max_len = len(row)\n",
    "\n",
    "    X = pad_sequences(X, maxlen=max_len, padding='post', dtype='float64')\n",
    "    return X, y\n",
    "\n",
    "def group_labels_russel(labels):\n",
    "    new_labels = []\n",
    "    for value in labels:\n",
    "        if value == 0:\n",
    "            new_labels.append(0)\n",
    "        if value == 3:\n",
    "            new_labels.append(1)\n",
    "        if  value == 5:\n",
    "            new_labels.append(2)\n",
    "        if value in [1,2,4]:\n",
    "            new_labels.append(3)\n",
    "        if value == 6:\n",
    "            new_labels.append(4)\n",
    "    \n",
    "    return np.asarray(new_labels)\n",
    "\n",
    "\n",
    "def group_labels(labels, ignore_neutral=False):\n",
    "    new_labels = []\n",
    "    for value in labels:\n",
    "        if value in [3,5]:\n",
    "            new_labels.append(1)\n",
    "        else:\n",
    "            if value == 0 and not ignore_neutral:\n",
    "                new_labels.append(3)\n",
    "            else:\n",
    "                new_labels.append(2)\n",
    "    \n",
    "    return np.asarray(new_labels)\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    DATASET_PATH = 'datasets/Original/MFCC/'\n",
    "    dataset_loader = DatasetLoader(DATASET_PATH)\n",
    "    mfcc_features, y = dataset_loader.get_dataset()\n",
    "\n",
    "    DATASET_PATH = 'datasets/Original/Prosody/'\n",
    "    dataset_loader = DatasetLoader(DATASET_PATH)\n",
    "    prosody_features, y = dataset_loader.get_dataset()\n",
    "\n",
    "\n",
    "    new_dataset = []\n",
    "    for index in range(0, len(mfcc_features)):\n",
    "        new_instance = []\n",
    "        for row_index in range(0, len(mfcc_features[index])):\n",
    "            new_row = np.concatenate(\n",
    "                (mfcc_features[index][row_index],\n",
    "                prosody_features[index][row_index]),\n",
    "                axis= None\n",
    "            )\n",
    "            new_instance.append(new_row)\n",
    "        new_dataset.append(new_instance)\n",
    "\n",
    "    X = new_dataset\n",
    "\n",
    "    DATASET_PATH = 'datasets/Original/Chroma/'\n",
    "    dataset_loader = DatasetLoader(DATASET_PATH)\n",
    "    chroma_features, y = dataset_loader.get_dataset()\n",
    "\n",
    "    new_dataset = []\n",
    "    for index in range(0, len(chroma_features)):\n",
    "        new_instance = []\n",
    "        for row_index in range(0, len(chroma_features[index])):\n",
    "            new_row = np.concatenate(\n",
    "                (X[index][row_index],\n",
    "                chroma_features[index][row_index]),\n",
    "                axis= None\n",
    "            )\n",
    "            new_instance.append(new_row)\n",
    "        new_dataset.append(new_instance)\n",
    "\n",
    "    X = np.asarray(new_dataset)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def apply_smote(X, y):\n",
    "    shape_0 = X.shape[0]\n",
    "    shape_1 = X.shape[1]\n",
    "    shape_2 = X.shape[2]\n",
    "    X = X.reshape(shape_0, shape_1 * shape_2)\n",
    "\n",
    "    # Apply SMOTE\n",
    "    smt = SMOTE()\n",
    "    try:\n",
    "        X, y = smt.fit_sample(X, y)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Reshaping back to original shape dimensions 1 and 2\n",
    "    X = X.reshape(X.shape[0], shape_1, shape_2)\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "def wanted_emotion_indexes(wanted_emotion, y_all):\n",
    "    # selection of indexes of desired emotion\n",
    "    indexes = []\n",
    "    for i in range(0,len(y_all)):\n",
    "        if y_all[i][0] == wanted_emotion:\n",
    "            indexes.append(i)\n",
    "    return indexes\n",
    "\n",
    "def binary_emotion_label(wanted_emotion, y_all):\n",
    "    for i in range(0,len(y_all)):\n",
    "        if y_all[i][0] == wanted_emotion:\n",
    "            y_all[i][0] = 1\n",
    "        else:\n",
    "            y_all[i][0] = 0\n",
    "    return y_all\n",
    "\n",
    "def load_mock_dataset():\n",
    "    X = np.array([[0,0],[0,1],[0,2],[0,3],[0,4],[0,5],[0,6],[0,7],[0,8]])\n",
    "    y = [[0,'f1'],[1,'f1'],[2,'f1'],[3,'f1'],[4,'f1'],[5,'f1'],[6,'f1'],[6,'f1'],[2,'f1']]\n",
    "    return X,y\n",
    "\n",
    "def run(wanted_emotion, run_name):\n",
    "    # Load dataset\n",
    "    X_all,y_all = load_dataset()\n",
    "    y_list = []\n",
    "    \n",
    "    # Create list of indexes for each emotion\n",
    "    for emotion in EMOTION_NUMBERS:\n",
    "        current_emotion_indexes = wanted_emotion_indexes(emotion,y_all)\n",
    "        y_list.append(current_emotion_indexes)\n",
    "    \n",
    "    # Create a list of wanted indexes containing all indexes for the desired emotion.\n",
    "    # That number will be the first half of the list, the other half will contain\n",
    "    # A slice of random indexes from the other emotions. This will result in a wanted list\n",
    "    # with half of indexes of the desired emotion and other half with other emotions\n",
    "    indexes_wanted = y_list[wanted_emotion]\n",
    "    half_dataset_number = len(y_list[wanted_emotion])\n",
    "    other_emotions_number = math.ceil(half_dataset_number/(len(EMOTION_NUMBERS)-1))\n",
    "    for emotion in EMOTION_NUMBERS:\n",
    "        if(emotion != wanted_emotion):\n",
    "            indexes_wanted = indexes_wanted + random.sample(y_list[emotion], other_emotions_number)\n",
    "    \n",
    "    # Adjust the labels as being the desired emotion or not\n",
    "    y_all = binary_emotion_label(wanted_emotion, y_all)\n",
    "    \n",
    "    # Create X and y\n",
    "    X = np.take(X_all, indexes_wanted)\n",
    "    y = [inst_y[0] for inst_y in y_all]\n",
    "    y = np.take(y, indexes_wanted)\n",
    "    X = np.asarray(X)\n",
    "    \n",
    "    \n",
    "    X, y = add_padding(X,y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        stratify=y,\n",
    "                                                        test_size=0.3)\n",
    "    \n",
    "    X_test, y_test = apply_smote(X_test, y_test)\n",
    "    X_train, y_train = apply_smote(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_test_labels = y_test\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    num_rows = X[0].shape[0]\n",
    "    num_columns = X[0].shape[1]\n",
    "    num_channels = 1\n",
    "    X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns,num_channels)\n",
    "    X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns,num_channels)\n",
    "\n",
    "    batch_size = 16\n",
    "    epochs = 300\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=128,\n",
    "                    kernel_size=2,\n",
    "                    input_shape=(num_rows, num_columns, num_channels),\n",
    "                    activation='relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=2,\n",
    "                    activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    # Compile the keras model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "        \n",
    "    lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9,\n",
    "                                        patience=20, min_lr=0.000001)\n",
    "    mcp_save = ModelCheckpoint(run_name,\n",
    "                            save_best_only=True, monitor='val_accuracy',\n",
    "                            mode='max')\n",
    "    \n",
    "    result = model.fit(X_train, y_train, batch_size=batch_size,\n",
    "                epochs=epochs, validation_data=(X_test, y_test),\n",
    "                callbacks=[mcp_save, lr_reduce], verbose=1)\n",
    "    \n",
    "    validation_acc = np.amax(result.history['val_accuracy'])\n",
    "    \n",
    "    \n",
    "    model.load_weights(run_name)\n",
    "    \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    info_best_validation_acc = validation_acc\n",
    "\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    predictions_labels = []\n",
    "    for predict in predictions:\n",
    "        predictions_labels.append(predict.tolist().index(np.amax(predict)))\n",
    "\n",
    "    correct = 0\n",
    "    total = len(predictions_labels)\n",
    "    for index in range(0, len(predictions_labels)):\n",
    "        if predictions_labels[index] == y_test_labels[index]:\n",
    "            correct += 1\n",
    "\n",
    "    print(\"average: {}\".format(correct/total))\n",
    "    info_average = correct/total\n",
    "    \n",
    "    return {'run_name': run_name, 'best_validation_acc': info_best_validation_acc, \n",
    "            'average': info_average}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 236 samples, validate on 100 samples\n",
      "Epoch 1/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.7617 - accuracy: 0.4873 - val_loss: 0.7849 - val_accuracy: 0.5000\n",
      "Epoch 2/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.7278 - accuracy: 0.4915 - val_loss: 0.7123 - val_accuracy: 0.5000\n",
      "Epoch 3/300\n",
      "236/236 [==============================] - 13s 55ms/step - loss: 0.7092 - accuracy: 0.5381 - val_loss: 0.7720 - val_accuracy: 0.5000\n",
      "Epoch 4/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.7164 - accuracy: 0.4703 - val_loss: 0.6901 - val_accuracy: 0.5500\n",
      "Epoch 5/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.7089 - accuracy: 0.5000 - val_loss: 0.7056 - val_accuracy: 0.5000\n",
      "Epoch 6/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.7027 - accuracy: 0.4873 - val_loss: 0.7681 - val_accuracy: 0.5000\n",
      "Epoch 7/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.7112 - accuracy: 0.5085 - val_loss: 0.7381 - val_accuracy: 0.5000\n",
      "Epoch 8/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.7056 - accuracy: 0.5000 - val_loss: 0.6916 - val_accuracy: 0.5100\n",
      "Epoch 9/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.7054 - accuracy: 0.5000 - val_loss: 0.7187 - val_accuracy: 0.5000\n",
      "Epoch 10/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.7305 - accuracy: 0.5042 - val_loss: 0.6875 - val_accuracy: 0.4700\n",
      "Epoch 11/300\n",
      "236/236 [==============================] - 13s 53ms/step - loss: 0.6992 - accuracy: 0.5042 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 12/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.6990 - accuracy: 0.4619 - val_loss: 0.6905 - val_accuracy: 0.5400\n",
      "Epoch 13/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.7004 - accuracy: 0.5169 - val_loss: 0.6869 - val_accuracy: 0.5100\n",
      "Epoch 14/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6979 - accuracy: 0.4703 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
      "Epoch 15/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.7005 - accuracy: 0.5339 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 16/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6942 - accuracy: 0.5042 - val_loss: 0.6880 - val_accuracy: 0.5600\n",
      "Epoch 17/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.6955 - accuracy: 0.5000 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
      "Epoch 18/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6913 - accuracy: 0.5000 - val_loss: 0.6865 - val_accuracy: 0.6600\n",
      "Epoch 19/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6964 - accuracy: 0.5000 - val_loss: 0.6852 - val_accuracy: 0.5300\n",
      "Epoch 20/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.6984 - accuracy: 0.5212 - val_loss: 0.6858 - val_accuracy: 0.5600\n",
      "Epoch 21/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.7092 - accuracy: 0.5085 - val_loss: 0.6993 - val_accuracy: 0.5000\n",
      "Epoch 22/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.7009 - accuracy: 0.4873 - val_loss: 0.6873 - val_accuracy: 0.5200\n",
      "Epoch 23/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6948 - accuracy: 0.5042 - val_loss: 0.6951 - val_accuracy: 0.5000\n",
      "Epoch 24/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6923 - accuracy: 0.4915 - val_loss: 0.6889 - val_accuracy: 0.5400\n",
      "Epoch 25/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6923 - accuracy: 0.5339 - val_loss: 0.6881 - val_accuracy: 0.5800\n",
      "Epoch 26/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6938 - accuracy: 0.4576 - val_loss: 0.6862 - val_accuracy: 0.5900\n",
      "Epoch 27/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6955 - accuracy: 0.4958 - val_loss: 0.6894 - val_accuracy: 0.5000\n",
      "Epoch 28/300\n",
      "236/236 [==============================] - 13s 54ms/step - loss: 0.6956 - accuracy: 0.4788 - val_loss: 0.6855 - val_accuracy: 0.6200\n",
      "Epoch 29/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6922 - accuracy: 0.4831 - val_loss: 0.6885 - val_accuracy: 0.5100\n",
      "Epoch 30/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6932 - accuracy: 0.4873 - val_loss: 0.6868 - val_accuracy: 0.5500\n",
      "Epoch 31/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6952 - accuracy: 0.4831 - val_loss: 0.6852 - val_accuracy: 0.6600\n",
      "Epoch 32/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.6894 - accuracy: 0.5339 - val_loss: 0.6870 - val_accuracy: 0.5300\n",
      "Epoch 33/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6897 - accuracy: 0.4873 - val_loss: 0.6859 - val_accuracy: 0.5200\n",
      "Epoch 34/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6900 - accuracy: 0.5254 - val_loss: 0.6837 - val_accuracy: 0.6300\n",
      "Epoch 35/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6926 - accuracy: 0.5381 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 36/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6962 - accuracy: 0.4449 - val_loss: 0.6831 - val_accuracy: 0.6700\n",
      "Epoch 37/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6924 - accuracy: 0.4831 - val_loss: 0.6852 - val_accuracy: 0.6000\n",
      "Epoch 38/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6917 - accuracy: 0.4746 - val_loss: 0.6820 - val_accuracy: 0.5500\n",
      "Epoch 39/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6997 - accuracy: 0.4661 - val_loss: 0.6825 - val_accuracy: 0.5900\n",
      "Epoch 40/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6904 - accuracy: 0.5381 - val_loss: 0.6876 - val_accuracy: 0.5000\n",
      "Epoch 41/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.6959 - accuracy: 0.5000 - val_loss: 0.6853 - val_accuracy: 0.5400\n",
      "Epoch 42/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.7040 - accuracy: 0.5212 - val_loss: 0.6856 - val_accuracy: 0.5100\n",
      "Epoch 43/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6894 - accuracy: 0.5042 - val_loss: 0.6915 - val_accuracy: 0.5300\n",
      "Epoch 44/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6906 - accuracy: 0.5000 - val_loss: 0.6905 - val_accuracy: 0.5600\n",
      "Epoch 45/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6900 - accuracy: 0.5000 - val_loss: 0.6877 - val_accuracy: 0.6800\n",
      "Epoch 46/300\n",
      "236/236 [==============================] - 13s 54ms/step - loss: 0.6909 - accuracy: 0.5720 - val_loss: 0.6851 - val_accuracy: 0.5400\n",
      "Epoch 47/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.6891 - accuracy: 0.5805 - val_loss: 0.6860 - val_accuracy: 0.5600\n",
      "Epoch 48/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6891 - accuracy: 0.5169 - val_loss: 0.6832 - val_accuracy: 0.7100\n",
      "Epoch 49/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6883 - accuracy: 0.5593 - val_loss: 0.6829 - val_accuracy: 0.6600\n",
      "Epoch 50/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6924 - accuracy: 0.5381 - val_loss: 0.6801 - val_accuracy: 0.6600\n",
      "Epoch 51/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6879 - accuracy: 0.5508 - val_loss: 0.6845 - val_accuracy: 0.5100\n",
      "Epoch 52/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6880 - accuracy: 0.5000 - val_loss: 0.6805 - val_accuracy: 0.6800\n",
      "Epoch 53/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6898 - accuracy: 0.5636 - val_loss: 0.6771 - val_accuracy: 0.6000\n",
      "Epoch 54/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6877 - accuracy: 0.5169 - val_loss: 0.6806 - val_accuracy: 0.5600\n",
      "Epoch 55/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6885 - accuracy: 0.5000 - val_loss: 0.6782 - val_accuracy: 0.7300\n",
      "Epoch 56/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6981 - accuracy: 0.4915 - val_loss: 0.6795 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6895 - accuracy: 0.5042 - val_loss: 0.6843 - val_accuracy: 0.5100\n",
      "Epoch 58/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6908 - accuracy: 0.5254 - val_loss: 0.6796 - val_accuracy: 0.6000\n",
      "Epoch 59/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6874 - accuracy: 0.5805 - val_loss: 0.6804 - val_accuracy: 0.6700\n",
      "Epoch 60/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6922 - accuracy: 0.5085 - val_loss: 0.6793 - val_accuracy: 0.7200\n",
      "Epoch 61/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6890 - accuracy: 0.5000 - val_loss: 0.6851 - val_accuracy: 0.5100\n",
      "Epoch 62/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6911 - accuracy: 0.4958 - val_loss: 0.6776 - val_accuracy: 0.5500\n",
      "Epoch 63/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6902 - accuracy: 0.4873 - val_loss: 0.6824 - val_accuracy: 0.5700\n",
      "Epoch 64/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6859 - accuracy: 0.5297 - val_loss: 0.6767 - val_accuracy: 0.6300\n",
      "Epoch 65/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6871 - accuracy: 0.5890 - val_loss: 0.6786 - val_accuracy: 0.6200\n",
      "Epoch 66/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6917 - accuracy: 0.4788 - val_loss: 0.6756 - val_accuracy: 0.7400\n",
      "Epoch 67/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6887 - accuracy: 0.5551 - val_loss: 0.6770 - val_accuracy: 0.5800\n",
      "Epoch 68/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6840 - accuracy: 0.6144 - val_loss: 0.6815 - val_accuracy: 0.6000\n",
      "Epoch 69/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6863 - accuracy: 0.5508 - val_loss: 0.6757 - val_accuracy: 0.6900\n",
      "Epoch 70/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6828 - accuracy: 0.5932 - val_loss: 0.6768 - val_accuracy: 0.5500\n",
      "Epoch 71/300\n",
      "236/236 [==============================] - 13s 54ms/step - loss: 0.6829 - accuracy: 0.5085 - val_loss: 0.6702 - val_accuracy: 0.7200\n",
      "Epoch 72/300\n",
      "236/236 [==============================] - 13s 54ms/step - loss: 0.6833 - accuracy: 0.5466 - val_loss: 0.6678 - val_accuracy: 0.7400\n",
      "Epoch 73/300\n",
      "236/236 [==============================] - 12s 50ms/step - loss: 0.6923 - accuracy: 0.5508 - val_loss: 0.6724 - val_accuracy: 0.6100\n",
      "Epoch 74/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6874 - accuracy: 0.4831 - val_loss: 0.6739 - val_accuracy: 0.6600\n",
      "Epoch 75/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.7014 - accuracy: 0.5169 - val_loss: 0.6749 - val_accuracy: 0.6100\n",
      "Epoch 76/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6841 - accuracy: 0.5847 - val_loss: 0.6836 - val_accuracy: 0.5400\n",
      "Epoch 77/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6859 - accuracy: 0.5424 - val_loss: 0.6746 - val_accuracy: 0.7100\n",
      "Epoch 78/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6833 - accuracy: 0.5805 - val_loss: 0.6743 - val_accuracy: 0.6200\n",
      "Epoch 79/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6865 - accuracy: 0.5339 - val_loss: 0.6703 - val_accuracy: 0.7100\n",
      "Epoch 80/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6818 - accuracy: 0.5551 - val_loss: 0.6721 - val_accuracy: 0.6500\n",
      "Epoch 81/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6809 - accuracy: 0.5636 - val_loss: 0.6669 - val_accuracy: 0.6600\n",
      "Epoch 82/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6811 - accuracy: 0.5254 - val_loss: 0.6655 - val_accuracy: 0.6800\n",
      "Epoch 83/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6790 - accuracy: 0.6017 - val_loss: 0.6623 - val_accuracy: 0.7200\n",
      "Epoch 84/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6758 - accuracy: 0.5975 - val_loss: 0.6637 - val_accuracy: 0.6400\n",
      "Epoch 85/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6808 - accuracy: 0.5975 - val_loss: 0.6626 - val_accuracy: 0.6600\n",
      "Epoch 86/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6798 - accuracy: 0.5636 - val_loss: 0.6590 - val_accuracy: 0.6700\n",
      "Epoch 87/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6762 - accuracy: 0.5932 - val_loss: 0.6583 - val_accuracy: 0.7200\n",
      "Epoch 88/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6849 - accuracy: 0.5297 - val_loss: 0.6597 - val_accuracy: 0.5700\n",
      "Epoch 89/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6849 - accuracy: 0.5763 - val_loss: 0.6624 - val_accuracy: 0.7100\n",
      "Epoch 90/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6786 - accuracy: 0.5763 - val_loss: 0.6617 - val_accuracy: 0.6800\n",
      "Epoch 91/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6787 - accuracy: 0.5720 - val_loss: 0.6607 - val_accuracy: 0.6700\n",
      "Epoch 92/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6730 - accuracy: 0.6271 - val_loss: 0.6561 - val_accuracy: 0.7300\n",
      "Epoch 93/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6812 - accuracy: 0.5508 - val_loss: 0.6647 - val_accuracy: 0.6000\n",
      "Epoch 94/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6760 - accuracy: 0.5339 - val_loss: 0.6528 - val_accuracy: 0.6800\n",
      "Epoch 95/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6747 - accuracy: 0.5720 - val_loss: 0.6524 - val_accuracy: 0.7300\n",
      "Epoch 96/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6751 - accuracy: 0.6102 - val_loss: 0.6495 - val_accuracy: 0.7200\n",
      "Epoch 97/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6697 - accuracy: 0.5847 - val_loss: 0.6487 - val_accuracy: 0.6800\n",
      "Epoch 98/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6736 - accuracy: 0.5763 - val_loss: 0.6509 - val_accuracy: 0.7100\n",
      "Epoch 99/300\n",
      "236/236 [==============================] - 14s 59ms/step - loss: 0.6726 - accuracy: 0.5847 - val_loss: 0.6538 - val_accuracy: 0.6600\n",
      "Epoch 100/300\n",
      "236/236 [==============================] - 14s 58ms/step - loss: 0.6724 - accuracy: 0.5593 - val_loss: 0.6463 - val_accuracy: 0.6600\n",
      "Epoch 101/300\n",
      "236/236 [==============================] - 14s 60ms/step - loss: 0.6667 - accuracy: 0.6102 - val_loss: 0.6520 - val_accuracy: 0.6800\n",
      "Epoch 102/300\n",
      "236/236 [==============================] - 13s 56ms/step - loss: 0.6717 - accuracy: 0.6186 - val_loss: 0.6482 - val_accuracy: 0.6900\n",
      "Epoch 103/300\n",
      "236/236 [==============================] - 13s 56ms/step - loss: 0.6714 - accuracy: 0.5763 - val_loss: 0.6400 - val_accuracy: 0.7400\n",
      "Epoch 104/300\n",
      "236/236 [==============================] - 14s 60ms/step - loss: 0.6704 - accuracy: 0.6017 - val_loss: 0.6457 - val_accuracy: 0.6700\n",
      "Epoch 105/300\n",
      "236/236 [==============================] - 13s 53ms/step - loss: 0.6794 - accuracy: 0.5593 - val_loss: 0.6699 - val_accuracy: 0.5800\n",
      "Epoch 106/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.6880 - accuracy: 0.5466 - val_loss: 0.6638 - val_accuracy: 0.5100\n",
      "Epoch 107/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6889 - accuracy: 0.5169 - val_loss: 0.6563 - val_accuracy: 0.6700\n",
      "Epoch 108/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6787 - accuracy: 0.5508 - val_loss: 0.6617 - val_accuracy: 0.6600\n",
      "Epoch 109/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.6680 - accuracy: 0.6398 - val_loss: 0.6513 - val_accuracy: 0.6800\n",
      "Epoch 110/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6742 - accuracy: 0.6102 - val_loss: 0.6452 - val_accuracy: 0.7400\n",
      "Epoch 111/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6703 - accuracy: 0.6271 - val_loss: 0.6455 - val_accuracy: 0.6900\n",
      "Epoch 112/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.6694 - accuracy: 0.5847 - val_loss: 0.6424 - val_accuracy: 0.7100\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6659 - accuracy: 0.6525 - val_loss: 0.6407 - val_accuracy: 0.7100\n",
      "Epoch 114/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6680 - accuracy: 0.5890 - val_loss: 0.6475 - val_accuracy: 0.6500\n",
      "Epoch 115/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6688 - accuracy: 0.6356 - val_loss: 0.6394 - val_accuracy: 0.6900\n",
      "Epoch 116/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6647 - accuracy: 0.6483 - val_loss: 0.6367 - val_accuracy: 0.6800\n",
      "Epoch 117/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.6673 - accuracy: 0.5847 - val_loss: 0.6315 - val_accuracy: 0.7400\n",
      "Epoch 118/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6636 - accuracy: 0.6017 - val_loss: 0.6353 - val_accuracy: 0.6800\n",
      "Epoch 119/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6580 - accuracy: 0.6398 - val_loss: 0.6306 - val_accuracy: 0.7000\n",
      "Epoch 120/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6696 - accuracy: 0.5593 - val_loss: 0.6309 - val_accuracy: 0.7100\n",
      "Epoch 121/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6746 - accuracy: 0.5975 - val_loss: 0.6335 - val_accuracy: 0.7000\n",
      "Epoch 122/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6577 - accuracy: 0.6059 - val_loss: 0.6285 - val_accuracy: 0.6900\n",
      "Epoch 123/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6718 - accuracy: 0.5508 - val_loss: 0.6310 - val_accuracy: 0.7000\n",
      "Epoch 124/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6597 - accuracy: 0.6441 - val_loss: 0.6279 - val_accuracy: 0.6900\n",
      "Epoch 125/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6511 - accuracy: 0.6483 - val_loss: 0.6457 - val_accuracy: 0.6400\n",
      "Epoch 126/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6606 - accuracy: 0.5720 - val_loss: 0.6287 - val_accuracy: 0.6900\n",
      "Epoch 127/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6753 - accuracy: 0.5805 - val_loss: 0.6439 - val_accuracy: 0.6600\n",
      "Epoch 128/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6704 - accuracy: 0.5678 - val_loss: 0.6328 - val_accuracy: 0.6200\n",
      "Epoch 129/300\n",
      "236/236 [==============================] - 13s 54ms/step - loss: 0.6699 - accuracy: 0.5678 - val_loss: 0.6289 - val_accuracy: 0.7200\n",
      "Epoch 130/300\n",
      "236/236 [==============================] - 15s 62ms/step - loss: 0.6723 - accuracy: 0.5890 - val_loss: 0.6337 - val_accuracy: 0.6800\n",
      "Epoch 131/300\n",
      "236/236 [==============================] - 14s 57ms/step - loss: 0.6657 - accuracy: 0.5847 - val_loss: 0.6273 - val_accuracy: 0.7100\n",
      "Epoch 132/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6712 - accuracy: 0.5932 - val_loss: 0.6342 - val_accuracy: 0.6900\n",
      "Epoch 133/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6693 - accuracy: 0.5551 - val_loss: 0.6298 - val_accuracy: 0.7000\n",
      "Epoch 134/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6734 - accuracy: 0.5805 - val_loss: 0.6336 - val_accuracy: 0.7100\n",
      "Epoch 135/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6622 - accuracy: 0.6144 - val_loss: 0.6334 - val_accuracy: 0.7000\n",
      "Epoch 136/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6608 - accuracy: 0.6059 - val_loss: 0.6259 - val_accuracy: 0.7100\n",
      "Epoch 137/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6683 - accuracy: 0.5381 - val_loss: 0.6287 - val_accuracy: 0.6900\n",
      "Epoch 138/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6651 - accuracy: 0.6144 - val_loss: 0.6305 - val_accuracy: 0.7000\n",
      "Epoch 139/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6596 - accuracy: 0.5847 - val_loss: 0.6237 - val_accuracy: 0.7100\n",
      "Epoch 140/300\n",
      "236/236 [==============================] - 12s 53ms/step - loss: 0.6555 - accuracy: 0.6229 - val_loss: 0.6196 - val_accuracy: 0.7300\n",
      "Epoch 141/300\n",
      "236/236 [==============================] - 13s 56ms/step - loss: 0.6531 - accuracy: 0.6314 - val_loss: 0.6190 - val_accuracy: 0.7100\n",
      "Epoch 142/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6695 - accuracy: 0.5805 - val_loss: 0.6217 - val_accuracy: 0.6900\n",
      "Epoch 143/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6666 - accuracy: 0.5805 - val_loss: 0.6235 - val_accuracy: 0.7000\n",
      "Epoch 144/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6570 - accuracy: 0.6144 - val_loss: 0.6209 - val_accuracy: 0.6900\n",
      "Epoch 145/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6669 - accuracy: 0.5678 - val_loss: 0.6255 - val_accuracy: 0.6300\n",
      "Epoch 146/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6621 - accuracy: 0.6186 - val_loss: 0.6167 - val_accuracy: 0.7000\n",
      "Epoch 147/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6587 - accuracy: 0.6017 - val_loss: 0.6230 - val_accuracy: 0.6900\n",
      "Epoch 148/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6533 - accuracy: 0.6017 - val_loss: 0.6136 - val_accuracy: 0.7200\n",
      "Epoch 149/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6499 - accuracy: 0.6441 - val_loss: 0.6131 - val_accuracy: 0.7100\n",
      "Epoch 150/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6495 - accuracy: 0.6483 - val_loss: 0.6125 - val_accuracy: 0.6900\n",
      "Epoch 151/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6503 - accuracy: 0.6525 - val_loss: 0.6094 - val_accuracy: 0.7100\n",
      "Epoch 152/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6569 - accuracy: 0.6186 - val_loss: 0.6187 - val_accuracy: 0.6900\n",
      "Epoch 153/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6498 - accuracy: 0.6271 - val_loss: 0.6109 - val_accuracy: 0.7000\n",
      "Epoch 154/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6474 - accuracy: 0.6356 - val_loss: 0.6093 - val_accuracy: 0.7100\n",
      "Epoch 155/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6621 - accuracy: 0.5975 - val_loss: 0.6069 - val_accuracy: 0.7100\n",
      "Epoch 156/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6558 - accuracy: 0.6144 - val_loss: 0.6074 - val_accuracy: 0.7100\n",
      "Epoch 157/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6518 - accuracy: 0.6610 - val_loss: 0.6065 - val_accuracy: 0.7200\n",
      "Epoch 158/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6523 - accuracy: 0.6441 - val_loss: 0.6111 - val_accuracy: 0.6900\n",
      "Epoch 159/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6394 - accuracy: 0.6483 - val_loss: 0.6095 - val_accuracy: 0.7000\n",
      "Epoch 160/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6602 - accuracy: 0.6144 - val_loss: 0.6081 - val_accuracy: 0.7000\n",
      "Epoch 161/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6517 - accuracy: 0.6356 - val_loss: 0.6122 - val_accuracy: 0.6900\n",
      "Epoch 162/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6457 - accuracy: 0.6525 - val_loss: 0.6036 - val_accuracy: 0.7100\n",
      "Epoch 163/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6701 - accuracy: 0.5847 - val_loss: 0.6001 - val_accuracy: 0.7100\n",
      "Epoch 164/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6545 - accuracy: 0.5593 - val_loss: 0.6070 - val_accuracy: 0.7100\n",
      "Epoch 165/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6459 - accuracy: 0.6314 - val_loss: 0.6049 - val_accuracy: 0.7000\n",
      "Epoch 166/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6457 - accuracy: 0.6059 - val_loss: 0.6186 - val_accuracy: 0.5800\n",
      "Epoch 167/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6579 - accuracy: 0.6059 - val_loss: 0.6054 - val_accuracy: 0.7100\n",
      "Epoch 168/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6480 - accuracy: 0.6398 - val_loss: 0.6032 - val_accuracy: 0.7100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6425 - accuracy: 0.6102 - val_loss: 0.6070 - val_accuracy: 0.7000\n",
      "Epoch 170/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6509 - accuracy: 0.6144 - val_loss: 0.6061 - val_accuracy: 0.6900\n",
      "Epoch 171/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6463 - accuracy: 0.6059 - val_loss: 0.6044 - val_accuracy: 0.7100\n",
      "Epoch 172/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6365 - accuracy: 0.6653 - val_loss: 0.6059 - val_accuracy: 0.7000\n",
      "Epoch 173/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6613 - accuracy: 0.5593 - val_loss: 0.6000 - val_accuracy: 0.7200\n",
      "Epoch 174/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6514 - accuracy: 0.6314 - val_loss: 0.6043 - val_accuracy: 0.7100\n",
      "Epoch 175/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6446 - accuracy: 0.6398 - val_loss: 0.5957 - val_accuracy: 0.7200\n",
      "Epoch 176/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6383 - accuracy: 0.6822 - val_loss: 0.6038 - val_accuracy: 0.7000\n",
      "Epoch 177/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6516 - accuracy: 0.5975 - val_loss: 0.6167 - val_accuracy: 0.6700\n",
      "Epoch 178/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6565 - accuracy: 0.6186 - val_loss: 0.5986 - val_accuracy: 0.7100\n",
      "Epoch 179/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6439 - accuracy: 0.5932 - val_loss: 0.6070 - val_accuracy: 0.7000\n",
      "Epoch 180/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6616 - accuracy: 0.5932 - val_loss: 0.6043 - val_accuracy: 0.7200\n",
      "Epoch 181/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6390 - accuracy: 0.6144 - val_loss: 0.5977 - val_accuracy: 0.7000\n",
      "Epoch 182/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6370 - accuracy: 0.6653 - val_loss: 0.5939 - val_accuracy: 0.7200\n",
      "Epoch 183/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6420 - accuracy: 0.6398 - val_loss: 0.5937 - val_accuracy: 0.6900\n",
      "Epoch 184/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6427 - accuracy: 0.6525 - val_loss: 0.5929 - val_accuracy: 0.7000\n",
      "Epoch 185/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6474 - accuracy: 0.6059 - val_loss: 0.5974 - val_accuracy: 0.7000\n",
      "Epoch 186/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6413 - accuracy: 0.6483 - val_loss: 0.5955 - val_accuracy: 0.7100\n",
      "Epoch 187/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6450 - accuracy: 0.6441 - val_loss: 0.6023 - val_accuracy: 0.7000\n",
      "Epoch 188/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6550 - accuracy: 0.6144 - val_loss: 0.6004 - val_accuracy: 0.7000\n",
      "Epoch 189/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6450 - accuracy: 0.6229 - val_loss: 0.5926 - val_accuracy: 0.7200\n",
      "Epoch 190/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6370 - accuracy: 0.6653 - val_loss: 0.5914 - val_accuracy: 0.6900\n",
      "Epoch 191/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6428 - accuracy: 0.6483 - val_loss: 0.6034 - val_accuracy: 0.6900\n",
      "Epoch 192/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6334 - accuracy: 0.6398 - val_loss: 0.5947 - val_accuracy: 0.7100\n",
      "Epoch 193/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6362 - accuracy: 0.6483 - val_loss: 0.5926 - val_accuracy: 0.7000\n",
      "Epoch 194/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6494 - accuracy: 0.6356 - val_loss: 0.5874 - val_accuracy: 0.7000\n",
      "Epoch 195/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6346 - accuracy: 0.6695 - val_loss: 0.5860 - val_accuracy: 0.6900\n",
      "Epoch 196/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6342 - accuracy: 0.6610 - val_loss: 0.5905 - val_accuracy: 0.7100\n",
      "Epoch 197/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6347 - accuracy: 0.6186 - val_loss: 0.5867 - val_accuracy: 0.6800\n",
      "Epoch 198/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6298 - accuracy: 0.6610 - val_loss: 0.5857 - val_accuracy: 0.7100\n",
      "Epoch 199/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6374 - accuracy: 0.6525 - val_loss: 0.5883 - val_accuracy: 0.7100\n",
      "Epoch 200/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6432 - accuracy: 0.6271 - val_loss: 0.6132 - val_accuracy: 0.6900\n",
      "Epoch 201/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6512 - accuracy: 0.6271 - val_loss: 0.5888 - val_accuracy: 0.7200\n",
      "Epoch 202/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6428 - accuracy: 0.6483 - val_loss: 0.5887 - val_accuracy: 0.7100\n",
      "Epoch 203/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6487 - accuracy: 0.6398 - val_loss: 0.6092 - val_accuracy: 0.5900\n",
      "Epoch 204/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6456 - accuracy: 0.6271 - val_loss: 0.5923 - val_accuracy: 0.7100\n",
      "Epoch 205/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6345 - accuracy: 0.6398 - val_loss: 0.5899 - val_accuracy: 0.6900\n",
      "Epoch 206/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6452 - accuracy: 0.6356 - val_loss: 0.5990 - val_accuracy: 0.7200\n",
      "Epoch 207/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6473 - accuracy: 0.6314 - val_loss: 0.5904 - val_accuracy: 0.7200\n",
      "Epoch 208/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6252 - accuracy: 0.6949 - val_loss: 0.5843 - val_accuracy: 0.6900\n",
      "Epoch 209/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6307 - accuracy: 0.6864 - val_loss: 0.5888 - val_accuracy: 0.7000\n",
      "Epoch 210/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6385 - accuracy: 0.6186 - val_loss: 0.5883 - val_accuracy: 0.7200\n",
      "Epoch 211/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6379 - accuracy: 0.6398 - val_loss: 0.5887 - val_accuracy: 0.7100\n",
      "Epoch 212/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6269 - accuracy: 0.6949 - val_loss: 0.5920 - val_accuracy: 0.7000\n",
      "Epoch 213/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6401 - accuracy: 0.6229 - val_loss: 0.5835 - val_accuracy: 0.7100\n",
      "Epoch 214/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6317 - accuracy: 0.6356 - val_loss: 0.5840 - val_accuracy: 0.6900\n",
      "Epoch 215/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6280 - accuracy: 0.6653 - val_loss: 0.5815 - val_accuracy: 0.7000\n",
      "Epoch 216/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6287 - accuracy: 0.6653 - val_loss: 0.5820 - val_accuracy: 0.7100\n",
      "Epoch 217/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6317 - accuracy: 0.6314 - val_loss: 0.5879 - val_accuracy: 0.7200\n",
      "Epoch 218/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6376 - accuracy: 0.6441 - val_loss: 0.5805 - val_accuracy: 0.7000\n",
      "Epoch 219/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6454 - accuracy: 0.5890 - val_loss: 0.5909 - val_accuracy: 0.6900\n",
      "Epoch 220/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6288 - accuracy: 0.6525 - val_loss: 0.5847 - val_accuracy: 0.7300\n",
      "Epoch 221/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6328 - accuracy: 0.6398 - val_loss: 0.5784 - val_accuracy: 0.7000\n",
      "Epoch 222/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6132 - accuracy: 0.7034 - val_loss: 0.5909 - val_accuracy: 0.6900\n",
      "Epoch 223/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6458 - accuracy: 0.6483 - val_loss: 0.5798 - val_accuracy: 0.7100\n",
      "Epoch 224/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6854 - accuracy: 0.5508 - val_loss: 0.5987 - val_accuracy: 0.6800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6559 - accuracy: 0.5847 - val_loss: 0.5935 - val_accuracy: 0.7000\n",
      "Epoch 226/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6409 - accuracy: 0.6271 - val_loss: 0.5941 - val_accuracy: 0.6900\n",
      "Epoch 227/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6298 - accuracy: 0.6483 - val_loss: 0.5830 - val_accuracy: 0.7100\n",
      "Epoch 228/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6254 - accuracy: 0.6610 - val_loss: 0.5788 - val_accuracy: 0.7200\n",
      "Epoch 229/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6283 - accuracy: 0.6610 - val_loss: 0.5807 - val_accuracy: 0.7200\n",
      "Epoch 230/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6224 - accuracy: 0.6314 - val_loss: 0.5870 - val_accuracy: 0.6900\n",
      "Epoch 231/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6310 - accuracy: 0.6356 - val_loss: 0.5835 - val_accuracy: 0.7200\n",
      "Epoch 232/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6367 - accuracy: 0.6229 - val_loss: 0.5815 - val_accuracy: 0.7100\n",
      "Epoch 233/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6738 - accuracy: 0.6102 - val_loss: 0.6312 - val_accuracy: 0.6700\n",
      "Epoch 234/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6470 - accuracy: 0.6271 - val_loss: 0.5787 - val_accuracy: 0.7200\n",
      "Epoch 235/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6311 - accuracy: 0.6525 - val_loss: 0.5877 - val_accuracy: 0.7000\n",
      "Epoch 236/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6278 - accuracy: 0.6992 - val_loss: 0.5913 - val_accuracy: 0.6900\n",
      "Epoch 237/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6269 - accuracy: 0.6525 - val_loss: 0.5818 - val_accuracy: 0.7200\n",
      "Epoch 238/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6269 - accuracy: 0.6610 - val_loss: 0.5788 - val_accuracy: 0.7200\n",
      "Epoch 239/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6435 - accuracy: 0.6314 - val_loss: 0.5905 - val_accuracy: 0.7000\n",
      "Epoch 240/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6404 - accuracy: 0.6356 - val_loss: 0.5796 - val_accuracy: 0.7200\n",
      "Epoch 241/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6314 - accuracy: 0.6229 - val_loss: 0.5914 - val_accuracy: 0.7000\n",
      "Epoch 242/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6380 - accuracy: 0.6314 - val_loss: 0.6025 - val_accuracy: 0.6800\n",
      "Epoch 243/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6222 - accuracy: 0.6737 - val_loss: 0.5800 - val_accuracy: 0.7200\n",
      "Epoch 244/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6258 - accuracy: 0.6525 - val_loss: 0.5768 - val_accuracy: 0.7000\n",
      "Epoch 245/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6178 - accuracy: 0.6356 - val_loss: 0.5777 - val_accuracy: 0.7100\n",
      "Epoch 246/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6247 - accuracy: 0.6356 - val_loss: 0.5748 - val_accuracy: 0.7400\n",
      "Epoch 247/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6171 - accuracy: 0.6780 - val_loss: 0.5752 - val_accuracy: 0.7200\n",
      "Epoch 248/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6215 - accuracy: 0.6610 - val_loss: 0.5751 - val_accuracy: 0.7100\n",
      "Epoch 249/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6249 - accuracy: 0.6525 - val_loss: 0.5759 - val_accuracy: 0.7100\n",
      "Epoch 250/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6166 - accuracy: 0.6568 - val_loss: 0.5732 - val_accuracy: 0.7200\n",
      "Epoch 251/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6158 - accuracy: 0.6271 - val_loss: 0.5773 - val_accuracy: 0.7100\n",
      "Epoch 252/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6205 - accuracy: 0.6737 - val_loss: 0.5783 - val_accuracy: 0.6900\n",
      "Epoch 253/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6258 - accuracy: 0.6568 - val_loss: 0.5840 - val_accuracy: 0.6900\n",
      "Epoch 254/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6126 - accuracy: 0.6483 - val_loss: 0.5692 - val_accuracy: 0.7300\n",
      "Epoch 255/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6248 - accuracy: 0.6229 - val_loss: 0.5882 - val_accuracy: 0.7000\n",
      "Epoch 256/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6176 - accuracy: 0.6695 - val_loss: 0.5719 - val_accuracy: 0.7000\n",
      "Epoch 257/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6138 - accuracy: 0.6737 - val_loss: 0.5734 - val_accuracy: 0.6900\n",
      "Epoch 258/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6181 - accuracy: 0.6737 - val_loss: 0.5693 - val_accuracy: 0.7400\n",
      "Epoch 259/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6266 - accuracy: 0.6780 - val_loss: 0.6262 - val_accuracy: 0.6700\n",
      "Epoch 260/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6378 - accuracy: 0.6144 - val_loss: 0.5733 - val_accuracy: 0.7300\n",
      "Epoch 261/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6178 - accuracy: 0.6737 - val_loss: 0.5790 - val_accuracy: 0.7000\n",
      "Epoch 262/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6327 - accuracy: 0.6356 - val_loss: 0.5753 - val_accuracy: 0.6800\n",
      "Epoch 263/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6051 - accuracy: 0.6568 - val_loss: 0.5780 - val_accuracy: 0.7000\n",
      "Epoch 264/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6246 - accuracy: 0.6186 - val_loss: 0.5948 - val_accuracy: 0.6700\n",
      "Epoch 265/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6093 - accuracy: 0.6483 - val_loss: 0.5753 - val_accuracy: 0.7200\n",
      "Epoch 266/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6101 - accuracy: 0.6356 - val_loss: 0.5690 - val_accuracy: 0.7100\n",
      "Epoch 267/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6070 - accuracy: 0.6610 - val_loss: 0.5741 - val_accuracy: 0.7400\n",
      "Epoch 268/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6115 - accuracy: 0.6822 - val_loss: 0.5785 - val_accuracy: 0.6900\n",
      "Epoch 269/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6233 - accuracy: 0.6314 - val_loss: 0.5719 - val_accuracy: 0.7200\n",
      "Epoch 270/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6311 - accuracy: 0.6229 - val_loss: 0.6128 - val_accuracy: 0.6600\n",
      "Epoch 271/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6098 - accuracy: 0.6737 - val_loss: 0.5687 - val_accuracy: 0.7100\n",
      "Epoch 272/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6119 - accuracy: 0.6695 - val_loss: 0.5667 - val_accuracy: 0.7200\n",
      "Epoch 273/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6010 - accuracy: 0.6822 - val_loss: 0.5655 - val_accuracy: 0.7200\n",
      "Epoch 274/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6048 - accuracy: 0.6610 - val_loss: 0.5638 - val_accuracy: 0.7400\n",
      "Epoch 275/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6180 - accuracy: 0.6568 - val_loss: 0.5654 - val_accuracy: 0.7000\n",
      "Epoch 276/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6310 - accuracy: 0.6186 - val_loss: 0.5747 - val_accuracy: 0.7000\n",
      "Epoch 277/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6206 - accuracy: 0.6780 - val_loss: 0.5671 - val_accuracy: 0.7300\n",
      "Epoch 278/300\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 0.6060 - accuracy: 0.6610 - val_loss: 0.5649 - val_accuracy: 0.7200\n",
      "Epoch 279/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6046 - accuracy: 0.7246 - val_loss: 0.5644 - val_accuracy: 0.7000\n",
      "Epoch 280/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6042 - accuracy: 0.6822 - val_loss: 0.5660 - val_accuracy: 0.7100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6129 - accuracy: 0.6314 - val_loss: 0.5697 - val_accuracy: 0.7200\n",
      "Epoch 282/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.5990 - accuracy: 0.6653 - val_loss: 0.5634 - val_accuracy: 0.6900\n",
      "Epoch 283/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6109 - accuracy: 0.6737 - val_loss: 0.5873 - val_accuracy: 0.6700\n",
      "Epoch 284/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6002 - accuracy: 0.6610 - val_loss: 0.5694 - val_accuracy: 0.7000\n",
      "Epoch 285/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6061 - accuracy: 0.6398 - val_loss: 0.5672 - val_accuracy: 0.7100\n",
      "Epoch 286/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6141 - accuracy: 0.6483 - val_loss: 0.5598 - val_accuracy: 0.7200\n",
      "Epoch 287/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.5964 - accuracy: 0.6992 - val_loss: 0.5616 - val_accuracy: 0.7300\n",
      "Epoch 288/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6022 - accuracy: 0.6610 - val_loss: 0.5626 - val_accuracy: 0.7200\n",
      "Epoch 289/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6094 - accuracy: 0.6610 - val_loss: 0.5570 - val_accuracy: 0.7500\n",
      "Epoch 290/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6024 - accuracy: 0.6864 - val_loss: 0.5577 - val_accuracy: 0.7200\n",
      "Epoch 291/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.5943 - accuracy: 0.6992 - val_loss: 0.5697 - val_accuracy: 0.7000\n",
      "Epoch 292/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6176 - accuracy: 0.6737 - val_loss: 0.5585 - val_accuracy: 0.7300\n",
      "Epoch 293/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6237 - accuracy: 0.6653 - val_loss: 0.5859 - val_accuracy: 0.6800\n",
      "Epoch 294/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6174 - accuracy: 0.6356 - val_loss: 0.6334 - val_accuracy: 0.5800\n",
      "Epoch 295/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6365 - accuracy: 0.6314 - val_loss: 0.5673 - val_accuracy: 0.7000\n",
      "Epoch 296/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6042 - accuracy: 0.6907 - val_loss: 0.5715 - val_accuracy: 0.6900\n",
      "Epoch 297/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6039 - accuracy: 0.6992 - val_loss: 0.5627 - val_accuracy: 0.7100\n",
      "Epoch 298/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6029 - accuracy: 0.6780 - val_loss: 0.5637 - val_accuracy: 0.7000\n",
      "Epoch 299/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.6123 - accuracy: 0.6653 - val_loss: 0.5675 - val_accuracy: 0.7100\n",
      "Epoch 300/300\n",
      "236/236 [==============================] - 12s 51ms/step - loss: 0.5861 - accuracy: 0.6907 - val_loss: 0.5891 - val_accuracy: 0.6700\n",
      "Best validation acc of epoch: 0.75\n",
      "100/100 [==============================] - 1s 12ms/step\n",
      "average: 0.75\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "data.append(run(2,'individual_note_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'run_name': 'individual_note_test', 'best_validation_acc': 0.75, 'average': 0.75}]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
