{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "# This function returns a normalized version of the input dataframe \n",
    "def normalize(df):\n",
    "    normalized_df = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        normalized_df[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "        \n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Dataset ###\n",
    "def load_data_kfold(k):\n",
    "    \n",
    "    DATASET_PATH = \"emotion-recognition-by-voice/datasets/dataset_48.csv\"\n",
    "    NUMBER_OF_SPLITS = 10\n",
    "    df = pd.read_csv(DATASET_PATH, sep=\",\")\n",
    "\n",
    "    X = df[df.columns[3:51]] # Only the MFCC features\n",
    "    y = df[df.columns[-1]] # Emotion label\n",
    "\n",
    "    # Normalization of input features in X\n",
    "    X = normalize(X)\n",
    "\n",
    "    # Split the dataset in train and test\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3)\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    \n",
    "\n",
    "\n",
    "    folds = list(StratifiedKFold(n_splits=NUMBER_OF_SPLITS, shuffle=True, random_state=1).split(X_train, y_train))\n",
    "\n",
    "    return folds, X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Callback Functions ##\n",
    "\n",
    "def get_callbacks(name_weights, patience_lr):\n",
    "    mcp_save = ModelCheckpoint(name_weights, save_best_only=True, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=patience_lr, verbose=1, epsilon=1e-4, mode='min')\n",
    "    return [mcp_save, reduce_lr_loss]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model ##\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(128, 5,padding='same', input_shape=(48,1), name=\"conv1\"))\n",
    "    model.add(Activation('sigmoid', name=\"activation1\"))\n",
    "    model.add(Conv1D(64, 5,padding='same', name=\"conv2\"))\n",
    "    model.add(Activation('sigmoid', name=\"activation2\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling1D(pool_size=(8)))\n",
    "    model.add(Conv1D(32, 5,padding='same',))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Conv1D(32, 5,padding='same',))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax', name=\"last_activation\"))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(1))\n",
    "#     model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds, X_train, y_train = load_data_kfold(7)\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv[0]\n",
    "X_train\n",
    "X_traincnn = np.expand_dims(X_train, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_89 (Conv1D)           (None, 48, 128)           768       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 48, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 48, 64)            41024     \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 48, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 48, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 6, 32)             10272     \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 6, 32)             5152      \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 7)                 1351      \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 58,567\n",
      "Trainable params: 58,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 954 samples, validate on 112 samples\n",
      "Epoch 1/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9711 - accuracy: 0.1436 - val_loss: 1.9677 - val_accuracy: 0.1429\n",
      "Epoch 2/100\n",
      "954/954 [==============================] - 0s 449us/step - loss: 1.9657 - accuracy: 0.1205 - val_loss: 1.9535 - val_accuracy: 0.1429\n",
      "Epoch 3/100\n",
      "954/954 [==============================] - 1s 612us/step - loss: 1.9631 - accuracy: 0.1300 - val_loss: 1.9613 - val_accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "954/954 [==============================] - 1s 571us/step - loss: 1.9581 - accuracy: 0.1394 - val_loss: 1.9618 - val_accuracy: 0.1429\n",
      "Epoch 5/100\n",
      "954/954 [==============================] - 0s 469us/step - loss: 1.9598 - accuracy: 0.1436 - val_loss: 1.9539 - val_accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "954/954 [==============================] - 0s 448us/step - loss: 1.9605 - accuracy: 0.1373 - val_loss: 1.9558 - val_accuracy: 0.1429\n",
      "Epoch 7/100\n",
      "954/954 [==============================] - 1s 629us/step - loss: 1.9578 - accuracy: 0.1237 - val_loss: 1.9517 - val_accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "954/954 [==============================] - 1s 757us/step - loss: 1.9518 - accuracy: 0.1289 - val_loss: 1.9486 - val_accuracy: 0.1429\n",
      "Epoch 9/100\n",
      "954/954 [==============================] - 1s 932us/step - loss: 1.9559 - accuracy: 0.1164 - val_loss: 1.9482 - val_accuracy: 0.1429\n",
      "Epoch 10/100\n",
      "954/954 [==============================] - 1s 815us/step - loss: 1.9539 - accuracy: 0.1394 - val_loss: 1.9507 - val_accuracy: 0.1429\n",
      "Epoch 11/100\n",
      "954/954 [==============================] - 1s 747us/step - loss: 1.9576 - accuracy: 0.1247 - val_loss: 1.9473 - val_accuracy: 0.1429\n",
      "Epoch 12/100\n",
      "954/954 [==============================] - 1s 662us/step - loss: 1.9580 - accuracy: 0.1195 - val_loss: 1.9559 - val_accuracy: 0.1429\n",
      "Epoch 13/100\n",
      "954/954 [==============================] - 1s 749us/step - loss: 1.9627 - accuracy: 0.1310 - val_loss: 1.9563 - val_accuracy: 0.1429\n",
      "Epoch 14/100\n",
      "954/954 [==============================] - 1s 615us/step - loss: 1.9566 - accuracy: 0.1279 - val_loss: 1.9492 - val_accuracy: 0.1429\n",
      "Epoch 15/100\n",
      "954/954 [==============================] - 1s 606us/step - loss: 1.9590 - accuracy: 0.1394 - val_loss: 1.9522 - val_accuracy: 0.1429\n",
      "Epoch 16/100\n",
      "954/954 [==============================] - 1s 636us/step - loss: 1.9530 - accuracy: 0.1268 - val_loss: 1.9485 - val_accuracy: 0.1429\n",
      "Epoch 17/100\n",
      "954/954 [==============================] - 1s 650us/step - loss: 1.9534 - accuracy: 0.1300 - val_loss: 1.9493 - val_accuracy: 0.1429\n",
      "Epoch 18/100\n",
      "954/954 [==============================] - 1s 691us/step - loss: 1.9564 - accuracy: 0.1132 - val_loss: 1.9506 - val_accuracy: 0.1429\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 19/100\n",
      "954/954 [==============================] - 1s 717us/step - loss: 1.9500 - accuracy: 0.1426 - val_loss: 1.9481 - val_accuracy: 0.1429\n",
      "Epoch 20/100\n",
      "954/954 [==============================] - 1s 859us/step - loss: 1.9482 - accuracy: 0.1310 - val_loss: 1.9466 - val_accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "954/954 [==============================] - 1s 762us/step - loss: 1.9467 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 22/100\n",
      "954/954 [==============================] - 1s 638us/step - loss: 1.9467 - accuracy: 0.1363 - val_loss: 1.9461 - val_accuracy: 0.1429\n",
      "Epoch 23/100\n",
      "954/954 [==============================] - 1s 824us/step - loss: 1.9473 - accuracy: 0.1195 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 24/100\n",
      "954/954 [==============================] - 1s 738us/step - loss: 1.9467 - accuracy: 0.1394 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 25/100\n",
      "954/954 [==============================] - 1s 942us/step - loss: 1.9468 - accuracy: 0.1247 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 26/100\n",
      "954/954 [==============================] - 1s 922us/step - loss: 1.9470 - accuracy: 0.1226 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 27/100\n",
      "954/954 [==============================] - 1s 971us/step - loss: 1.9477 - accuracy: 0.1310 - val_loss: 1.9461 - val_accuracy: 0.1429\n",
      "Epoch 28/100\n",
      "954/954 [==============================] - 1s 945us/step - loss: 1.9475 - accuracy: 0.1237 - val_loss: 1.9461 - val_accuracy: 0.1429\n",
      "Epoch 29/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9468 - accuracy: 0.1247 - val_loss: 1.9459 - val_accuracy: 0.1429\n",
      "Epoch 30/100\n",
      "954/954 [==============================] - 1s 942us/step - loss: 1.9467 - accuracy: 0.1174 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 31/100\n",
      "954/954 [==============================] - 1s 940us/step - loss: 1.9471 - accuracy: 0.1363 - val_loss: 1.9461 - val_accuracy: 0.1429\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 32/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9461 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 33/100\n",
      "954/954 [==============================] - 1s 896us/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 34/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 35/100\n",
      "954/954 [==============================] - 1s 920us/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 36/100\n",
      "954/954 [==============================] - 1s 694us/step - loss: 1.9461 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 37/100\n",
      "954/954 [==============================] - 1s 614us/step - loss: 1.9461 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 38/100\n",
      "954/954 [==============================] - 1s 684us/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 39/100\n",
      "954/954 [==============================] - 1s 662us/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 40/100\n",
      "954/954 [==============================] - 1s 658us/step - loss: 1.9460 - accuracy: 0.1363 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 41/100\n",
      "954/954 [==============================] - 1s 667us/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 42/100\n",
      "954/954 [==============================] - 1s 718us/step - loss: 1.9460 - accuracy: 0.1321 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 43/100\n",
      "954/954 [==============================] - 1s 849us/step - loss: 1.9459 - accuracy: 0.1384 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 44/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1352 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 45/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "954/954 [==============================] - 1s 814us/step - loss: 1.9459 - accuracy: 0.1352 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 47/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1300 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 48/100\n",
      "954/954 [==============================] - 1s 860us/step - loss: 1.9459 - accuracy: 0.1468 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 49/100\n",
      "954/954 [==============================] - 1s 999us/step - loss: 1.9459 - accuracy: 0.1520 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 50/100\n",
      "954/954 [==============================] - 1s 979us/step - loss: 1.9459 - accuracy: 0.1415 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 51/100\n",
      "954/954 [==============================] - 1s 981us/step - loss: 1.9459 - accuracy: 0.1551 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 52/100\n",
      "954/954 [==============================] - 1s 769us/step - loss: 1.9459 - accuracy: 0.1321 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 53/100\n",
      "954/954 [==============================] - 1s 896us/step - loss: 1.9459 - accuracy: 0.1342 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 54/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "954/954 [==============================] - 1s 845us/step - loss: 1.9459 - accuracy: 0.1509 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 56/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1384 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 57/100\n",
      "954/954 [==============================] - 1s 859us/step - loss: 1.9459 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 58/100\n",
      "954/954 [==============================] - 1s 968us/step - loss: 1.9459 - accuracy: 0.1247 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 59/100\n",
      "954/954 [==============================] - 1s 962us/step - loss: 1.9459 - accuracy: 0.1384 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 60/100\n",
      "954/954 [==============================] - 1s 706us/step - loss: 1.9459 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 61/100\n",
      "954/954 [==============================] - 1s 696us/step - loss: 1.9459 - accuracy: 0.1352 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 62/100\n",
      "954/954 [==============================] - 1s 691us/step - loss: 1.9459 - accuracy: 0.1405 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 63/100\n",
      "954/954 [==============================] - 1s 687us/step - loss: 1.9459 - accuracy: 0.1310 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 64/100\n",
      "954/954 [==============================] - 1s 803us/step - loss: 1.9459 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 65/100\n",
      "954/954 [==============================] - 1s 714us/step - loss: 1.9459 - accuracy: 0.1457 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 66/100\n",
      "954/954 [==============================] - 1s 696us/step - loss: 1.9459 - accuracy: 0.1468 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 67/100\n",
      "954/954 [==============================] - 1s 827us/step - loss: 1.9459 - accuracy: 0.1541 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 68/100\n",
      "954/954 [==============================] - 1s 891us/step - loss: 1.9459 - accuracy: 0.1468 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 69/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 70/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1499 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 71/100\n",
      "954/954 [==============================] - 1s 653us/step - loss: 1.9459 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 72/100\n",
      "954/954 [==============================] - 1s 750us/step - loss: 1.9459 - accuracy: 0.1520 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 73/100\n",
      "954/954 [==============================] - 1s 527us/step - loss: 1.9459 - accuracy: 0.1289 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 74/100\n",
      "954/954 [==============================] - 0s 513us/step - loss: 1.9459 - accuracy: 0.1352 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 75/100\n",
      "954/954 [==============================] - 1s 627us/step - loss: 1.9459 - accuracy: 0.1625 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 76/100\n",
      "954/954 [==============================] - 0s 517us/step - loss: 1.9459 - accuracy: 0.1499 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 77/100\n",
      "954/954 [==============================] - 0s 506us/step - loss: 1.9459 - accuracy: 0.1415 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "954/954 [==============================] - 1s 564us/step - loss: 1.9459 - accuracy: 0.1562 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 79/100\n",
      "954/954 [==============================] - 1s 552us/step - loss: 1.9459 - accuracy: 0.1478 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 80/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1646 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 81/100\n",
      "954/954 [==============================] - 1s 2ms/step - loss: 1.9459 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 82/100\n",
      "954/954 [==============================] - 2s 2ms/step - loss: 1.9459 - accuracy: 0.1530 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 83/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1520 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 84/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 85/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1457 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 86/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 87/100\n",
      "954/954 [==============================] - 1s 875us/step - loss: 1.9459 - accuracy: 0.1394 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 88/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 89/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1363 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 90/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1457 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 91/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1384 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 92/100\n",
      "954/954 [==============================] - 1s 1ms/step - loss: 1.9459 - accuracy: 0.1405 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 93/100\n",
      "954/954 [==============================] - 1s 919us/step - loss: 1.9459 - accuracy: 0.1478 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "Epoch 94/100\n",
      "954/954 [==============================] - 1s 884us/step - loss: 1.9459 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 95/100\n",
      "954/954 [==============================] - 1s 738us/step - loss: 1.9459 - accuracy: 0.1583 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 96/100\n",
      "954/954 [==============================] - 1s 618us/step - loss: 1.9459 - accuracy: 0.1457 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 97/100\n",
      "954/954 [==============================] - 1s 627us/step - loss: 1.9459 - accuracy: 0.1478 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 98/100\n",
      "954/954 [==============================] - 1s 868us/step - loss: 1.9459 - accuracy: 0.1499 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 99/100\n",
      "954/954 [==============================] - 1s 706us/step - loss: 1.9459 - accuracy: 0.1457 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "954/954 [==============================] - 1s 643us/step - loss: 1.9459 - accuracy: 0.1405 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
      "\n",
      "Fold  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 955 samples, validate on 111 samples\n",
      "Epoch 1/100\n",
      "955/955 [==============================] - 1s 924us/step - loss: 1.9887 - accuracy: 0.1131 - val_loss: 1.9523 - val_accuracy: 0.1441\n",
      "Epoch 2/100\n",
      "955/955 [==============================] - 1s 535us/step - loss: 1.9547 - accuracy: 0.1382 - val_loss: 1.9511 - val_accuracy: 0.1441\n",
      "Epoch 3/100\n",
      "955/955 [==============================] - 1s 716us/step - loss: 1.9632 - accuracy: 0.1382 - val_loss: 1.9533 - val_accuracy: 0.1441\n",
      "Epoch 4/100\n",
      "955/955 [==============================] - 1s 634us/step - loss: 1.9606 - accuracy: 0.1225 - val_loss: 1.9514 - val_accuracy: 0.1441\n",
      "Epoch 5/100\n",
      "955/955 [==============================] - 1s 686us/step - loss: 1.9530 - accuracy: 0.1424 - val_loss: 1.9524 - val_accuracy: 0.1441\n",
      "Epoch 6/100\n",
      "955/955 [==============================] - 1s 772us/step - loss: 1.9571 - accuracy: 0.1382 - val_loss: 1.9623 - val_accuracy: 0.1441\n",
      "Epoch 7/100\n",
      "955/955 [==============================] - 1s 716us/step - loss: 1.9625 - accuracy: 0.1309 - val_loss: 1.9536 - val_accuracy: 0.1441\n",
      "Epoch 8/100\n",
      "955/955 [==============================] - 1s 669us/step - loss: 1.9575 - accuracy: 0.1403 - val_loss: 1.9545 - val_accuracy: 0.1351\n",
      "Epoch 9/100\n",
      "955/955 [==============================] - 1s 665us/step - loss: 1.9626 - accuracy: 0.0963 - val_loss: 1.9465 - val_accuracy: 0.1441\n",
      "Epoch 10/100\n",
      "955/955 [==============================] - 1s 634us/step - loss: 1.9566 - accuracy: 0.1361 - val_loss: 1.9543 - val_accuracy: 0.1351\n",
      "Epoch 11/100\n",
      "955/955 [==============================] - 0s 493us/step - loss: 1.9631 - accuracy: 0.1351 - val_loss: 1.9519 - val_accuracy: 0.1441\n",
      "Epoch 12/100\n",
      "955/955 [==============================] - 0s 472us/step - loss: 1.9534 - accuracy: 0.1330 - val_loss: 1.9467 - val_accuracy: 0.2072\n",
      "Epoch 13/100\n",
      "955/955 [==============================] - 0s 480us/step - loss: 1.9535 - accuracy: 0.1236 - val_loss: 1.9461 - val_accuracy: 0.1441\n",
      "Epoch 14/100\n",
      "955/955 [==============================] - 1s 563us/step - loss: 1.9546 - accuracy: 0.1435 - val_loss: 1.9488 - val_accuracy: 0.1441\n",
      "Epoch 15/100\n",
      "955/955 [==============================] - 1s 685us/step - loss: 1.9519 - accuracy: 0.1455 - val_loss: 1.9489 - val_accuracy: 0.1441\n",
      "Epoch 16/100\n",
      "955/955 [==============================] - 1s 554us/step - loss: 1.9541 - accuracy: 0.1120 - val_loss: 1.9475 - val_accuracy: 0.1441\n",
      "Epoch 17/100\n",
      "955/955 [==============================] - 0s 507us/step - loss: 1.9529 - accuracy: 0.1529 - val_loss: 1.9498 - val_accuracy: 0.1351\n",
      "Epoch 18/100\n",
      "955/955 [==============================] - 1s 885us/step - loss: 1.9555 - accuracy: 0.1141 - val_loss: 1.9490 - val_accuracy: 0.1351\n",
      "Epoch 19/100\n",
      "955/955 [==============================] - 1s 648us/step - loss: 1.9573 - accuracy: 0.1225 - val_loss: 1.9509 - val_accuracy: 0.1351\n",
      "Epoch 20/100\n",
      "955/955 [==============================] - 1s 728us/step - loss: 1.9526 - accuracy: 0.1487 - val_loss: 1.9488 - val_accuracy: 0.1441\n",
      "Epoch 21/100\n",
      "955/955 [==============================] - 0s 495us/step - loss: 1.9521 - accuracy: 0.1319 - val_loss: 1.9484 - val_accuracy: 0.1351\n",
      "Epoch 22/100\n",
      "955/955 [==============================] - 0s 519us/step - loss: 1.9529 - accuracy: 0.1141 - val_loss: 1.9476 - val_accuracy: 0.1351\n",
      "Epoch 23/100\n",
      "955/955 [==============================] - 1s 537us/step - loss: 1.9510 - accuracy: 0.1319 - val_loss: 1.9461 - val_accuracy: 0.1441\n",
      "Epoch 24/100\n",
      "955/955 [==============================] - 1s 728us/step - loss: 1.9505 - accuracy: 0.1298 - val_loss: 1.9462 - val_accuracy: 0.1441\n",
      "Epoch 25/100\n",
      "955/955 [==============================] - 1s 827us/step - loss: 1.9508 - accuracy: 0.1319 - val_loss: 1.9466 - val_accuracy: 0.1441\n",
      "Epoch 26/100\n",
      "955/955 [==============================] - 1s 842us/step - loss: 1.9515 - accuracy: 0.1361 - val_loss: 1.9463 - val_accuracy: 0.1441\n",
      "Epoch 27/100\n",
      "955/955 [==============================] - 1s 719us/step - loss: 1.9516 - accuracy: 0.1277 - val_loss: 1.9465 - val_accuracy: 0.1441\n",
      "Epoch 28/100\n",
      "955/955 [==============================] - 1s 668us/step - loss: 1.9513 - accuracy: 0.1361 - val_loss: 1.9464 - val_accuracy: 0.1351\n",
      "Epoch 29/100\n",
      "955/955 [==============================] - 1s 687us/step - loss: 1.9526 - accuracy: 0.1204 - val_loss: 1.9461 - val_accuracy: 0.1441\n",
      "Epoch 30/100\n",
      "955/955 [==============================] - 1s 765us/step - loss: 1.9526 - accuracy: 0.1225 - val_loss: 1.9467 - val_accuracy: 0.1441\n",
      "Epoch 31/100\n",
      "955/955 [==============================] - 0s 481us/step - loss: 1.9503 - accuracy: 0.1351 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 32/100\n",
      "955/955 [==============================] - 0s 513us/step - loss: 1.9509 - accuracy: 0.1393 - val_loss: 1.9464 - val_accuracy: 0.1441\n",
      "Epoch 33/100\n",
      "955/955 [==============================] - 0s 479us/step - loss: 1.9488 - accuracy: 0.1183 - val_loss: 1.9461 - val_accuracy: 0.1441\n",
      "Epoch 34/100\n",
      "955/955 [==============================] - 0s 496us/step - loss: 1.9485 - accuracy: 0.1204 - val_loss: 1.9464 - val_accuracy: 0.1441\n",
      "Epoch 35/100\n",
      "955/955 [==============================] - 0s 480us/step - loss: 1.9515 - accuracy: 0.1298 - val_loss: 1.9463 - val_accuracy: 0.1441\n",
      "Epoch 36/100\n",
      "955/955 [==============================] - 0s 509us/step - loss: 1.9510 - accuracy: 0.1466 - val_loss: 1.9463 - val_accuracy: 0.1441\n",
      "Epoch 37/100\n",
      "955/955 [==============================] - 1s 701us/step - loss: 1.9489 - accuracy: 0.1372 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 38/100\n",
      "955/955 [==============================] - 0s 486us/step - loss: 1.9483 - accuracy: 0.1110 - val_loss: 1.9465 - val_accuracy: 0.1351\n",
      "Epoch 39/100\n",
      "955/955 [==============================] - 0s 484us/step - loss: 1.9487 - accuracy: 0.1236 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 40/100\n",
      "955/955 [==============================] - 0s 517us/step - loss: 1.9485 - accuracy: 0.1267 - val_loss: 1.9469 - val_accuracy: 0.1441\n",
      "Epoch 41/100\n",
      "955/955 [==============================] - 0s 493us/step - loss: 1.9484 - accuracy: 0.1298 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 42/100\n",
      "955/955 [==============================] - 0s 494us/step - loss: 1.9504 - accuracy: 0.1215 - val_loss: 1.9463 - val_accuracy: 0.1351\n",
      "Epoch 43/100\n",
      "955/955 [==============================] - 0s 498us/step - loss: 1.9478 - accuracy: 0.1267 - val_loss: 1.9462 - val_accuracy: 0.1441\n",
      "Epoch 44/100\n",
      "955/955 [==============================] - 1s 710us/step - loss: 1.9488 - accuracy: 0.1361 - val_loss: 1.9463 - val_accuracy: 0.1441\n",
      "Epoch 45/100\n",
      "955/955 [==============================] - 1s 741us/step - loss: 1.9478 - accuracy: 0.1236 - val_loss: 1.9461 - val_accuracy: 0.1441\n",
      "Epoch 46/100\n",
      "955/955 [==============================] - 1s 648us/step - loss: 1.9484 - accuracy: 0.1414 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 47/100\n",
      "955/955 [==============================] - 1s 688us/step - loss: 1.9482 - accuracy: 0.1141 - val_loss: 1.9460 - val_accuracy: 0.1441\n",
      "Epoch 48/100\n",
      "955/955 [==============================] - 1s 691us/step - loss: 1.9478 - accuracy: 0.1277 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 49/100\n",
      "955/955 [==============================] - 1s 557us/step - loss: 1.9478 - accuracy: 0.1455 - val_loss: 1.9461 - val_accuracy: 0.1441\n",
      "Epoch 50/100\n",
      "955/955 [==============================] - 0s 504us/step - loss: 1.9481 - accuracy: 0.1204 - val_loss: 1.9461 - val_accuracy: 0.1441\n",
      "Epoch 51/100\n",
      "955/955 [==============================] - 0s 492us/step - loss: 1.9473 - accuracy: 0.1298 - val_loss: 1.9461 - val_accuracy: 0.1351\n",
      "Epoch 52/100\n",
      "955/955 [==============================] - 1s 706us/step - loss: 1.9469 - accuracy: 0.1414 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 53/100\n",
      "955/955 [==============================] - 1s 532us/step - loss: 1.9476 - accuracy: 0.1361 - val_loss: 1.9458 - val_accuracy: 0.1441\n",
      "Epoch 54/100\n",
      "955/955 [==============================] - 1s 898us/step - loss: 1.9468 - accuracy: 0.1173 - val_loss: 1.9462 - val_accuracy: 0.1351\n",
      "Epoch 55/100\n",
      "955/955 [==============================] - 1s 812us/step - loss: 1.9473 - accuracy: 0.1225 - val_loss: 1.9461 - val_accuracy: 0.1441\n",
      "Epoch 56/100\n",
      "955/955 [==============================] - 1s 567us/step - loss: 1.9475 - accuracy: 0.1288 - val_loss: 1.9459 - val_accuracy: 0.1441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "955/955 [==============================] - 1s 699us/step - loss: 1.9474 - accuracy: 0.1267 - val_loss: 1.9463 - val_accuracy: 0.1441\n",
      "Epoch 58/100\n",
      "955/955 [==============================] - 0s 479us/step - loss: 1.9468 - accuracy: 0.1288 - val_loss: 1.9458 - val_accuracy: 0.1441\n",
      "Epoch 59/100\n",
      "955/955 [==============================] - 1s 682us/step - loss: 1.9472 - accuracy: 0.1267 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 60/100\n",
      "955/955 [==============================] - 1s 585us/step - loss: 1.9468 - accuracy: 0.1309 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 61/100\n",
      "955/955 [==============================] - 1s 564us/step - loss: 1.9472 - accuracy: 0.1257 - val_loss: 1.9458 - val_accuracy: 0.1441\n",
      "Epoch 62/100\n",
      "955/955 [==============================] - 1s 637us/step - loss: 1.9470 - accuracy: 0.1309 - val_loss: 1.9461 - val_accuracy: 0.1441\n",
      "Epoch 63/100\n",
      "955/955 [==============================] - 0s 444us/step - loss: 1.9470 - accuracy: 0.1288 - val_loss: 1.9460 - val_accuracy: 0.1441\n",
      "Epoch 64/100\n",
      "955/955 [==============================] - 0s 472us/step - loss: 1.9472 - accuracy: 0.1340 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 65/100\n",
      "955/955 [==============================] - 0s 482us/step - loss: 1.9461 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 66/100\n",
      "955/955 [==============================] - 0s 461us/step - loss: 1.9460 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 67/100\n",
      "955/955 [==============================] - 0s 506us/step - loss: 1.9460 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 68/100\n",
      "955/955 [==============================] - 0s 468us/step - loss: 1.9460 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 69/100\n",
      "955/955 [==============================] - 0s 465us/step - loss: 1.9460 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 70/100\n",
      "955/955 [==============================] - 0s 465us/step - loss: 1.9461 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 71/100\n",
      "955/955 [==============================] - 0s 452us/step - loss: 1.9461 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 72/100\n",
      "955/955 [==============================] - 0s 455us/step - loss: 1.9460 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 73/100\n",
      "955/955 [==============================] - 0s 433us/step - loss: 1.9460 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 74/100\n",
      "955/955 [==============================] - 0s 434us/step - loss: 1.9460 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 75/100\n",
      "955/955 [==============================] - 0s 469us/step - loss: 1.9461 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 76/100\n",
      "955/955 [==============================] - 0s 449us/step - loss: 1.9461 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 77/100\n",
      "955/955 [==============================] - 0s 456us/step - loss: 1.9460 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 78/100\n",
      "955/955 [==============================] - 0s 449us/step - loss: 1.9460 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 79/100\n",
      "955/955 [==============================] - 0s 478us/step - loss: 1.9459 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 80/100\n",
      "955/955 [==============================] - 0s 455us/step - loss: 1.9459 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 81/100\n",
      "955/955 [==============================] - 0s 443us/step - loss: 1.9459 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 82/100\n",
      "955/955 [==============================] - 0s 451us/step - loss: 1.9459 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 83/100\n",
      "955/955 [==============================] - 0s 440us/step - loss: 1.9459 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 84/100\n",
      "955/955 [==============================] - 0s 443us/step - loss: 1.9459 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 85/100\n",
      "955/955 [==============================] - 0s 439us/step - loss: 1.9459 - accuracy: 0.1435 - val_loss: 1.9459 - val_accuracy: 0.1441\n",
      "Epoch 86/100\n",
      "288/955 [========>.....................] - ETA: 0s - loss: 1.9464 - accuracy: 0.1250"
     ]
    }
   ],
   "source": [
    "######### K Fold ##############\n",
    "batch_size = 12\n",
    "EPOCHS = 100\n",
    "    \n",
    "for jindex , (train_idx, val_idx) in enumerate(folds):\n",
    "    print('\\nFold ',jindex)\n",
    "#     print(train_idx)\n",
    "#     print(val_idx)\n",
    "    X_train_cv = X_train.values[train_idx]\n",
    "    y_train_cv = y_train[train_idx]\n",
    "    X_valid_cv = X_train.values[val_idx]\n",
    "    y_valid_cv= y_train[val_idx]\n",
    "    \n",
    "    \n",
    "    name_weights = \"final_model_fold\" + str(jindex) + \"_weights.h5\"\n",
    "    callbacks = get_callbacks(name_weights = name_weights, patience_lr=10)\n",
    "    model = get_model()\n",
    "    \n",
    "    X_traincnn = np.expand_dims(X_train_cv, axis=2)\n",
    "    X_validcnn = np.expand_dims(X_valid_cv, axis=2)\n",
    "\n",
    "    model.fit(  X_traincnn,\n",
    "                y_train_cv,\n",
    "                epochs=EPOCHS,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data = (X_validcnn, y_valid_cv),\n",
    "                callbacks = callbacks\n",
    "             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
