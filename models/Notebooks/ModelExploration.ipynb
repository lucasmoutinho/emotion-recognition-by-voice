{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and program variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split # to split dataset into train and test\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from time_series_dataset_loader import TimeSeriesDatasetLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize_dataset(dataset):\n",
    "    ''' Returns a 1 dimensional representation from the dataset '''\n",
    "    new_dataset = []\n",
    "\n",
    "    for data_instance in dataset:\n",
    "        new_dataset_cell = []\n",
    "        for t_instance in data_instance:\n",
    "            for value in t_instance[2:]:\n",
    "                new_dataset_cell.append(value)\n",
    "\n",
    "        new_dataset.append(new_dataset_cell)\n",
    "    return np.asarray(new_dataset)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(X, y):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    max_len = len(X[0])\n",
    "    for row in X:\n",
    "        if len(row) > max_len:\n",
    "            max_len = len(row)\n",
    "\n",
    "    X = pad_sequences(X, maxlen=max_len, padding='post', dtype='float64')\n",
    "    X = linearize_dataset(X)\n",
    "    return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(128, 5,padding='same', input_shape=(504, 504)))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "#     model.add(Conv1D(64, 5,padding='same'))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(MaxPooling1D(pool_size=(8)))\n",
    "#     model.add(Conv1D(32, 5,padding='same',))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(3))\n",
    "#     model.add(Activation('softmax'))\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(1, 504))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.full(100, 2)\n",
    "b = np.full(2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_VALUES = np.where(y==1)[0]\n",
    "NEUTRAL_VALUES = np.where(y==0)[0]\n",
    "NEGATIVE_VALUES = np.where(y==2)[0][0:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(X, y):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    POSITIVE_VALUES = np.where(y==1)[0]\n",
    "    NEUTRAL_VALUES = np.where(y==0)[0]\n",
    "    NEGATIVE_VALUES = np.where(y==2)[0][0:600]\n",
    "    all_indexes = POSITIVE_VALUES.tolist() + NEUTRAL_VALUES.tolist() + NEGATIVE_VALUES.tolist()\n",
    "    new_y = np.full(len(POSITIVE_VALUES), 1).tolist() \\\n",
    "        + np.full(len(NEUTRAL_VALUES), 0).tolist() \\\n",
    "        + np.full(len(NEGATIVE_VALUES), 2).tolist()\n",
    "    \n",
    "    \n",
    "    return np.take(X, all_indexes), new_y\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[ 0.000000e+00,  0.000000e+00,  6.404657e+00, -1.402514e+00,\n",
       "        -2.236425e+00,  8.194284e-01,  2.850164e+00, -5.242842e+00,\n",
       "         9.194818e+00,  2.701216e-01, -3.601112e+00, -4.030871e-01,\n",
       "        -2.343826e+00,  2.297522e+00,  3.568069e+00,  3.482819e-01],\n",
       "       [ 1.000000e+00,  5.000000e-02,  2.751345e+00, -2.712686e+00,\n",
       "        -4.506105e+00,  2.210746e+00,  5.707813e+00, -3.487714e+00,\n",
       "         1.170016e+01,  6.808586e-01,  2.428516e+00,  3.335083e+00,\n",
       "        -2.458509e+00, -7.786846e-01,  4.941757e+00,  2.185959e+00],\n",
       "       [ 2.000000e+00,  1.000000e-01, -1.635752e-01, -5.268727e+00,\n",
       "        -4.959724e+00,  2.915101e+00,  6.304276e+00, -6.310949e-01,\n",
       "         1.200349e+01,  4.023399e-01,  3.059360e+00,  4.107836e+00,\n",
       "        -4.426288e+00, -8.730631e-01,  4.143346e+00,  2.863602e+00],\n",
       "       [ 3.000000e+00,  1.500000e-01, -2.830689e+00, -4.344458e+00,\n",
       "        -3.053741e+00,  5.715581e+00,  8.206596e+00,  2.755392e+00,\n",
       "         1.075323e+01,  2.223854e-01,  1.420535e+00,  4.286180e+00,\n",
       "        -6.052005e+00,  1.083669e+00,  3.116860e+00,  1.569321e+00],\n",
       "       [ 4.000000e+00,  2.000000e-01, -5.299613e+00,  4.561985e+00,\n",
       "         1.758661e-01,  1.181679e+01,  3.053884e+00,  1.048036e+00,\n",
       "         4.981320e+00, -3.957542e+00, -3.033644e+00, -3.884969e+00,\n",
       "        -4.408713e+00,  1.217579e+00,  1.045349e+00,  3.533859e-01],\n",
       "       [ 5.000000e+00,  2.500000e-01, -6.351640e+00,  1.038501e+01,\n",
       "         4.799002e+00,  1.436675e+01, -3.382558e+00, -4.010645e+00,\n",
       "         5.850177e+00, -2.901974e+00, -4.600304e+00, -7.195258e+00,\n",
       "        -4.656470e-01,  4.048447e+00, -1.138968e+00,  2.081940e+00],\n",
       "       [ 6.000000e+00,  3.000000e-01, -8.431956e+00,  1.233150e+01,\n",
       "         5.332103e+00,  1.444931e+01, -2.999502e+00, -3.567239e+00,\n",
       "         6.023727e+00, -1.416770e+00, -4.639982e+00, -4.974616e+00,\n",
       "         3.320603e-01,  4.998702e+00,  8.051775e-01,  3.098373e+00],\n",
       "       [ 7.000000e+00,  3.500000e-01, -1.258600e+01,  1.327753e+01,\n",
       "         4.916274e+00,  1.394609e+01, -1.051304e+00, -4.299808e-01,\n",
       "         5.034500e+00, -2.656069e-01, -2.313300e+00, -3.306484e+00,\n",
       "         9.781384e-01,  6.841725e+00,  2.595836e+00,  1.325356e+00],\n",
       "       [ 8.000000e+00,  4.000000e-01, -1.781170e+01,  9.786327e+00,\n",
       "         1.067772e+00,  1.292888e+01,  2.976684e+00,  4.943336e+00,\n",
       "         6.629072e+00,  3.532507e+00,  1.719223e+00, -1.549993e+00,\n",
       "         1.881899e+00,  8.299522e+00,  3.277492e+00, -2.476936e+00],\n",
       "       [ 9.000000e+00,  4.500000e-01, -1.994363e+01,  7.402315e+00,\n",
       "        -1.719728e+00,  1.207707e+01,  4.047573e+00,  8.300514e+00,\n",
       "         1.003207e+01,  8.158909e+00,  5.516482e+00,  2.558694e+00,\n",
       "         3.286880e+00,  7.843517e+00,  4.158624e+00, -7.685242e+00],\n",
       "       [ 1.000000e+01,  5.000000e-01, -2.891162e+00,  3.776752e+00,\n",
       "        -6.125561e+00,  6.152779e+00, -3.529166e+00, -4.826010e+00,\n",
       "         1.077337e+00,  1.102542e+01,  6.223758e+00,  7.264008e+00,\n",
       "         2.299340e+00, -1.815099e+00,  1.325483e+00, -2.642601e+00],\n",
       "       [ 1.100000e+01,  5.500000e-01,  1.833347e+00, -3.304969e+00,\n",
       "        -1.157784e+00, -6.680179e-01,  1.568222e+00, -7.073016e+00,\n",
       "         1.992637e+00,  1.146663e+01,  6.038472e+00,  8.085065e+00,\n",
       "         1.627787e+00, -4.445051e+00,  2.208932e+00,  3.119682e+00],\n",
       "       [ 1.200000e+01,  6.000000e-01,  1.648565e+00, -5.119749e+00,\n",
       "        -3.180597e+00, -3.009706e+00,  3.339253e+00, -3.420685e+00,\n",
       "         2.231216e+00,  1.023541e+01,  4.866956e+00,  8.715129e+00,\n",
       "         1.061716e-01, -8.935378e+00,  6.827639e+00,  5.837349e+00],\n",
       "       [ 1.300000e+01,  6.500000e-01,  1.295753e+00, -8.046216e+00,\n",
       "        -6.441458e+00, -5.148137e+00,  5.640388e+00,  2.565567e+00,\n",
       "         2.162398e+00,  6.837421e+00,  2.255552e+00,  7.642087e+00,\n",
       "        -1.032692e+00, -1.469670e+01,  1.113856e+01,  5.533249e+00],\n",
       "       [ 1.400000e+01,  7.000000e-01,  1.333987e+00, -9.661177e+00,\n",
       "        -8.298861e+00, -5.942528e+00,  5.845438e+00,  4.538472e+00,\n",
       "         2.317284e+00,  3.801012e+00, -3.459798e-01,  4.955892e+00,\n",
       "        -2.769881e+00, -1.595915e+01,  1.051995e+01,  3.652008e+00],\n",
       "       [ 1.500000e+01,  7.500000e-01,  3.229073e+00, -6.887894e+00,\n",
       "        -6.838364e+00, -7.842757e+00,  3.118762e+00,  2.070652e+00,\n",
       "         1.828504e+00,  3.328524e-01, -9.732115e-01,  2.516918e+00,\n",
       "        -1.093005e+00, -7.717790e+00,  4.317678e+00,  1.484459e+00],\n",
       "       [ 1.600000e+01,  8.000000e-01,  3.418728e+00, -3.570615e+00,\n",
       "        -3.629475e+00, -1.110313e+01, -5.728242e+00,  2.823098e+00,\n",
       "        -1.914978e-02,  1.367851e+00, -2.762614e+00, -4.243173e+00,\n",
       "         4.097626e+00, -2.347460e-01, -8.697807e-01,  3.257980e-01],\n",
       "       [ 1.700000e+01,  8.500000e-01,  3.377264e+00,  9.345322e-01,\n",
       "        -3.286903e+00, -1.366952e+01, -8.845016e+00,  4.151560e+00,\n",
       "        -2.260908e+00, -6.985159e-01, -5.574957e+00, -8.891518e+00,\n",
       "         5.953523e+00,  1.579793e+00,  3.054122e-01,  1.334610e-01],\n",
       "       [ 1.800000e+01,  9.000000e-01,  2.460085e+00,  5.423792e+00,\n",
       "        -3.087729e+00, -1.331953e+01, -2.493916e-01,  5.529380e-01,\n",
       "        -3.363289e+00, -6.068110e+00, -9.060316e+00, -7.218161e+00,\n",
       "        -1.649683e+00,  2.702949e+00, -1.531171e+00,  6.209335e-01],\n",
       "       [ 1.900000e+01,  9.500000e-01,  5.223818e-01,  3.575822e+00,\n",
       "        -1.036716e+00, -5.777247e+00,  6.339631e+00, -2.831955e+00,\n",
       "        -6.026197e+00, -7.162775e+00, -7.514900e+00, -3.800781e+00,\n",
       "        -5.534005e+00,  7.664485e-01, -2.399730e+00,  1.805466e+00],\n",
       "       [ 2.000000e+01,  1.000000e+00,  2.516867e+00,  4.062219e-01,\n",
       "        -3.889282e+00, -5.209921e+00,  7.165794e+00, -4.194196e+00,\n",
       "        -8.463795e+00, -6.573668e+00, -3.659210e+00,  1.459103e-01,\n",
       "        -4.209296e+00, -2.267303e+00, -6.910979e+00,  2.796463e+00],\n",
       "       [ 2.100000e+01,  1.050000e+00,  5.888969e+00, -2.655813e+00,\n",
       "        -4.890963e+00, -6.193061e+00,  5.158765e+00, -2.572607e+00,\n",
       "        -9.992290e+00, -6.421415e+00, -2.995087e+00,  9.132805e-01,\n",
       "        -2.452879e+00, -5.435419e-01, -9.489441e+00,  2.239647e+00],\n",
       "       [ 2.200000e+01,  1.100000e+00,  6.336985e+00, -3.044483e+00,\n",
       "        -3.870743e+00, -6.268065e+00,  2.027072e+00,  1.000074e+00,\n",
       "        -1.140218e+01, -8.627074e+00, -2.761220e+00,  1.296335e+00,\n",
       "        -2.260105e+00,  4.101367e-01, -9.532392e+00, -5.324402e-01],\n",
       "       [ 2.300000e+01,  1.150000e+00,  4.414243e+00,  2.385785e+00,\n",
       "        -3.309189e+00, -4.759671e+00, -3.218241e-01,  5.510490e+00,\n",
       "        -9.266920e+00, -1.289243e+01, -2.588431e+00, -2.157917e+00,\n",
       "        -2.904792e-01, -9.373226e-01, -6.981112e+00, -4.308372e+00],\n",
       "       [ 2.400000e+01,  1.200000e+00,  4.714633e+00,  2.116967e+00,\n",
       "        -3.943304e+00, -6.258527e+00,  5.735655e-01,  9.311809e+00,\n",
       "        -8.958931e+00, -8.497203e+00,  8.415049e-01, -1.216440e-01,\n",
       "        -2.203896e+00, -7.467661e+00, -3.752697e+00, -4.639717e+00],\n",
       "       [ 2.500000e+01,  1.250000e+00,  4.710360e+00, -4.603683e+00,\n",
       "        -2.523058e+00, -6.952273e+00, -1.677952e+00,  1.035390e+01,\n",
       "        -9.280289e+00,  2.654552e-01,  3.653793e+00,  3.515813e+00,\n",
       "        -5.902366e+00, -7.117290e+00, -3.665266e+00, -2.422195e+00],\n",
       "       [ 2.600000e+01,  1.300000e+00,  4.857491e+00, -6.863629e+00,\n",
       "        -1.308592e+00, -6.195317e+00, -3.534298e-01,  1.141391e+01,\n",
       "        -5.398019e+00,  3.771333e+00,  6.174337e+00,  5.918438e+00,\n",
       "        -6.183857e+00, -4.577327e+00, -4.877527e+00, -1.901573e+00],\n",
       "       [ 2.700000e+01,  1.350000e+00,  5.812518e+00, -6.654972e+00,\n",
       "         5.706301e-01, -4.550348e+00,  2.215951e+00,  1.056224e+01,\n",
       "        -1.835036e+00,  3.845409e+00,  7.737549e+00,  7.225592e+00,\n",
       "        -4.736520e+00, -1.912478e+00, -5.163975e+00, -5.016899e+00],\n",
       "       [ 2.800000e+01,  1.400000e+00,  3.838013e+00, -1.068821e+00,\n",
       "         8.897144e+00,  1.356921e+00, -2.113476e+00, -3.818098e+00,\n",
       "        -4.424283e+00, -1.465292e+00, -2.383439e+00, -1.982038e+00,\n",
       "         1.525156e+00,  4.367843e+00, -4.526542e+00, -6.870827e+00],\n",
       "       [ 2.900000e+01,  1.450000e+00,  5.266762e-01,  2.245167e+00,\n",
       "         1.728628e+01,  5.180499e+00, -1.055137e+01, -7.516167e+00,\n",
       "        -4.780273e+00, -9.289255e-01, -3.646692e+00, -7.814407e+00,\n",
       "         7.810173e+00,  8.792685e+00, -3.574357e+00, -3.296593e+00],\n",
       "       [ 3.000000e+01,  1.500000e+00,  2.735615e-02,  6.517024e-01,\n",
       "         1.583545e+01,  4.202472e+00, -1.332884e+01, -7.516724e+00,\n",
       "        -3.502208e+00, -7.012634e-01, -1.953292e-01, -7.344123e+00,\n",
       "         1.170270e+01,  9.325083e+00, -2.748237e+00, -1.744156e-01],\n",
       "       [ 3.100000e+01,  1.550000e+00,  1.083967e+00, -1.202985e+00,\n",
       "         1.335865e+01,  2.797669e+00, -1.291357e+01, -9.647195e+00,\n",
       "        -2.711038e+00,  4.934864e-01,  3.851619e+00, -5.148983e+00,\n",
       "         1.128119e+01,  8.625434e+00, -5.274107e-01,  1.042191e+00],\n",
       "       [ 3.200000e+01,  1.600000e+00,  3.306693e+00, -2.847978e+00,\n",
       "         1.105512e+01,  1.931636e+00, -9.094209e+00, -1.111582e+01,\n",
       "        -2.127134e+00,  1.869155e+00,  6.862072e+00, -2.445117e+00,\n",
       "         7.591006e+00,  7.077515e+00,  3.393431e+00, -4.487915e-01]]),\n",
       "       array([[  0.        ,   0.        ,   0.8584499 ,  -0.06234932,\n",
       "          0.6381655 ,   2.067782  ,   1.466267  ,  -5.236912  ,\n",
       "         -5.16106   ,   2.806617  ,  -7.93083   ,  -6.261017  ,\n",
       "        -14.80071   ,  -9.692534  ,   2.33831   ,  -1.356331  ],\n",
       "       [  1.        ,   0.05      ,  -1.207735  ,   7.510152  ,\n",
       "         -1.2938    ,   8.459466  ,   0.6622734 ,  -6.250132  ,\n",
       "          2.354074  ,  -5.550307  ,  -6.720773  ,   1.917521  ,\n",
       "         -2.162607  ,   0.07467079,  -0.2530327 ,  -1.541298  ],\n",
       "       [  2.        ,   0.1       ,  -5.552505  ,   9.823504  ,\n",
       "         -2.373136  ,   7.790485  ,   1.842518  ,  -7.585262  ,\n",
       "          1.125608  ,  -7.599536  ,  -8.481077  ,  -0.7221379 ,\n",
       "         -1.047152  ,   0.1912718 ,  -3.607041  ,  -1.32634   ],\n",
       "       [  3.        ,   0.15      ,  -6.946867  ,   7.171237  ,\n",
       "          0.918313  ,   5.650533  ,   2.315489  ,  -0.5013771 ,\n",
       "          4.679728  ,  -3.478522  ,  -6.355207  ,  -2.744469  ,\n",
       "         -1.314259  ,  -1.703808  ,  -3.64396   ,   0.4204483 ],\n",
       "       [  4.        ,   0.2       ,  -5.035713  ,   3.658808  ,\n",
       "          3.762272  ,   0.228538  ,  -0.4992981 ,   4.888617  ,\n",
       "          5.107679  ,  -0.1748552 ,  -2.317669  ,   0.3913496 ,\n",
       "          4.323189  ,   0.3015938 ,   1.386691  ,   1.389038  ],\n",
       "       [  5.        ,   0.25      ,  -1.414188  ,  -1.07897   ,\n",
       "          3.103863  ,  -5.394039  ,   0.7092438 ,  10.39493   ,\n",
       "          0.6285744 ,  -2.426867  ,  -3.338134  ,   2.543783  ,\n",
       "          8.036339  ,   0.06646729,   2.692165  ,  -0.5637283 ],\n",
       "       [  6.        ,   0.3       ,   4.604761  ,  -1.496604  ,\n",
       "         -3.339551  ,  -5.949055  ,   4.794369  ,  16.10473   ,\n",
       "         -4.941151  ,   1.384632  ,  -4.955505  ,   4.364705  ,\n",
       "          4.854179  ,   0.8887796 ,   6.894809  ,  -2.948257  ],\n",
       "       [  7.        ,   0.35      ,   6.083555  ,  -0.8252177 ,\n",
       "         -7.311017  ,  -2.84368   ,   2.587221  ,   9.45497   ,\n",
       "         -1.636492  ,  -2.24916   ,  -4.764758  ,   0.4906845 ,\n",
       "          1.866659  ,   2.108391  ,   6.756481  ,  -3.157578  ],\n",
       "       [  8.        ,   0.4       ,   2.31048   ,  -2.63715   ,\n",
       "          2.496407  ,  -3.552368  ,  -2.052376  ,  -0.2410221 ,\n",
       "          3.55297   ,  -1.709708  ,   1.377667  ,  -0.8652587 ,\n",
       "         -1.053427  ,   0.4588108 ,   1.121365  ,   0.2852325 ],\n",
       "       [  9.        ,   0.45      ,  -1.106804  ,  -4.595172  ,\n",
       "          5.190173  ,  -2.178683  ,  -7.159309  ,  -7.12764   ,\n",
       "          1.272871  ,   3.527918  ,   7.133472  ,   1.003933  ,\n",
       "         -1.516786  ,   1.422666  ,  -1.928174  ,   2.991966  ],\n",
       "       [ 10.        ,   0.5       ,  -2.57995   ,  -8.545055  ,\n",
       "          2.418425  ,  -0.7648621 ,  -5.162403  ,  -7.605551  ,\n",
       "         -1.257978  ,   6.739287  ,  12.01723   ,   5.735229  ,\n",
       "          2.119232  ,   3.664497  ,  -3.753984  ,   3.386604  ],\n",
       "       [ 11.        ,   0.55      ,   0.9452    ,  -8.498287  ,\n",
       "         -1.357975  ,  -0.8932343 ,  -1.359306  ,  -4.93704   ,\n",
       "         -1.944897  ,   7.677544  ,  13.06948   ,   4.190055  ,\n",
       "          2.769464  ,   2.739187  ,  -4.445093  ,   2.225334  ],\n",
       "       [ 12.        ,   0.6       ,   9.041316  ,  -0.4248953 ,\n",
       "         -2.852141  ,  -2.620885  ,   1.855335  ,  -1.358315  ,\n",
       "         -3.779909  ,   1.052965  ,  11.26611   , -10.04438   ,\n",
       "         -2.074109  ,  -0.5199928 ,  -3.558534  ,   0.1948929 ]]),\n",
       "       array([[ 0.000000e+00,  0.000000e+00,  5.846846e+00, -1.007883e+01,\n",
       "        -1.102912e+01, -4.533997e+00,  8.879251e+00, -3.173862e+00,\n",
       "        -4.484479e+00,  3.822571e+00,  4.942968e+00,  7.616708e+00,\n",
       "         6.971733e+00,  6.083839e+00, -1.775110e+00,  2.480362e+00],\n",
       "       [ 1.000000e+00,  5.000000e-02, -6.254740e-01, -1.274459e+01,\n",
       "        -5.428665e+00, -5.168175e+00,  2.672766e+00, -8.041673e+00,\n",
       "        -3.112568e+00,  5.291677e+00,  5.417786e+00,  4.257380e+00,\n",
       "        -2.141714e-02,  3.595017e+00, -1.804691e+00,  6.058281e+00],\n",
       "       [ 2.000000e+00,  1.000000e-01, -2.094105e+00, -1.260675e+01,\n",
       "        -3.259531e+00, -8.073059e+00,  2.974586e-01, -7.904130e+00,\n",
       "        -1.528611e+00,  4.315360e+00,  4.284035e+00,  6.249084e+00,\n",
       "        -1.323022e+00,  4.455402e+00, -2.264643e+00,  7.369217e+00],\n",
       "       [ 3.000000e+00,  1.500000e-01, -1.491084e+00, -1.018062e+01,\n",
       "        -8.827666e-01, -1.014923e+01, -7.994175e-01, -5.943091e+00,\n",
       "        -1.900609e+00, -1.549459e-01,  1.457321e+00,  1.045094e+01,\n",
       "        -1.053158e+00,  5.735393e+00, -1.778615e+00,  5.098854e+00],\n",
       "       [ 4.000000e+00,  2.000000e-01,  1.043661e+00, -4.133790e+00,\n",
       "         7.642652e-01, -6.512465e+00,  2.798491e+00, -1.116080e+00,\n",
       "        -2.437150e+00, -3.601633e+00,  5.570517e+00,  1.749642e+01,\n",
       "        -2.051349e+00,  4.781059e+00,  2.954686e-01, -3.295364e-01],\n",
       "       [ 5.000000e+00,  2.500000e-01,  3.527279e+00, -1.991948e+00,\n",
       "        -7.655859e+00, -1.868111e+00,  7.600403e+00, -1.309851e+01,\n",
       "         1.355502e+00,  5.821505e+00,  1.815621e+01,  9.029414e+00,\n",
       "        -2.415402e+00, -2.549934e-01,  5.747995e+00, -1.793869e+00],\n",
       "       [ 6.000000e+00,  3.000000e-01,  2.136257e+00, -5.987218e+00,\n",
       "        -8.977877e+00, -3.684424e+00,  5.955846e+00, -1.865484e+01,\n",
       "         1.933452e+00,  7.738412e+00,  1.577310e+01,  6.125455e+00,\n",
       "        -1.249001e+00,  1.373721e+00,  5.767600e+00,  1.640167e+00],\n",
       "       [ 7.000000e+00,  3.500000e-01,  2.043152e-02, -8.889640e+00,\n",
       "        -6.304328e+00, -4.561487e+00,  2.213657e+00, -1.829602e+01,\n",
       "         2.773252e+00,  6.939783e+00,  1.500800e+01,  5.314180e+00,\n",
       "         2.345963e-01,  5.632092e+00,  3.583525e+00,  3.070007e+00],\n",
       "       [ 8.000000e+00,  4.000000e-01, -1.415090e+00, -7.851682e+00,\n",
       "         1.062168e-01, -3.512252e+00,  1.897564e+00, -1.494431e+01,\n",
       "         4.781538e+00,  4.066811e+00,  1.289383e+01,  2.732815e+00,\n",
       "         1.686818e+00,  8.340994e+00, -5.501385e-01,  2.239830e+00],\n",
       "       [ 9.000000e+00,  4.500000e-01, -4.068834e+00,  1.825509e-01,\n",
       "         7.921283e+00, -5.810146e-01,  1.050863e+00, -8.096223e+00,\n",
       "         4.835650e+00, -1.859585e+00,  8.280207e+00,  5.566944e-01,\n",
       "         2.686895e+00,  9.307462e+00, -5.665359e+00,  1.092873e+00],\n",
       "       [ 1.000000e+01,  5.000000e-01, -9.801653e+00,  1.156291e+01,\n",
       "         1.357567e+01,  3.811113e+00, -5.335068e+00, -1.018908e+00,\n",
       "         4.205996e+00, -7.178787e+00,  4.260540e+00,  1.186613e+00,\n",
       "         4.025033e+00,  2.411526e+00, -8.034137e+00, -3.258209e-01],\n",
       "       [ 1.100000e+01,  5.500000e-01, -1.247383e+01,  1.616987e+01,\n",
       "         1.201317e+01,  9.809832e+00, -7.832577e+00,  3.960838e-01,\n",
       "         1.882450e+00, -7.253019e+00,  4.264412e+00, -2.580834e+00,\n",
       "         1.061822e+00, -1.572367e+00, -8.001198e+00, -2.055954e+00],\n",
       "       [ 1.200000e+01,  6.000000e-01, -1.363045e+01,  1.856544e+01,\n",
       "         6.756591e+00,  1.195624e+01, -4.795040e+00,  3.361556e+00,\n",
       "         7.239606e-01, -8.193716e+00,  3.794922e+00, -3.543286e+00,\n",
       "         2.795805e+00,  1.791726e+00, -8.358185e+00, -4.624512e+00],\n",
       "       [ 1.300000e+01,  6.500000e-01, -1.511456e+01,  1.429857e+01,\n",
       "         1.140650e+01,  9.014034e+00, -4.613560e+00,  7.314726e+00,\n",
       "         4.479247e+00, -1.055056e+01, -7.039688e+00, -5.013157e+00,\n",
       "         3.475839e+00, -8.761597e-01, -7.699505e+00, -2.263359e+00],\n",
       "       [ 1.400000e+01,  7.000000e-01, -1.277574e+01,  9.579840e+00,\n",
       "         1.213758e+01,  4.641717e+00, -2.856710e+00,  9.216023e+00,\n",
       "         4.556180e+00, -9.860863e+00, -8.384995e+00, -4.071113e+00,\n",
       "         9.205213e-01, -6.091927e+00, -7.963949e+00,  2.262039e-01],\n",
       "       [ 1.500000e+01,  7.500000e-01, -7.482597e+00,  4.113473e+00,\n",
       "         8.732595e+00, -1.294750e+00,  3.199081e-01,  1.231930e+01,\n",
       "         4.219128e+00, -9.054409e+00, -9.015804e+00, -3.591487e+00,\n",
       "        -1.749938e+00, -7.282785e+00, -3.525632e+00, -4.833221e-02],\n",
       "       [ 1.600000e+01,  8.000000e-01,  1.418714e+00, -9.117088e-01,\n",
       "         7.181332e-01, -6.559155e+00,  3.934729e+00,  2.262193e+01,\n",
       "         7.592466e+00, -7.453614e+00, -1.486231e+01, -2.776281e+00,\n",
       "        -3.134912e+00, -2.471769e+00,  5.417361e+00, -3.022026e+00],\n",
       "       [ 1.700000e+01,  8.500000e-01,  9.403349e+00,  3.540454e+00,\n",
       "        -1.635829e+01, -7.678875e+00, -2.080002e+00,  2.499576e+01,\n",
       "         1.327909e+01, -5.521067e+00, -1.617720e+01,  7.856133e+00,\n",
       "        -6.054299e+00,  2.748415e+00,  4.813591e+00, -6.361366e+00],\n",
       "       [ 1.800000e+01,  9.000000e-01,  1.287584e+01,  7.790075e+00,\n",
       "        -2.386563e+01, -4.899630e+00, -8.442879e-02,  1.212626e+01,\n",
       "         7.471477e+00,  3.894335e+00, -1.196215e+01,  6.656970e-02,\n",
       "        -6.375618e+00,  1.111226e+00,  7.113682e+00, -5.168747e+00],\n",
       "       [ 1.900000e+01,  9.500000e-01,  1.419878e+01,  4.447824e+00,\n",
       "        -2.045521e+01,  6.383029e+00, -5.270870e+00,  5.144678e+00,\n",
       "         4.843588e+00,  4.188166e+00, -5.929398e+00, -6.159101e+00,\n",
       "        -8.608695e+00, -9.860172e+00,  8.509896e+00, -3.157539e+00],\n",
       "       [ 2.000000e+01,  1.000000e+00,  1.215371e+01, -7.678442e-01,\n",
       "        -4.545280e+00,  7.543228e+00, -5.598797e+00,  6.619452e+00,\n",
       "        -1.160452e+01,  7.634710e+00, -2.151672e+00, -1.895893e+01,\n",
       "        -5.815458e-01, -1.423357e+01,  4.873300e+00, -9.044952e-01],\n",
       "       [ 2.100000e+01,  1.050000e+00,  8.900246e+00, -5.061556e+00,\n",
       "         1.327096e+01,  8.201841e+00, -1.177473e+00,  5.543232e-01,\n",
       "        -2.086232e+01,  7.678316e+00, -1.185259e+01, -1.857109e+01,\n",
       "         3.085276e+00, -1.244223e+01,  5.952517e+00,  1.978989e-01],\n",
       "       [ 2.200000e+01,  1.100000e+00,  9.448262e+00, -9.044831e+00,\n",
       "         2.135959e+01,  7.715600e+00,  2.822996e+00, -4.382443e+00,\n",
       "        -2.300271e+01,  9.290543e+00, -1.672808e+01, -1.367313e+01,\n",
       "         7.674017e+00, -2.281874e+00,  5.346223e+00,  5.818253e-01]]),\n",
       "       ...,\n",
       "       array([[ 0.000000e+00,  0.000000e+00,  1.299762e+01, -7.800581e+00,\n",
       "        -1.155792e+00,  8.216294e+00, -3.303236e+00,  7.682997e+00,\n",
       "         3.135076e+00, -7.875061e-01,  4.424605e-01, -1.079867e+01,\n",
       "        -2.507576e+00, -7.699791e+00, -2.794294e-01, -5.706299e+00],\n",
       "       [ 1.000000e+00,  5.000000e-02,  1.267458e+01, -5.670663e+00,\n",
       "         6.586325e-01,  1.040101e+01,  1.265907e+00,  9.956731e+00,\n",
       "         3.443951e+00,  1.328724e+00,  1.195805e+00, -8.605493e+00,\n",
       "        -1.286137e+00, -3.829934e+00,  1.806234e+00, -6.983192e+00],\n",
       "       [ 2.000000e+00,  1.000000e-01,  1.351760e+01, -2.027406e+00,\n",
       "        -2.998477e+00,  3.785181e+00,  7.295526e+00,  1.125541e+01,\n",
       "         2.621374e+00,  5.331337e+00,  2.375661e+00,  1.463082e+00,\n",
       "         1.792608e+00, -2.942501e+00,  1.566830e+00, -8.399445e+00],\n",
       "       [ 3.000000e+00,  1.500000e-01,  1.369307e+01, -4.559921e+00,\n",
       "        -1.244487e+01, -6.422823e+00,  1.100411e+01,  6.674817e+00,\n",
       "        -2.184125e+00,  7.051356e+00,  4.234393e+00,  1.438155e+01,\n",
       "         7.749051e+00, -5.499682e+00,  3.095245e+00, -3.473663e+00],\n",
       "       [ 4.000000e+00,  2.000000e-01,  1.162486e+01, -9.165596e+00,\n",
       "        -1.391168e+01, -7.272001e+00,  6.869182e+00,  9.767761e-01,\n",
       "        -4.885321e+00,  5.607419e+00,  6.669850e+00,  1.358183e+01,\n",
       "         3.679538e+00, -6.444601e+00,  1.402631e+00,  1.569496e+00],\n",
       "       [ 5.000000e+00,  2.500000e-01,  1.022867e+01, -1.133897e+01,\n",
       "        -1.204635e+01, -5.618077e+00,  2.722664e+00, -1.518484e+00,\n",
       "        -5.967328e+00,  5.101954e+00,  7.882141e+00,  1.041496e+01,\n",
       "        -1.034615e+00, -6.278322e+00, -7.815361e-02,  2.861038e+00],\n",
       "       [ 6.000000e+00,  3.000000e-01,  8.669609e+00, -1.032271e+01,\n",
       "        -5.366088e+00, -2.922699e+00, -4.011528e+00, -2.778487e+00,\n",
       "        -8.636829e+00,  3.688494e+00,  6.732904e+00,  4.050764e+00,\n",
       "        -3.702798e+00, -4.834160e+00, -6.082115e-01,  1.733955e+00],\n",
       "       [ 7.000000e+00,  3.500000e-01,  5.401073e+00, -4.442240e+00,\n",
       "         3.432132e+00, -7.659445e-01, -7.470314e+00, -2.008650e+00,\n",
       "        -8.764951e+00,  1.588987e+00,  1.249385e+00, -2.918983e+00,\n",
       "        -1.000260e+00, -7.659998e-01,  1.187148e+00, -8.844223e-01],\n",
       "       [ 8.000000e+00,  4.000000e-01,  1.799652e+00,  9.148169e-01,\n",
       "         7.147895e+00,  5.694962e-02, -3.512444e+00,  4.732352e+00,\n",
       "        -6.311916e+00, -5.312490e+00, -3.765055e+00, -4.089112e-01,\n",
       "         2.060251e+00, -1.377735e+00,  8.770690e-01, -2.609329e+00],\n",
       "       [ 9.000000e+00,  4.500000e-01, -5.081844e-01,  7.219992e-01,\n",
       "         8.683036e+00, -1.525134e+00, -8.272205e+00,  4.906499e+00,\n",
       "        -8.360186e-01, -7.766874e+00, -2.604416e+00,  4.173817e+00,\n",
       "         2.764719e+00, -5.228238e+00,  9.533172e-01, -7.568130e-01],\n",
       "       [ 1.000000e+01,  5.000000e-01, -8.140078e-01,  7.117872e-01,\n",
       "         1.070504e+01, -6.762924e-01, -1.093670e+01,  4.219742e+00,\n",
       "         3.078232e+00, -9.745092e+00, -3.499728e+00,  2.368177e+00,\n",
       "         2.334306e+00, -6.314919e+00,  6.787920e-02, -5.929871e-01],\n",
       "       [ 1.100000e+01,  5.500000e-01, -7.838154e-02,  1.549149e+00,\n",
       "         1.297261e+01,  3.504544e+00, -9.434263e+00,  6.231696e+00,\n",
       "         6.955820e+00, -1.008761e+01, -2.822317e+00,  2.663415e+00,\n",
       "         4.039624e+00, -5.147346e+00,  1.700253e-01, -3.553520e+00],\n",
       "       [ 1.200000e+01,  6.000000e-01,  2.094564e+00, -5.441365e-01,\n",
       "         6.000869e+00,  2.983483e+00,  8.112850e-01,  5.046215e+00,\n",
       "         1.773032e+00, -1.016553e+01, -6.092701e+00,  7.712402e+00,\n",
       "         7.099500e+00,  2.937303e-01,  3.242273e-01, -5.180855e+00],\n",
       "       [ 1.300000e+01,  6.500000e-01,  2.995355e+00, -1.602974e-01,\n",
       "         4.273257e+00, -8.079405e-01,  1.897221e+00,  9.430494e-01,\n",
       "        -3.484946e+00, -7.045971e+00, -6.151767e+00,  5.932980e+00,\n",
       "         5.095983e+00,  6.120719e+00,  2.074153e+00, -2.163734e+00],\n",
       "       [ 1.400000e+01,  7.000000e-01,  3.910363e+00, -1.509378e+00,\n",
       "         7.768228e+00, -1.508236e+00, -2.697008e+00, -3.188813e+00,\n",
       "        -2.661397e+00, -1.885860e+00, -7.395550e+00,  2.509760e+00,\n",
       "         4.670280e+00,  5.818507e+00,  1.806085e+00, -1.085228e+00],\n",
       "       [ 1.500000e+01,  7.500000e-01,  4.290634e+00, -1.484030e+00,\n",
       "         1.131376e+01, -1.609439e+00, -7.848928e+00, -8.570424e+00,\n",
       "         1.135004e-01,  4.610119e-01, -6.127135e+00, -2.719760e+00,\n",
       "         2.776326e+00,  4.758434e+00,  2.656588e+00, -2.247490e+00],\n",
       "       [ 1.600000e+01,  8.000000e-01,  3.887327e+00,  1.246817e+00,\n",
       "         9.678663e+00,  9.890890e-01, -8.272795e+00, -5.627378e+00,\n",
       "         1.658088e+00, -3.729788e+00, -4.382107e+00, -1.327675e+00,\n",
       "         1.705589e+00,  5.878848e+00,  2.363520e+00, -3.153648e+00],\n",
       "       [ 1.700000e+01,  8.500000e-01, -1.338971e+00,  8.611798e+00,\n",
       "         4.338630e+00,  3.186669e+00, -7.322168e+00, -2.792568e+00,\n",
       "         2.820513e+00, -7.590004e+00, -2.729248e+00,  2.443702e+00,\n",
       "        -2.130608e+00,  5.729737e+00,  7.555866e-01, -3.577652e+00],\n",
       "       [ 1.800000e+01,  9.000000e-01, -6.841172e+00,  1.402665e+01,\n",
       "         1.854894e+00,  5.935699e+00,  1.344883e+00, -1.077087e+00,\n",
       "         5.171631e+00, -2.259539e+00, -1.329880e+00,  1.867237e-01,\n",
       "        -4.282117e+00,  4.212902e+00, -1.213637e+00, -3.480728e+00],\n",
       "       [ 1.900000e+01,  9.500000e-01, -8.620105e+00,  1.352778e+01,\n",
       "        -4.237095e-01,  7.783484e+00,  7.361017e+00, -1.944260e+00,\n",
       "         5.291409e+00,  3.352991e+00, -1.280666e+00, -6.065149e+00,\n",
       "        -5.683342e+00,  4.740727e+00, -1.138349e+00, -2.826050e+00],\n",
       "       [ 2.000000e+01,  1.000000e+00, -6.168962e+00,  1.033633e+01,\n",
       "         1.770458e+00,  7.446901e+00,  4.019135e+00, -3.791456e+00,\n",
       "         6.247962e+00,  3.602751e+00, -1.917828e+00, -7.857438e+00,\n",
       "        -5.095466e+00,  4.192759e+00, -8.061743e-01, -1.458618e+00],\n",
       "       [ 2.100000e+01,  1.050000e+00, -1.980401e+00,  4.988502e+00,\n",
       "         6.813494e+00,  2.764163e+00, -8.931580e-01, -2.966694e+00,\n",
       "         3.881588e+00,  3.967323e-01, -3.466514e+00, -1.042819e+01,\n",
       "        -6.334924e+00,  4.630661e-02, -7.117764e+00, -1.201439e+00],\n",
       "       [ 2.200000e+01,  1.100000e+00,  3.420639e-02,  2.740746e+00,\n",
       "         7.678679e+00, -2.171326e-01, -1.057476e+00,  1.379465e+00,\n",
       "         9.774866e-01, -1.670498e+00, -5.720144e+00, -9.034373e+00,\n",
       "        -4.538585e+00, -3.900803e+00, -1.194015e+01, -1.823883e+00],\n",
       "       [ 2.300000e+01,  1.150000e+00, -4.997479e+00,  8.802898e+00,\n",
       "         6.635468e-01,  3.050837e+00,  3.480312e+00,  4.027392e+00,\n",
       "         1.645908e+00, -1.251274e+00, -5.528600e+00, -5.049874e+00,\n",
       "        -3.887040e+00, -3.961172e+00, -8.398059e+00, -1.440041e+00],\n",
       "       [ 2.400000e+01,  1.200000e+00, -1.340226e+01,  1.010936e+01,\n",
       "        -1.844666e+00,  4.815857e+00,  1.035882e+01,  5.550742e+00,\n",
       "         3.548830e+00, -9.770069e-01, -3.979568e+00, -4.268156e+00,\n",
       "        -4.119382e+00,  2.304710e+00, -2.662990e+00, -3.422318e-01],\n",
       "       [ 2.500000e+01,  1.250000e+00, -1.809563e+01,  7.453935e+00,\n",
       "        -3.914923e+00,  3.869412e+00,  1.027006e+01,  3.937196e+00,\n",
       "         4.191253e+00,  2.108152e+00,  1.913838e+00,  9.236059e-01,\n",
       "         3.297265e+00,  8.193863e+00,  4.682031e-01,  5.758209e-01],\n",
       "       [ 2.600000e+01,  1.300000e+00, -1.388061e+01,  7.401251e+00,\n",
       "        -8.596609e+00, -1.054597e+00,  1.874146e+00, -6.652049e+00,\n",
       "         1.223391e+00,  8.869561e+00,  1.077617e+01,  3.113920e+00,\n",
       "         4.034035e+00,  1.104557e+01,  3.063217e+00,  3.275749e+00],\n",
       "       [ 2.700000e+01,  1.350000e+00, -7.968896e+00,  1.185911e+00,\n",
       "        -1.220635e+01, -1.612302e+00, -5.399853e+00, -1.075501e+01,\n",
       "         1.330426e+00,  8.810844e+00,  1.022712e+01, -5.676317e-01,\n",
       "        -2.801199e+00,  6.496567e+00,  1.899698e+00,  5.970009e+00],\n",
       "       [ 2.800000e+01,  1.400000e+00, -2.854481e+00, -7.942556e+00,\n",
       "        -9.502566e+00, -2.649796e+00, -7.207548e+00, -6.771199e+00,\n",
       "         2.454553e+00,  1.223730e+01,  8.465316e+00, -2.493765e+00,\n",
       "        -2.422551e+00,  2.961381e+00,  4.063067e-01,  6.940323e+00],\n",
       "       [ 2.900000e+01,  1.450000e+00, -8.950872e-01, -1.113028e+01,\n",
       "        -5.502191e+00, -6.630816e+00, -4.230955e+00, -7.593402e+00,\n",
       "         2.191353e+00,  1.249633e+01,  1.737440e+00, -4.606661e+00,\n",
       "        -3.545900e+00,  1.538509e+00, -7.822046e-01,  6.861633e+00],\n",
       "       [ 3.000000e+01,  1.500000e+00, -6.573489e+00, -2.258643e+00,\n",
       "        -2.755533e+00, -7.489910e+00, -6.164951e-01, -5.701644e+00,\n",
       "         2.901202e+00,  1.106719e+01,  3.793749e+00, -5.541097e+00,\n",
       "         2.315845e+00,  4.158903e+00,  2.307106e+00,  8.046410e+00],\n",
       "       [ 3.100000e+01,  1.550000e+00, -1.213700e+01,  1.530657e+00,\n",
       "         3.082984e+00, -6.876955e+00,  2.642994e+00, -5.319118e-01,\n",
       "        -1.582525e+00,  2.514582e+00,  4.954663e+00, -2.913961e+00,\n",
       "        -1.104640e+00,  3.492985e-01,  4.898266e+00,  7.041199e+00],\n",
       "       [ 3.200000e+01,  1.600000e+00, -9.578609e+00, -1.723151e-01,\n",
       "         1.035738e+00, -5.123735e+00,  6.691150e+00,  1.121582e+00,\n",
       "        -6.965693e+00, -6.650837e+00,  1.900483e+00, -1.233507e+00,\n",
       "        -3.884108e+00, -7.097244e+00,  2.252572e+00,  7.273430e+00],\n",
       "       [ 3.300000e+01,  1.650000e+00, -1.162702e+00, -4.187408e+00,\n",
       "        -4.895255e+00, -4.655124e+00,  6.828745e+00, -1.421013e-01,\n",
       "        -6.960996e+00, -8.195940e+00,  4.646482e-01,  1.532429e+00,\n",
       "         4.802461e-01, -6.639919e+00,  2.021043e+00,  5.749367e+00],\n",
       "       [ 3.400000e+01,  1.700000e+00,  6.823691e+00, -6.840636e+00,\n",
       "        -8.534575e+00, -4.401054e-01,  4.432486e+00, -2.725763e-01,\n",
       "        -4.753369e+00, -7.132914e+00, -8.370943e-01,  6.240864e+00,\n",
       "         6.760006e-01, -3.233466e-01, -1.650244e+00,  1.955925e+00],\n",
       "       [ 3.500000e+01,  1.750000e+00,  3.253564e+00, -4.302593e+00,\n",
       "        -3.772908e+00, -2.910494e+00,  1.317356e+00, -3.958453e+00,\n",
       "        -2.661175e+00, -3.361052e+00, -5.385724e+00,  3.145336e+00,\n",
       "         2.790079e+00, -5.558000e-01, -1.747546e+00,  3.087212e+00]]),\n",
       "       array([[ 0.000000e+00,  0.000000e+00,  3.280588e+00,  2.007889e+00,\n",
       "        -2.019495e+00, -2.305276e+00,  6.614293e+00,  5.461595e+00,\n",
       "         6.093031e+00,  3.689784e+00,  1.122280e+01,  3.314852e+00,\n",
       "        -1.936963e+00,  4.901731e+00,  2.333452e+00,  1.625908e+00],\n",
       "       [ 1.000000e+00,  5.000000e-02,  4.610037e+00,  2.953304e+00,\n",
       "        -6.601028e-01, -3.320723e+00,  6.109126e+00,  6.112799e+00,\n",
       "         5.025781e+00,  2.919614e+00,  8.682760e+00,  1.728273e+00,\n",
       "        -1.918189e+00,  4.556925e+00,  2.336957e+00,  5.009567e+00],\n",
       "       [ 2.000000e+00,  1.000000e-01,  4.730622e+00,  3.065429e+00,\n",
       "         2.559048e+00, -3.164366e+00,  4.209465e+00,  6.348255e+00,\n",
       "         5.090338e+00,  7.126389e-01,  4.633312e+00,  1.581058e+00,\n",
       "        -2.305800e+00,  1.037056e+00,  3.425694e+00,  4.312340e+00],\n",
       "       [ 3.000000e+00,  1.500000e-01,  1.710743e+00,  1.954243e+00,\n",
       "         8.954997e+00, -6.619644e-02,  7.193956e-01,  3.316816e+00,\n",
       "         6.871360e+00, -2.455844e+00, -1.410356e+00,  7.467027e-01,\n",
       "        -2.376689e+00, -3.724712e+00,  3.616010e+00,  1.417633e+00],\n",
       "       [ 4.000000e+00,  2.000000e-01,  9.957361e-01, -4.470717e+00,\n",
       "         7.975132e+00,  2.154689e+00,  2.581562e+00,  7.184248e-01,\n",
       "         3.277793e+00, -4.384149e+00, -6.670331e+00,  1.099323e+00,\n",
       "        -2.622247e+00, -4.614510e+00,  2.588925e+00,  1.272964e-01],\n",
       "       [ 5.000000e+00,  2.500000e-01,  4.338546e+00, -1.023062e+01,\n",
       "         2.781860e+00, -5.062100e+00,  1.287508e-01, -1.131289e+00,\n",
       "        -3.215615e+00, -3.354719e+00, -1.521402e+01,  3.600895e+00,\n",
       "        -5.275388e+00, -5.947177e-01,  2.045411e+00, -2.290787e+00],\n",
       "       [ 6.000000e+00,  3.000000e-01,  6.924177e+00, -9.499638e+00,\n",
       "        -4.402046e-01, -1.308367e+01,  2.151942e+00,  1.012295e+00,\n",
       "        -7.486098e+00, -4.101729e+00, -1.825118e+01,  1.117563e+00,\n",
       "        -7.269697e+00,  4.453414e+00, -1.001025e+00, -6.051399e+00],\n",
       "       [ 7.000000e+00,  3.500000e-01,  7.354035e+00, -8.550712e+00,\n",
       "         4.085164e-01, -1.869727e+01,  5.398205e+00,  3.555428e+00,\n",
       "        -4.249330e+00, -7.607069e+00, -1.498887e+01, -3.754495e+00,\n",
       "        -2.975214e+00,  3.641089e+00, -1.050831e+00, -7.324638e+00],\n",
       "       [ 8.000000e+00,  4.000000e-01,  6.008067e+00, -1.068285e+01,\n",
       "        -2.619638e-01, -1.938913e+01,  3.813110e+00,  3.558660e-01,\n",
       "        -7.152826e+00, -7.733994e+00, -1.585602e+01, -3.149769e+00,\n",
       "        -5.003298e+00,  1.214535e+00, -9.055200e-01, -6.759598e+00],\n",
       "       [ 9.000000e+00,  4.500000e-01,  3.949959e+00, -1.015594e+01,\n",
       "         8.327863e-01, -1.370480e+01,  1.248145e+00, -5.077506e+00,\n",
       "        -8.575542e+00, -4.254401e+00, -1.308529e+01,  5.583906e-02,\n",
       "        -5.145602e+00, -6.850154e-01, -1.123981e+00, -3.411652e+00],\n",
       "       [ 1.000000e+01,  5.000000e-01,  2.838041e+00, -8.593061e+00,\n",
       "         4.891103e+00, -7.920717e+00, -6.573925e-01, -4.977150e+00,\n",
       "        -4.982995e+00,  2.589159e-01, -5.043706e+00, -7.249355e-02,\n",
       "        -1.453887e+00,  6.708491e-01,  4.442624e-01,  1.869431e-01],\n",
       "       [ 1.100000e+01,  5.500000e-01,  2.579984e+00, -7.223343e+00,\n",
       "         7.219419e+00, -1.855332e+00, -1.994852e+00, -2.441989e+00,\n",
       "        -3.464940e+00,  2.912132e+00,  2.397713e+00, -2.042680e+00,\n",
       "        -8.374984e-01,  1.679263e+00,  3.108204e+00,  1.830048e+00],\n",
       "       [ 1.200000e+01,  6.000000e-01,  3.049538e+00, -7.213940e+00,\n",
       "         7.685555e+00,  2.079709e+00,  7.773352e-01,  9.698753e-01,\n",
       "        -5.009959e+00,  2.761375e+00,  4.716300e+00, -4.280349e+00,\n",
       "        -2.939547e+00,  1.329970e+00,  4.662945e+00,  8.493652e-01],\n",
       "       [ 1.300000e+01,  6.500000e-01,  3.658533e-01, -3.255597e+00,\n",
       "         4.201855e+00,  4.047935e+00,  5.464283e+00, -5.003295e-01,\n",
       "        -5.302011e+00, -2.278000e+00,  6.866396e+00, -7.483058e+00,\n",
       "        -5.520298e+00,  1.319766e+00,  3.334137e+00, -1.143661e+00],\n",
       "       [ 1.400000e+01,  7.000000e-01, -5.375958e+00,  4.288651e+00,\n",
       "        -2.578580e+00,  6.714412e+00,  9.049825e+00, -2.436483e+00,\n",
       "        -7.653985e-01, -5.079749e+00,  5.812111e+00, -7.865107e+00,\n",
       "        -6.341338e+00, -4.146626e-01, -1.158506e+00, -3.255737e+00],\n",
       "       [ 1.500000e+01,  7.500000e-01, -6.335418e+00,  8.691884e+00,\n",
       "        -3.003217e+00,  8.805676e+00,  9.500635e+00, -2.970823e+00,\n",
       "         7.640770e+00, -2.479982e-01,  3.132776e+00, -2.568457e+00,\n",
       "         2.783779e+00,  6.361222e-01, -3.039975e+00, -3.999481e+00],\n",
       "       [ 1.600000e+01,  8.000000e-01, -1.306115e+00,  4.187445e+00,\n",
       "         4.012108e-03,  5.051296e+00, -5.039940e-01, -5.365389e+00,\n",
       "         6.096383e+00,  4.347904e+00,  5.585048e+00, -3.713850e-01,\n",
       "         5.937232e+00,  5.939033e+00,  3.604013e-01,  1.377213e+00],\n",
       "       [ 1.700000e+01,  8.500000e-01,  1.014261e+00,  1.646190e+00,\n",
       "         3.091939e+00, -5.026340e-02, -2.819047e+00, -5.839900e+00,\n",
       "         2.479297e+00,  6.166021e+00,  4.819429e+00,  1.059197e+00,\n",
       "         4.475551e+00,  5.053603e+00,  8.150148e-01,  4.945236e+00],\n",
       "       [ 1.800000e+01,  9.000000e-01,  1.439800e+00, -4.885740e-01,\n",
       "         5.596954e+00, -5.750854e+00, -4.227522e+00, -7.090294e+00,\n",
       "         1.571550e+00,  6.400562e+00,  3.344094e+00,  2.049398e+00,\n",
       "         3.357518e+00,  4.341860e+00,  1.200697e+00,  4.783684e+00],\n",
       "       [ 1.900000e+01,  9.500000e-01,  1.248411e+00, -2.538493e+00,\n",
       "         7.733252e+00, -1.060729e+01, -6.507811e+00, -5.989391e+00,\n",
       "         3.664442e+00,  7.976703e+00,  1.280704e+00,  5.062644e+00,\n",
       "         2.674244e+00,  5.541800e+00, -5.765543e-01,  3.122543e+00],\n",
       "       [ 2.000000e+01,  1.000000e+00, -3.525591e-01,  3.439541e-01,\n",
       "         5.394447e+00, -4.628975e+00, -7.791925e+00, -2.247876e+00,\n",
       "         4.302351e+00,  9.947073e+00,  4.801163e+00,  5.756580e+00,\n",
       "         2.973719e+00,  3.951429e+00, -1.023879e+00,  2.361794e+00],\n",
       "       [ 2.100000e+01,  1.050000e+00, -1.894629e+00,  8.844471e-01,\n",
       "        -6.775584e-01,  2.705577e+00, -3.477370e+00,  4.208717e-01,\n",
       "         1.458671e+00,  4.933321e+00,  6.868095e+00,  5.390275e+00,\n",
       "         3.813168e+00,  2.753609e+00, -1.822170e+00, -5.605316e-01],\n",
       "       [ 2.200000e+01,  1.100000e+00,  1.534637e+00, -8.495784e-01,\n",
       "        -1.085739e+01,  9.256654e-01,  1.090053e+00,  4.082426e+00,\n",
       "        -1.810347e+00, -2.163914e+00,  2.013868e+00,  3.275402e+00,\n",
       "         3.499800e+00,  1.255800e+00, -1.815416e+00, -4.790649e-01],\n",
       "       [ 2.300000e+01,  1.150000e+00,  5.084320e+00, -3.549710e+00,\n",
       "        -1.169258e+01, -4.838528e+00,  8.425579e-01,  3.953296e+00,\n",
       "        -6.492162e+00, -4.848547e+00,  7.408290e-01,  2.015392e+00,\n",
       "         1.149178e+00, -1.339634e+00, -2.989705e+00,  5.687714e-01],\n",
       "       [ 2.400000e+01,  1.200000e+00,  6.284238e+00, -7.441742e+00,\n",
       "        -7.125967e+00, -9.500652e+00,  1.460051e+00,  6.366506e-01,\n",
       "        -7.209004e+00, -7.443142e+00,  2.978811e-01, -7.414721e-01,\n",
       "        -2.105565e-01, -4.581076e+00, -2.918530e+00, -7.862778e-01],\n",
       "       [ 2.500000e+01,  1.250000e+00,  3.433711e+00, -4.668900e+00,\n",
       "        -3.296765e+00, -6.397757e+00, -1.584032e+00, -4.396052e-01,\n",
       "        -7.000700e+00, -8.167397e+00, -2.744099e+00, -1.169026e+00,\n",
       "        -3.225399e+00, -7.355790e+00, -9.024637e-01, -3.979485e+00],\n",
       "       [ 2.600000e+01,  1.300000e+00, -4.789762e+00,  1.005252e+01,\n",
       "        -2.455899e+00,  5.142554e+00, -7.623205e+00,  6.916947e-01,\n",
       "        -3.151796e+00, -9.207882e+00, -2.533426e+00, -2.684004e+00,\n",
       "        -6.155887e+00, -8.659451e+00,  1.394836e+00, -6.323952e+00],\n",
       "       [ 2.700000e+01,  1.350000e+00, -1.092695e+01,  1.360512e+01,\n",
       "        -3.148869e+00,  1.508747e+01,  2.118464e-01, -5.143213e-01,\n",
       "        -7.546563e-01, -3.261597e+00,  3.541421e+00, -5.801540e+00,\n",
       "        -2.913980e+00, -4.019450e+00,  9.583580e-01, -5.390060e+00],\n",
       "       [ 2.800000e+01,  1.400000e+00, -1.357162e+01,  1.061474e+01,\n",
       "        -4.428567e+00,  1.729148e+01,  4.948570e+00,  3.740074e+00,\n",
       "         5.581162e+00,  4.416142e+00,  7.880468e+00, -4.687521e+00,\n",
       "        -1.465175e-01, -2.950695e+00,  5.687736e-01, -3.035812e+00],\n",
       "       [ 2.900000e+01,  1.450000e+00, -7.999425e+00,  1.205780e+01,\n",
       "        -3.822482e+00,  1.324194e+01, -6.314192e-01,  8.018417e-01,\n",
       "         7.400041e+00,  5.488921e+00,  7.240514e+00,  2.597899e+00,\n",
       "         6.716479e+00, -2.076591e+00, -4.096329e-01,  1.234406e+00],\n",
       "       [ 3.000000e+01,  1.500000e+00, -3.440541e+00,  1.013623e+01,\n",
       "        -3.318697e+00,  8.663715e+00, -2.811501e+00,  1.912668e+00,\n",
       "         6.878794e+00,  2.242453e+00,  4.294793e+00,  5.311829e+00,\n",
       "         7.393218e+00, -4.132070e+00, -1.167134e+00,  3.665459e+00],\n",
       "       [ 3.100000e+01,  1.550000e+00, -4.376745e-01,  4.462037e+00,\n",
       "        -1.339957e+00,  2.764825e+00, -2.767907e+00,  3.354187e+00,\n",
       "         3.054719e+00, -8.213968e-01,  1.811969e+00,  4.618962e+00,\n",
       "         7.493162e+00, -4.326797e+00, -2.724164e+00,  3.887444e+00],\n",
       "       [ 3.200000e+01,  1.600000e+00, -1.281213e+00, -8.571267e-01,\n",
       "        -1.369448e+00,  7.953496e-01, -7.722698e+00,  1.128603e+00,\n",
       "        -2.181754e+00, -7.395744e-01, -4.397469e+00,  1.786699e+00,\n",
       "         5.224711e+00, -1.910985e+00, -5.140984e+00,  3.444885e+00],\n",
       "       [ 3.300000e+01,  1.650000e+00, -5.161908e+00,  2.489346e+00,\n",
       "        -1.214012e+00,  7.602111e+00, -9.112789e+00, -7.279153e-01,\n",
       "         1.718016e-01,  1.883538e+00, -2.955574e+00, -1.914961e+00,\n",
       "         4.657105e+00, -1.002028e+00, -3.889411e+00,  3.959457e+00],\n",
       "       [ 3.400000e+01,  1.700000e+00, -6.874249e+00,  4.036053e+00,\n",
       "         5.968187e-01,  1.517628e+01, -4.424620e+00, -1.716918e+00,\n",
       "         8.318210e-01,  5.894529e+00,  1.373458e+00, -1.667600e+00,\n",
       "         2.118543e+00, -9.162109e-01, -3.416486e-01,  3.371651e+00],\n",
       "       [ 3.500000e+01,  1.750000e+00, -3.027234e+00,  2.793270e+00,\n",
       "        -6.215965e+00,  1.209318e+01, -1.661035e+00,  8.935232e-01,\n",
       "         1.315057e+00,  5.199453e+00, -2.075872e-01, -1.914863e+00,\n",
       "         2.306578e+00, -9.734643e-01,  8.074539e-01,  2.710060e+00]]),\n",
       "       array([[ 0.000000e+00,  0.000000e+00,  5.084667e+00, -3.900648e+00,\n",
       "         1.228177e+01, -1.630181e+01,  5.691862e+00, -8.010381e+00,\n",
       "        -1.162919e+01,  2.157566e+00, -1.037307e+01, -7.081485e+00,\n",
       "        -8.257961e+00, -5.524247e+00,  2.769801e+00, -4.748123e+00],\n",
       "       [ 1.000000e+00,  5.000000e-02,  3.391902e+00, -2.526249e+00,\n",
       "         1.336192e+01, -9.863092e+00,  1.035079e+01, -2.473780e+00,\n",
       "        -1.264575e+01, -6.746888e-01, -1.045684e+01, -7.924012e+00,\n",
       "        -8.490755e+00, -3.764352e+00,  4.266841e+00, -3.798294e+00],\n",
       "       [ 2.000000e+00,  1.000000e-01,  5.013605e+00, -6.165528e-01,\n",
       "         9.571754e+00, -1.065381e+01,  1.115551e+01,  4.148189e+00,\n",
       "        -1.174793e+01,  1.239343e+00, -4.368771e+00, -2.575191e+00,\n",
       "        -7.062873e+00, -3.121142e+00,  2.461480e+00, -3.263245e-01],\n",
       "       [ 3.000000e+00,  1.500000e-01,  6.871203e+00, -6.076112e+00,\n",
       "        -1.691694e-01, -8.864969e+00,  1.448600e+01,  1.860507e+00,\n",
       "        -7.404469e+00,  2.675481e+00,  6.627164e-01, -3.416784e-01,\n",
       "        -3.268691e+00, -2.627574e+00,  2.719522e-01,  4.524574e+00],\n",
       "       [ 4.000000e+00,  2.000000e-01,  8.159369e+00, -9.735591e+00,\n",
       "        -6.922956e+00, -4.042626e+00,  1.376143e+01, -3.339358e+00,\n",
       "        -1.580311e+00,  9.653568e-03,  5.321056e+00, -2.811618e+00,\n",
       "        -9.125237e-01, -3.074891e+00,  1.265077e+00,  7.117058e+00],\n",
       "       [ 5.000000e+00,  2.500000e-01,  7.876379e+00, -1.248983e+01,\n",
       "        -8.986116e+00, -2.308144e+00,  8.828362e+00, -5.772265e+00,\n",
       "         4.289542e-01, -2.066788e+00,  8.753088e+00, -6.212353e+00,\n",
       "         5.314841e-01, -2.464946e+00,  2.078827e+00,  7.294380e+00],\n",
       "       [ 6.000000e+00,  3.000000e-01,  6.337461e+00, -1.448049e+01,\n",
       "        -5.788671e+00, -3.524310e+00,  2.889658e+00, -6.928007e+00,\n",
       "         1.250908e+00,  5.991526e-01,  7.956854e+00, -6.485589e+00,\n",
       "         1.152932e+00, -2.634621e+00,  1.432527e+00,  5.387230e+00],\n",
       "       [ 7.000000e+00,  3.500000e-01,  4.966063e+00, -1.418719e+01,\n",
       "         2.390258e+00, -7.645205e+00, -1.412885e+00, -6.933643e+00,\n",
       "         1.236617e+00,  3.551743e+00, -1.291142e-01, -3.090936e+00,\n",
       "        -4.081779e-01, -2.087658e+00, -4.675813e-01,  2.243622e+00],\n",
       "       [ 8.000000e+00,  4.000000e-01,  3.419584e+00, -1.398411e+01,\n",
       "         4.596488e+00, -9.351862e+00, -2.258168e+00, -6.596361e+00,\n",
       "         5.027653e-01,  3.125347e+00, -7.663674e+00, -8.950372e-01,\n",
       "        -5.838952e-01,  1.473856e-01, -3.153684e+00, -4.328156e-02],\n",
       "       [ 9.000000e+00,  4.500000e-01,  4.296906e+00, -9.022501e+00,\n",
       "         3.317506e+00, -2.494053e+00,  9.526501e-01, -6.400430e+00,\n",
       "         1.664298e+00,  4.085291e+00, -5.453633e+00, -3.926527e+00,\n",
       "        -4.185858e-01, -1.268754e+00, -4.152355e+00, -1.085167e+00],\n",
       "       [ 1.000000e+01,  5.000000e-01,  5.232111e+00, -3.970423e+00,\n",
       "         2.166435e+00, -1.595621e+00, -4.672572e+00, -6.231866e+00,\n",
       "         1.735891e+00,  3.793719e+00, -5.032039e-01,  5.021102e-01,\n",
       "         4.008319e-01,  4.060225e-01, -3.774992e+00, -7.558060e-01],\n",
       "       [ 1.100000e+01,  5.500000e-01,  3.950395e+00, -4.331872e+00,\n",
       "         4.464592e+00, -4.152252e+00, -9.397294e+00, -2.855999e+00,\n",
       "        -9.987836e-01,  3.228487e+00, -2.825124e+00,  5.700388e+00,\n",
       "        -1.356093e+00,  8.460283e-01, -2.977059e+00,  3.801575e-01],\n",
       "       [ 1.200000e+01,  6.000000e-01,  2.051536e+00, -2.393487e+00,\n",
       "         6.368906e+00, -3.784381e+00, -1.033509e+01, -7.476425e-02,\n",
       "        -3.905299e+00,  1.297913e-01, -4.479096e+00,  7.942852e+00,\n",
       "        -2.310003e+00,  1.305475e-01, -1.570013e+00, -1.450455e+00],\n",
       "       [ 1.300000e+01,  6.500000e-01,  1.765015e+00,  3.734331e+00,\n",
       "         4.814396e+00,  2.482878e+00, -3.341689e+00,  1.009271e+00,\n",
       "        -2.105268e+00, -5.750007e+00, -1.450627e+00,  7.333683e+00,\n",
       "         1.498316e+00, -2.083883e-01, -2.446373e-01, -1.368980e+00],\n",
       "       [ 1.400000e+01,  7.000000e-01,  2.490279e+00,  1.937252e+00,\n",
       "         4.659576e+00,  9.295311e-01, -3.554805e+00, -9.604959e-01,\n",
       "        -1.850643e-01, -3.930717e+00, -3.641514e+00,  7.655667e+00,\n",
       "         2.953693e+00,  1.316378e+00, -3.265212e-01,  2.891312e+00],\n",
       "       [ 1.500000e+01,  7.500000e-01,  3.220990e+00, -2.200227e+00,\n",
       "         7.006304e+00, -3.151610e+00, -5.209516e+00, -2.446331e+00,\n",
       "         2.239571e+00, -2.813620e+00, -3.661608e+00,  1.109444e+01,\n",
       "         1.432293e+00,  3.433943e+00,  8.367649e-01,  5.171577e+00],\n",
       "       [ 1.600000e+01,  8.000000e-01,  3.183296e+00, -6.358535e+00,\n",
       "         7.167288e+00, -6.409301e+00, -5.520923e+00, -5.612994e+00,\n",
       "         4.711753e+00, -8.173795e-01, -1.694463e+00,  1.149300e+01,\n",
       "         2.104884e+00,  6.484472e+00, -1.776600e-02,  4.723824e+00],\n",
       "       [ 1.700000e+01,  8.500000e-01, -8.038101e-01, -5.487481e+00,\n",
       "        -2.506263e+00, -2.595930e+00, -1.088824e+01, -5.510915e+00,\n",
       "         1.233379e+00,  4.906042e+00,  9.467983e-02,  6.737303e+00,\n",
       "         2.716759e+00,  6.033970e+00,  5.955420e-01,  3.292152e+00],\n",
       "       [ 1.800000e+01,  9.000000e-01, -4.116486e+00, -8.291953e-01,\n",
       "        -1.181824e+01,  2.500948e+00, -9.439580e+00, -6.461745e+00,\n",
       "        -3.126683e+00,  6.421629e+00,  2.183299e+00, -2.687389e+00,\n",
       "         1.212111e+00,  3.804100e+00, -1.631485e+00,  9.631348e-01],\n",
       "       [ 1.900000e+01,  9.500000e-01, -7.077532e+00,  6.669843e+00,\n",
       "        -1.540234e+01,  5.714830e+00, -2.260249e+00, -8.043937e+00,\n",
       "        -5.321068e+00,  3.853475e+00,  4.006973e+00, -7.879478e+00,\n",
       "        -1.365542e+00,  2.650313e+00, -3.452298e+00, -2.999458e+00],\n",
       "       [ 2.000000e+01,  1.000000e+00, -9.099253e+00,  1.261674e+01,\n",
       "        -3.952316e+00,  9.929367e+00,  2.363962e+00, -2.322739e+00,\n",
       "        -1.723273e+00, -4.361530e+00,  1.662904e+00, -1.468149e+00,\n",
       "         1.582227e-01,  2.406905e+00,  2.290625e+00, -6.085999e+00],\n",
       "       [ 2.100000e+01,  1.050000e+00, -6.294907e+00,  9.497888e+00,\n",
       "         6.548543e+00,  3.862099e+00, -3.339810e+00,  1.493759e+00,\n",
       "        -3.991230e-01, -9.990705e+00, -9.272709e-01,  3.237086e+00,\n",
       "         1.814914e-01,  2.103017e+00,  2.706413e+00, -5.777061e+00],\n",
       "       [ 2.200000e+01,  1.100000e+00, -2.583170e+00,  4.036081e+00,\n",
       "         1.244264e+01, -4.303747e+00, -4.094596e+00,  3.032502e+00,\n",
       "        -4.565630e+00, -8.855831e+00, -4.818042e+00,  8.251396e+00,\n",
       "        -3.258636e+00,  1.647943e+00,  3.371660e+00, -7.245186e+00],\n",
       "       [ 2.300000e+01,  1.150000e+00, -5.881721e+00,  8.915332e+00,\n",
       "         4.603776e+00, -4.439240e-01, -8.880420e+00,  7.365546e+00,\n",
       "        -1.034312e+01, -9.285040e+00, -3.853548e+00,  5.563003e+00,\n",
       "        -5.319413e+00, -3.654160e+00,  3.123787e+00, -8.890442e+00],\n",
       "       [ 2.400000e+01,  1.200000e+00, -1.094587e+01,  1.441205e+01,\n",
       "        -6.824198e+00,  1.138953e+01, -1.841006e+00,  2.751530e+00,\n",
       "        -6.506525e+00, -8.079466e+00, -3.964734e-01, -1.038721e+00,\n",
       "        -2.710835e+00, -2.920802e+00, -2.835127e+00, -9.023750e+00],\n",
       "       [ 2.500000e+01,  1.250000e+00, -1.479447e+01,  1.145894e+01,\n",
       "        -9.316057e+00,  1.943808e+01,  6.404454e+00,  6.211810e+00,\n",
       "         2.332131e+00, -2.992611e+00, -4.607692e-01,  3.106315e-01,\n",
       "         3.009553e+00, -9.536123e-01, -2.474815e+00, -7.462135e+00],\n",
       "       [ 2.600000e+01,  1.300000e+00, -1.611781e+01,  8.659938e+00,\n",
       "        -9.549042e+00,  2.074416e+01,  8.849479e+00,  1.049974e+01,\n",
       "         7.605494e+00,  1.793574e+00,  2.189338e+00,  3.643579e+00,\n",
       "         8.223176e+00,  2.755101e+00,  1.004258e+00, -6.744995e+00],\n",
       "       [ 2.700000e+01,  1.350000e+00, -6.463537e+00,  1.088183e+01,\n",
       "        -1.207117e+01,  1.016182e+01, -1.654506e+00,  7.645013e+00,\n",
       "         7.582842e+00,  6.428802e+00,  2.961309e+00, -2.416244e+00,\n",
       "         2.858685e+00, -6.496959e-01, -1.166963e+00, -1.369568e+00],\n",
       "       [ 2.800000e+01,  1.400000e+00, -1.361389e+00,  5.186924e+00,\n",
       "        -1.126782e+01,  5.303277e+00, -4.570483e+00,  9.601618e+00,\n",
       "         6.196736e+00,  6.955698e+00,  1.707090e+00, -5.428201e+00,\n",
       "         2.461488e+00, -9.933825e-01, -1.615217e+00,  3.073380e+00],\n",
       "       [ 2.900000e+01,  1.450000e+00,  8.376417e-01, -1.640803e+00,\n",
       "        -8.766354e+00, -5.832253e-01, -5.010734e+00,  8.109160e+00,\n",
       "         7.674318e+00,  5.143814e+00,  1.591082e+00, -6.146700e+00,\n",
       "         2.011054e+00, -2.112285e+00, -1.245568e+00,  4.693649e+00],\n",
       "       [ 3.000000e+01,  1.500000e+00,  1.898831e+00, -7.467563e+00,\n",
       "        -5.627963e+00, -8.191564e+00, -4.070685e+00,  1.794339e+00,\n",
       "         1.106059e+01, -3.002033e-01,  5.088638e+00, -7.574659e+00,\n",
       "         3.408479e+00, -3.394583e+00, -9.205170e-01,  3.160141e+00],\n",
       "       [ 3.100000e+01,  1.550000e+00,  9.528456e-01, -1.191570e+00,\n",
       "        -3.349776e+00, -4.053800e+00, -5.038630e+00,  3.884680e+00,\n",
       "         1.158174e+01,  2.128292e+00,  6.638189e+00, -2.657486e+00,\n",
       "         2.333632e+00, -1.999410e+00, -9.532578e-01,  1.378181e+00],\n",
       "       [ 3.200000e+01,  1.600000e+00, -2.008759e+00,  1.215857e+01,\n",
       "         2.395504e+00,  4.146913e+00,  2.620277e-01,  4.543902e+00,\n",
       "         1.308204e+01,  1.010379e+00,  7.577281e+00,  2.328170e+00,\n",
       "         2.448519e+00,  3.937850e+00,  8.719261e-01,  8.366165e-01],\n",
       "       [ 3.300000e+01,  1.650000e+00, -2.374943e+00,  1.262967e+01,\n",
       "         8.212144e+00,  1.092783e+01,  5.277147e+00,  3.234326e+00,\n",
       "         7.398341e+00, -1.184532e+00,  3.978679e+00, -1.871227e+00,\n",
       "         2.235882e+00,  5.447501e+00,  1.205760e+00,  2.864693e+00],\n",
       "       [ 3.400000e+01,  1.700000e+00,  1.692106e+00,  5.461215e+00,\n",
       "         4.407621e+00,  8.573931e+00,  8.002596e+00,  4.245056e+00,\n",
       "         1.115135e+00, -1.143800e+00,  4.097564e+00, -1.592227e+00,\n",
       "         1.499487e+00,  6.703157e-01,  2.448564e-01,  4.853378e+00],\n",
       "       [ 3.500000e+01,  1.750000e+00,  7.231378e+00, -5.366183e+00,\n",
       "         1.541014e+00, -1.789984e+00,  7.515955e+00,  5.545043e+00,\n",
       "        -6.446022e+00, -9.903274e-01,  6.860962e-01,  3.116157e-01,\n",
       "         8.909800e-01, -7.672844e-01,  2.181755e+00,  4.326027e+00]])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take(X, all_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../../datasets/Original/MFCC_5'\n",
    "# DATASET_PATH = \"../../../Output/?MFCC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = TimeSeriesDatasetLoader(DATASET_PATH)\n",
    "X, y = dataset_loader.get_dataset(type_='emotion_type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = balance_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocessing_data(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pandas_profiling import ProfileReport\n",
    "#df = pd.DataFrame(y)\n",
    "#profile = ProfileReport(df, title='Pandas Profiling Report', html={'style':{'full_width':True}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def run_classifier(classifier, params, X_train, X_test, y_train, y_test):\n",
    "    clf = GridSearchCV(classifier, params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.918021</td>\n",
       "      <td>0.011732</td>\n",
       "      <td>0.179412</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.567545</td>\n",
       "      <td>0.012179</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.190753</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.200017</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1, 'kernel': 'poly'}</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.198328</td>\n",
       "      <td>0.018286</td>\n",
       "      <td>0.204275</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.574930</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.964225</td>\n",
       "      <td>0.101805</td>\n",
       "      <td>0.226343</td>\n",
       "      <td>0.084557</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 1, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.571226</td>\n",
       "      <td>0.012223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.004677</td>\n",
       "      <td>0.067317</td>\n",
       "      <td>0.186636</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 2, 'kernel': 'linear'}</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533129</td>\n",
       "      <td>0.030699</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.201000</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.202591</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>2</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 2, 'kernel': 'poly'}</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.561728</td>\n",
       "      <td>0.550382</td>\n",
       "      <td>0.017573</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.190722</td>\n",
       "      <td>0.007260</td>\n",
       "      <td>0.223443</td>\n",
       "      <td>0.041259</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 2, 'kernel': 'rbf'}</td>\n",
       "      <td>0.533742</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.541725</td>\n",
       "      <td>0.023074</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.904399</td>\n",
       "      <td>0.032901</td>\n",
       "      <td>0.168921</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 2, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.549118</td>\n",
       "      <td>0.029526</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.899812</td>\n",
       "      <td>0.018234</td>\n",
       "      <td>0.174158</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 4, 'kernel': 'linear'}</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.472938</td>\n",
       "      <td>0.032661</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.246636</td>\n",
       "      <td>0.063273</td>\n",
       "      <td>0.207967</td>\n",
       "      <td>0.011058</td>\n",
       "      <td>4</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 4, 'kernel': 'poly'}</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.549148</td>\n",
       "      <td>0.016938</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.901161</td>\n",
       "      <td>0.369562</td>\n",
       "      <td>0.315651</td>\n",
       "      <td>0.066980</td>\n",
       "      <td>4</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 4, 'kernel': 'rbf'}</td>\n",
       "      <td>0.533742</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.546012</td>\n",
       "      <td>0.475309</td>\n",
       "      <td>0.531872</td>\n",
       "      <td>0.030087</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.491129</td>\n",
       "      <td>0.251646</td>\n",
       "      <td>0.268487</td>\n",
       "      <td>0.055901</td>\n",
       "      <td>4</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 4, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>0.509202</td>\n",
       "      <td>0.533742</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.520866</td>\n",
       "      <td>0.019042</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.752786</td>\n",
       "      <td>0.222342</td>\n",
       "      <td>0.326547</td>\n",
       "      <td>0.063302</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 5, 'kernel': 'linear'}</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.474157</td>\n",
       "      <td>0.023843</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.413301</td>\n",
       "      <td>0.261144</td>\n",
       "      <td>0.395890</td>\n",
       "      <td>0.047618</td>\n",
       "      <td>5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 5, 'kernel': 'poly'}</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.549148</td>\n",
       "      <td>0.016938</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.010759</td>\n",
       "      <td>0.279791</td>\n",
       "      <td>0.322688</td>\n",
       "      <td>0.060023</td>\n",
       "      <td>5</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 5, 'kernel': 'rbf'}</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.546012</td>\n",
       "      <td>0.475309</td>\n",
       "      <td>0.533099</td>\n",
       "      <td>0.030263</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.193987</td>\n",
       "      <td>0.154715</td>\n",
       "      <td>0.244455</td>\n",
       "      <td>0.046518</td>\n",
       "      <td>5</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 5, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.483996</td>\n",
       "      <td>0.016134</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.469735</td>\n",
       "      <td>0.080108</td>\n",
       "      <td>0.280897</td>\n",
       "      <td>0.086651</td>\n",
       "      <td>6</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 6, 'kernel': 'linear'}</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.476611</td>\n",
       "      <td>0.027101</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.348181</td>\n",
       "      <td>0.085485</td>\n",
       "      <td>0.239253</td>\n",
       "      <td>0.040468</td>\n",
       "      <td>6</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 6, 'kernel': 'poly'}</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.549148</td>\n",
       "      <td>0.016938</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.353063</td>\n",
       "      <td>0.115755</td>\n",
       "      <td>0.207972</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>6</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 6, 'kernel': 'rbf'}</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.546012</td>\n",
       "      <td>0.475309</td>\n",
       "      <td>0.533099</td>\n",
       "      <td>0.030263</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.901622</td>\n",
       "      <td>0.044202</td>\n",
       "      <td>0.167656</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>6</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 6, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.488874</td>\n",
       "      <td>0.034384</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.993822</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>0.178352</td>\n",
       "      <td>0.010851</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 8, 'kernel': 'linear'}</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.455760</td>\n",
       "      <td>0.017568</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.302947</td>\n",
       "      <td>0.080364</td>\n",
       "      <td>0.227889</td>\n",
       "      <td>0.026413</td>\n",
       "      <td>8</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 8, 'kernel': 'poly'}</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.549148</td>\n",
       "      <td>0.016938</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.299495</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>0.213756</td>\n",
       "      <td>0.008601</td>\n",
       "      <td>8</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 8, 'kernel': 'rbf'}</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.546012</td>\n",
       "      <td>0.475309</td>\n",
       "      <td>0.533099</td>\n",
       "      <td>0.030263</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.894349</td>\n",
       "      <td>0.054561</td>\n",
       "      <td>0.156924</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>8</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 8, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.413580</td>\n",
       "      <td>0.469219</td>\n",
       "      <td>0.038758</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.026305</td>\n",
       "      <td>0.082988</td>\n",
       "      <td>0.191734</td>\n",
       "      <td>0.030195</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.401235</td>\n",
       "      <td>0.439756</td>\n",
       "      <td>0.028252</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.248385</td>\n",
       "      <td>0.067603</td>\n",
       "      <td>0.204822</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 10, 'kernel': 'poly'}</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.549148</td>\n",
       "      <td>0.016938</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.263303</td>\n",
       "      <td>0.038617</td>\n",
       "      <td>0.229485</td>\n",
       "      <td>0.032135</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.546012</td>\n",
       "      <td>0.475309</td>\n",
       "      <td>0.533099</td>\n",
       "      <td>0.030263</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.895142</td>\n",
       "      <td>0.068605</td>\n",
       "      <td>0.173090</td>\n",
       "      <td>0.021267</td>\n",
       "      <td>10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 10, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.490798</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.458214</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.918021      0.011732         0.179412        0.002756       1   \n",
       "1        1.190753      0.006494         0.200017        0.001381       1   \n",
       "2        1.198328      0.018286         0.204275        0.000383       1   \n",
       "3        0.964225      0.101805         0.226343        0.084557       1   \n",
       "4        1.004677      0.067317         0.186636        0.008729       2   \n",
       "5        1.201000      0.003233         0.202591        0.000857       2   \n",
       "6        1.190722      0.007260         0.223443        0.041259       2   \n",
       "7        0.904399      0.032901         0.168921        0.002514       2   \n",
       "8        0.899812      0.018234         0.174158        0.001787       4   \n",
       "9        1.246636      0.063273         0.207967        0.011058       4   \n",
       "10       1.901161      0.369562         0.315651        0.066980       4   \n",
       "11       1.491129      0.251646         0.268487        0.055901       4   \n",
       "12       1.752786      0.222342         0.326547        0.063302       5   \n",
       "13       2.413301      0.261144         0.395890        0.047618       5   \n",
       "14       2.010759      0.279791         0.322688        0.060023       5   \n",
       "15       1.193987      0.154715         0.244455        0.046518       5   \n",
       "16       1.469735      0.080108         0.280897        0.086651       6   \n",
       "17       1.348181      0.085485         0.239253        0.040468       6   \n",
       "18       1.353063      0.115755         0.207972        0.006337       6   \n",
       "19       0.901622      0.044202         0.167656        0.006916       6   \n",
       "20       0.993822      0.055885         0.178352        0.010851       8   \n",
       "21       1.302947      0.080364         0.227889        0.026413       8   \n",
       "22       1.299495      0.079929         0.213756        0.008601       8   \n",
       "23       0.894349      0.054561         0.156924        0.004893       8   \n",
       "24       1.026305      0.082988         0.191734        0.030195      10   \n",
       "25       1.248385      0.067603         0.204822        0.006408      10   \n",
       "26       1.263303      0.038617         0.229485        0.032135      10   \n",
       "27       0.895142      0.068605         0.173090        0.021267      10   \n",
       "\n",
       "   param_kernel                          params  split0_test_score  \\\n",
       "0        linear    {'C': 1, 'kernel': 'linear'}           0.570552   \n",
       "1          poly      {'C': 1, 'kernel': 'poly'}           0.576687   \n",
       "2           rbf       {'C': 1, 'kernel': 'rbf'}           0.582822   \n",
       "3       sigmoid   {'C': 1, 'kernel': 'sigmoid'}           0.582822   \n",
       "4        linear    {'C': 2, 'kernel': 'linear'}           0.496933   \n",
       "5          poly      {'C': 2, 'kernel': 'poly'}           0.570552   \n",
       "6           rbf       {'C': 2, 'kernel': 'rbf'}           0.533742   \n",
       "7       sigmoid   {'C': 2, 'kernel': 'sigmoid'}           0.503067   \n",
       "8        linear    {'C': 4, 'kernel': 'linear'}           0.435583   \n",
       "9          poly      {'C': 4, 'kernel': 'poly'}           0.570552   \n",
       "10          rbf       {'C': 4, 'kernel': 'rbf'}           0.533742   \n",
       "11      sigmoid   {'C': 4, 'kernel': 'sigmoid'}           0.503067   \n",
       "12       linear    {'C': 5, 'kernel': 'linear'}           0.460123   \n",
       "13         poly      {'C': 5, 'kernel': 'poly'}           0.570552   \n",
       "14          rbf       {'C': 5, 'kernel': 'rbf'}           0.539877   \n",
       "15      sigmoid   {'C': 5, 'kernel': 'sigmoid'}           0.484663   \n",
       "16       linear    {'C': 6, 'kernel': 'linear'}           0.460123   \n",
       "17         poly      {'C': 6, 'kernel': 'poly'}           0.570552   \n",
       "18          rbf       {'C': 6, 'kernel': 'rbf'}           0.539877   \n",
       "19      sigmoid   {'C': 6, 'kernel': 'sigmoid'}           0.484663   \n",
       "20       linear    {'C': 8, 'kernel': 'linear'}           0.435583   \n",
       "21         poly      {'C': 8, 'kernel': 'poly'}           0.570552   \n",
       "22          rbf       {'C': 8, 'kernel': 'rbf'}           0.539877   \n",
       "23      sigmoid   {'C': 8, 'kernel': 'sigmoid'}           0.503067   \n",
       "24       linear   {'C': 10, 'kernel': 'linear'}           0.423313   \n",
       "25         poly     {'C': 10, 'kernel': 'poly'}           0.570552   \n",
       "26          rbf      {'C': 10, 'kernel': 'rbf'}           0.539877   \n",
       "27      sigmoid  {'C': 10, 'kernel': 'sigmoid'}           0.460123   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.576687           0.582822           0.558282   \n",
       "1            0.576687           0.570552           0.570552   \n",
       "2            0.576687           0.570552           0.576687   \n",
       "3            0.582822           0.570552           0.570552   \n",
       "4            0.576687           0.539877           0.552147   \n",
       "5            0.521472           0.558282           0.539877   \n",
       "6            0.576687           0.552147           0.539877   \n",
       "7            0.588957           0.564417           0.558282   \n",
       "8            0.472393           0.484663           0.527607   \n",
       "9            0.521472           0.558282           0.539877   \n",
       "10           0.564417           0.539877           0.546012   \n",
       "11           0.552147           0.509202           0.533742   \n",
       "12           0.496933           0.472393           0.503067   \n",
       "13           0.521472           0.558282           0.539877   \n",
       "14           0.564417           0.539877           0.546012   \n",
       "15           0.478528           0.496933           0.503067   \n",
       "16           0.496933           0.472393           0.515337   \n",
       "17           0.521472           0.558282           0.539877   \n",
       "18           0.564417           0.539877           0.546012   \n",
       "19           0.521472           0.478528           0.527607   \n",
       "20           0.447853           0.466258           0.484663   \n",
       "21           0.521472           0.558282           0.539877   \n",
       "22           0.564417           0.539877           0.546012   \n",
       "23           0.447853           0.460123           0.521472   \n",
       "24           0.435583           0.453988           0.484663   \n",
       "25           0.521472           0.558282           0.539877   \n",
       "26           0.564417           0.539877           0.546012   \n",
       "27           0.441718           0.453988           0.490798   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.549383         0.567545        0.012179                4  \n",
       "1            0.574074         0.573711        0.002750                2  \n",
       "2            0.567901         0.574930        0.005235                1  \n",
       "3            0.549383         0.571226        0.012223                3  \n",
       "4            0.500000         0.533129        0.030699               13  \n",
       "5            0.561728         0.550382        0.017573                5  \n",
       "6            0.506173         0.541725        0.023074               12  \n",
       "7            0.530864         0.549118        0.029526               11  \n",
       "8            0.444444         0.472938        0.032661               24  \n",
       "9            0.555556         0.549148        0.016938                6  \n",
       "10           0.475309         0.531872        0.030087               18  \n",
       "11           0.506173         0.520866        0.019042               19  \n",
       "12           0.438272         0.474157        0.023843               23  \n",
       "13           0.555556         0.549148        0.016938                6  \n",
       "14           0.475309         0.533099        0.030263               14  \n",
       "15           0.456790         0.483996        0.016134               21  \n",
       "16           0.438272         0.476611        0.027101               22  \n",
       "17           0.555556         0.549148        0.016938                6  \n",
       "18           0.475309         0.533099        0.030263               14  \n",
       "19           0.432099         0.488874        0.034384               20  \n",
       "20           0.444444         0.455760        0.017568               27  \n",
       "21           0.555556         0.549148        0.016938                6  \n",
       "22           0.475309         0.533099        0.030263               14  \n",
       "23           0.413580         0.469219        0.038758               25  \n",
       "24           0.401235         0.439756        0.028252               28  \n",
       "25           0.555556         0.549148        0.016938                6  \n",
       "26           0.475309         0.533099        0.030263               14  \n",
       "27           0.444444         0.458214        0.017578               26  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SVM ###\n",
    "\n",
    "params = {'kernel':['linear', 'poly', 'rbf', 'sigmoid'], 'C':[1, 2, 4,5, 6, 8, 10]}\n",
    "svc = svm.SVC()\n",
    "run_classifier(svc, params, X_train, X_test, y_train, y_test)\n",
    "\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "numpy.linalg.LinAlgError: the leading minor of order 649 of 'b' is not positive definite. The factorization of 'b' could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "numpy.linalg.LinAlgError: the leading minor of order 649 of 'b' is not positive definite. The factorization of 'b' could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "numpy.linalg.LinAlgError: the leading minor of order 649 of 'b' is not positive definite. The factorization of 'b' could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "numpy.linalg.LinAlgError: the leading minor of order 649 of 'b' is not positive definite. The factorization of 'b' could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "numpy.linalg.LinAlgError: the leading minor of order 651 of 'b' is not positive definite. The factorization of 'b' could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_shrinkage</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.084682</td>\n",
       "      <td>0.088733</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>None</td>\n",
       "      <td>svd</td>\n",
       "      <td>{'shrinkage': None, 'solver': 'svd'}</td>\n",
       "      <td>0.288344</td>\n",
       "      <td>0.392638</td>\n",
       "      <td>0.368098</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.364849</td>\n",
       "      <td>0.045217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.833917</td>\n",
       "      <td>1.151447</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>None</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>{'shrinkage': None, 'solver': 'lsqr'}</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.325153</td>\n",
       "      <td>0.263804</td>\n",
       "      <td>0.392638</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.324184</td>\n",
       "      <td>0.080597</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.591358</td>\n",
       "      <td>0.089739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>eigen</td>\n",
       "      <td>{'shrinkage': None, 'solver': 'eigen'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008084</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>svd</td>\n",
       "      <td>{'shrinkage': 'auto', 'solver': 'svd'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.992485</td>\n",
       "      <td>1.727315</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>auto</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>{'shrinkage': 'auto', 'solver': 'lsqr'}</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.453261</td>\n",
       "      <td>0.024628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.889251</td>\n",
       "      <td>0.180846</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>auto</td>\n",
       "      <td>eigen</td>\n",
       "      <td>{'shrinkage': 'auto', 'solver': 'eigen'}</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.453261</td>\n",
       "      <td>0.024628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.084682      0.088733         0.002409        0.001058   \n",
       "1       5.833917      1.151447         0.004631        0.003137   \n",
       "2       0.591358      0.089739         0.000000        0.000000   \n",
       "3       0.008084      0.004810         0.000000        0.000000   \n",
       "4       6.992485      1.727315         0.003526        0.003073   \n",
       "5       6.889251      0.180846         0.005418        0.003099   \n",
       "\n",
       "  param_shrinkage param_solver                                    params  \\\n",
       "0            None          svd      {'shrinkage': None, 'solver': 'svd'}   \n",
       "1            None         lsqr     {'shrinkage': None, 'solver': 'lsqr'}   \n",
       "2            None        eigen    {'shrinkage': None, 'solver': 'eigen'}   \n",
       "3            auto          svd    {'shrinkage': 'auto', 'solver': 'svd'}   \n",
       "4            auto         lsqr   {'shrinkage': 'auto', 'solver': 'lsqr'}   \n",
       "5            auto        eigen  {'shrinkage': 'auto', 'solver': 'eigen'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.288344           0.392638           0.368098           0.423313   \n",
       "1           0.429448           0.325153           0.263804           0.392638   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4           0.472393           0.466258           0.472393           0.447853   \n",
       "5           0.472393           0.466258           0.472393           0.447853   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.351852         0.364849        0.045217                3  \n",
       "1           0.209877         0.324184        0.080597                4  \n",
       "2                NaN              NaN             NaN                5  \n",
       "3                NaN              NaN             NaN                6  \n",
       "4           0.407407         0.453261        0.024628                1  \n",
       "5           0.407407         0.453261        0.024628                1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LDA ###\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "params = {'solver':['svd', 'lsqr', 'eigen'], 'shrinkage':[None, 'auto']}\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "run_classifier(clf, params, X_train, X_test, y_train, y_test)\n",
    "\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_algorithm</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.124693</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.591481</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 3, 'weigh...</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.422586</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.138771</td>\n",
       "      <td>0.015725</td>\n",
       "      <td>0.610776</td>\n",
       "      <td>0.027561</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 3, 'weigh...</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.443475</td>\n",
       "      <td>0.025302</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.109826</td>\n",
       "      <td>0.009184</td>\n",
       "      <td>0.588145</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 5, 'weigh...</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.125234</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.612433</td>\n",
       "      <td>0.029198</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 5, 'weigh...</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.464341</td>\n",
       "      <td>0.032151</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.108043</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.603692</td>\n",
       "      <td>0.034382</td>\n",
       "      <td>auto</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 7, 'weigh...</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.509202</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.450617</td>\n",
       "      <td>0.463130</td>\n",
       "      <td>0.033959</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.109389</td>\n",
       "      <td>0.008818</td>\n",
       "      <td>0.560888</td>\n",
       "      <td>0.084907</td>\n",
       "      <td>auto</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 7, 'weigh...</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.498750</td>\n",
       "      <td>0.020514</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.129217</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>0.614088</td>\n",
       "      <td>0.030427</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 10, 'weig...</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.512346</td>\n",
       "      <td>0.512285</td>\n",
       "      <td>0.039091</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.126126</td>\n",
       "      <td>0.015401</td>\n",
       "      <td>0.604699</td>\n",
       "      <td>0.041975</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 10, 'weig...</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.514716</td>\n",
       "      <td>0.027606</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.114662</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>0.617581</td>\n",
       "      <td>0.043277</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 50, 'weig...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.571249</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.118660</td>\n",
       "      <td>0.015374</td>\n",
       "      <td>0.616354</td>\n",
       "      <td>0.066527</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 50, 'weig...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.571249</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.113293</td>\n",
       "      <td>0.012425</td>\n",
       "      <td>0.616517</td>\n",
       "      <td>0.037586</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 100, 'wei...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.120982</td>\n",
       "      <td>0.020959</td>\n",
       "      <td>0.606287</td>\n",
       "      <td>0.039739</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 100, 'wei...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.086721</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>0.467512</td>\n",
       "      <td>0.022199</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 3, '...</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.422586</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.091579</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>0.474808</td>\n",
       "      <td>0.036834</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 3, '...</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.443475</td>\n",
       "      <td>0.025302</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.088821</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.451975</td>\n",
       "      <td>0.011146</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 5, '...</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.090264</td>\n",
       "      <td>0.013446</td>\n",
       "      <td>0.465146</td>\n",
       "      <td>0.014568</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 5, '...</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.464341</td>\n",
       "      <td>0.032151</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.095353</td>\n",
       "      <td>0.009525</td>\n",
       "      <td>0.454957</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 7, '...</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.509202</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.450617</td>\n",
       "      <td>0.463130</td>\n",
       "      <td>0.033959</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.080915</td>\n",
       "      <td>0.016637</td>\n",
       "      <td>0.393219</td>\n",
       "      <td>0.038817</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 7, '...</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.498750</td>\n",
       "      <td>0.020514</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.093757</td>\n",
       "      <td>0.010167</td>\n",
       "      <td>0.445190</td>\n",
       "      <td>0.040089</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 10, ...</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.512346</td>\n",
       "      <td>0.512285</td>\n",
       "      <td>0.039091</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.088232</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>0.434748</td>\n",
       "      <td>0.015263</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 10, ...</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.514716</td>\n",
       "      <td>0.027606</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.093919</td>\n",
       "      <td>0.010202</td>\n",
       "      <td>0.466723</td>\n",
       "      <td>0.023325</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 50, ...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.571249</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.010609</td>\n",
       "      <td>0.453635</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 50, ...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.571249</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.088215</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.456629</td>\n",
       "      <td>0.029048</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 100,...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.110205</td>\n",
       "      <td>0.031365</td>\n",
       "      <td>0.496191</td>\n",
       "      <td>0.040197</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 100,...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.113865</td>\n",
       "      <td>0.009784</td>\n",
       "      <td>0.578525</td>\n",
       "      <td>0.019624</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 3, 'we...</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.422586</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.124167</td>\n",
       "      <td>0.012032</td>\n",
       "      <td>0.597784</td>\n",
       "      <td>0.037478</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 3, 'we...</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.443475</td>\n",
       "      <td>0.025302</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.109469</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.595614</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 5, 'we...</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.116436</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.584011</td>\n",
       "      <td>0.059592</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 5, 'we...</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.464341</td>\n",
       "      <td>0.032151</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.109423</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.564797</td>\n",
       "      <td>0.044040</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 7, 'we...</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.509202</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.450617</td>\n",
       "      <td>0.463130</td>\n",
       "      <td>0.033959</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.118157</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>0.590760</td>\n",
       "      <td>0.063712</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 7, 'we...</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.498750</td>\n",
       "      <td>0.020514</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.107562</td>\n",
       "      <td>0.018630</td>\n",
       "      <td>0.569754</td>\n",
       "      <td>0.019149</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 10, 'w...</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.512346</td>\n",
       "      <td>0.512285</td>\n",
       "      <td>0.039091</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.118645</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>0.591263</td>\n",
       "      <td>0.029867</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 10, 'w...</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.514716</td>\n",
       "      <td>0.027606</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.107339</td>\n",
       "      <td>0.010704</td>\n",
       "      <td>0.598070</td>\n",
       "      <td>0.046343</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 50, 'w...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.571249</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.115027</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.588542</td>\n",
       "      <td>0.022765</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 50, 'w...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.571249</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.108419</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>0.577011</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 100, '...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.114503</td>\n",
       "      <td>0.005613</td>\n",
       "      <td>0.607822</td>\n",
       "      <td>0.025866</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 100, '...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.011564</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.075276</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>brute</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 3, 'weig...</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.422586</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.049835</td>\n",
       "      <td>0.014694</td>\n",
       "      <td>brute</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 3, 'weig...</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.443475</td>\n",
       "      <td>0.025302</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.008530</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.066960</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>brute</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 5, 'weig...</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.009320</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>brute</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 5, 'weig...</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.521472</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.464341</td>\n",
       "      <td>0.032151</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.010631</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.070820</td>\n",
       "      <td>0.012089</td>\n",
       "      <td>brute</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 7, 'weig...</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.509202</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.450617</td>\n",
       "      <td>0.463130</td>\n",
       "      <td>0.033959</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.011487</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.040679</td>\n",
       "      <td>0.007314</td>\n",
       "      <td>brute</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 7, 'weig...</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.498750</td>\n",
       "      <td>0.020514</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.013580</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.071991</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>brute</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 10, 'wei...</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.512346</td>\n",
       "      <td>0.512285</td>\n",
       "      <td>0.039091</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.045112</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>brute</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 10, 'wei...</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.527607</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.514716</td>\n",
       "      <td>0.027606</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.072723</td>\n",
       "      <td>0.029066</td>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 50, 'wei...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.571249</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.011055</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.044726</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 50, 'wei...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.571249</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.080056</td>\n",
       "      <td>0.013744</td>\n",
       "      <td>brute</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 100, 'we...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.013603</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.051343</td>\n",
       "      <td>0.009104</td>\n",
       "      <td>brute</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 100, 'we...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.124693      0.006563         0.591481        0.011307   \n",
       "1        0.138771      0.015725         0.610776        0.027561   \n",
       "2        0.109826      0.009184         0.588145        0.025714   \n",
       "3        0.125234      0.013917         0.612433        0.029198   \n",
       "4        0.108043      0.005275         0.603692        0.034382   \n",
       "5        0.109389      0.008818         0.560888        0.084907   \n",
       "6        0.129217      0.011712         0.614088        0.030427   \n",
       "7        0.126126      0.015401         0.604699        0.041975   \n",
       "8        0.114662      0.010740         0.617581        0.043277   \n",
       "9        0.118660      0.015374         0.616354        0.066527   \n",
       "10       0.113293      0.012425         0.616517        0.037586   \n",
       "11       0.120982      0.020959         0.606287        0.039739   \n",
       "12       0.086721      0.012567         0.467512        0.022199   \n",
       "13       0.091579      0.008351         0.474808        0.036834   \n",
       "14       0.088821      0.005325         0.451975        0.011146   \n",
       "15       0.090264      0.013446         0.465146        0.014568   \n",
       "16       0.095353      0.009525         0.454957        0.017202   \n",
       "17       0.080915      0.016637         0.393219        0.038817   \n",
       "18       0.093757      0.010167         0.445190        0.040089   \n",
       "19       0.088232      0.004809         0.434748        0.015263   \n",
       "20       0.093919      0.010202         0.466723        0.023325   \n",
       "21       0.101173      0.010609         0.453635        0.004652   \n",
       "22       0.088215      0.013958         0.456629        0.029048   \n",
       "23       0.110205      0.031365         0.496191        0.040197   \n",
       "24       0.113865      0.009784         0.578525        0.019624   \n",
       "25       0.124167      0.012032         0.597784        0.037478   \n",
       "26       0.109469      0.006508         0.595614        0.008316   \n",
       "27       0.116436      0.010742         0.584011        0.059592   \n",
       "28       0.109423      0.013545         0.564797        0.044040   \n",
       "29       0.118157      0.006398         0.590760        0.063712   \n",
       "30       0.107562      0.018630         0.569754        0.019149   \n",
       "31       0.118645      0.008819         0.591263        0.029867   \n",
       "32       0.107339      0.010704         0.598070        0.046343   \n",
       "33       0.115027      0.005733         0.588542        0.022765   \n",
       "34       0.108419      0.014276         0.577011        0.011800   \n",
       "35       0.114503      0.005613         0.607822        0.025866   \n",
       "36       0.011564      0.004864         0.075276        0.017294   \n",
       "37       0.007935      0.002923         0.049835        0.014694   \n",
       "38       0.008530      0.002346         0.066960        0.007017   \n",
       "39       0.009320      0.002517         0.047217        0.011772   \n",
       "40       0.010631      0.002517         0.070820        0.012089   \n",
       "41       0.011487      0.002845         0.040679        0.007314   \n",
       "42       0.013580      0.004391         0.071991        0.014833   \n",
       "43       0.009973      0.003815         0.045112        0.005667   \n",
       "44       0.014706      0.006681         0.072723        0.029066   \n",
       "45       0.011055      0.003749         0.044726        0.006253   \n",
       "46       0.011987      0.003441         0.080056        0.013744   \n",
       "47       0.013603      0.003559         0.051343        0.009104   \n",
       "\n",
       "   param_algorithm param_n_neighbors param_weights  \\\n",
       "0             auto                 3       uniform   \n",
       "1             auto                 3      distance   \n",
       "2             auto                 5       uniform   \n",
       "3             auto                 5      distance   \n",
       "4             auto                 7       uniform   \n",
       "5             auto                 7      distance   \n",
       "6             auto                10       uniform   \n",
       "7             auto                10      distance   \n",
       "8             auto                50       uniform   \n",
       "9             auto                50      distance   \n",
       "10            auto               100       uniform   \n",
       "11            auto               100      distance   \n",
       "12       ball_tree                 3       uniform   \n",
       "13       ball_tree                 3      distance   \n",
       "14       ball_tree                 5       uniform   \n",
       "15       ball_tree                 5      distance   \n",
       "16       ball_tree                 7       uniform   \n",
       "17       ball_tree                 7      distance   \n",
       "18       ball_tree                10       uniform   \n",
       "19       ball_tree                10      distance   \n",
       "20       ball_tree                50       uniform   \n",
       "21       ball_tree                50      distance   \n",
       "22       ball_tree               100       uniform   \n",
       "23       ball_tree               100      distance   \n",
       "24         kd_tree                 3       uniform   \n",
       "25         kd_tree                 3      distance   \n",
       "26         kd_tree                 5       uniform   \n",
       "27         kd_tree                 5      distance   \n",
       "28         kd_tree                 7       uniform   \n",
       "29         kd_tree                 7      distance   \n",
       "30         kd_tree                10       uniform   \n",
       "31         kd_tree                10      distance   \n",
       "32         kd_tree                50       uniform   \n",
       "33         kd_tree                50      distance   \n",
       "34         kd_tree               100       uniform   \n",
       "35         kd_tree               100      distance   \n",
       "36           brute                 3       uniform   \n",
       "37           brute                 3      distance   \n",
       "38           brute                 5       uniform   \n",
       "39           brute                 5      distance   \n",
       "40           brute                 7       uniform   \n",
       "41           brute                 7      distance   \n",
       "42           brute                10       uniform   \n",
       "43           brute                10      distance   \n",
       "44           brute                50       uniform   \n",
       "45           brute                50      distance   \n",
       "46           brute               100       uniform   \n",
       "47           brute               100      distance   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'algorithm': 'auto', 'n_neighbors': 3, 'weigh...           0.417178   \n",
       "1   {'algorithm': 'auto', 'n_neighbors': 3, 'weigh...           0.417178   \n",
       "2   {'algorithm': 'auto', 'n_neighbors': 5, 'weigh...           0.423313   \n",
       "3   {'algorithm': 'auto', 'n_neighbors': 5, 'weigh...           0.466258   \n",
       "4   {'algorithm': 'auto', 'n_neighbors': 7, 'weigh...           0.496933   \n",
       "5   {'algorithm': 'auto', 'n_neighbors': 7, 'weigh...           0.515337   \n",
       "6   {'algorithm': 'auto', 'n_neighbors': 10, 'weig...           0.503067   \n",
       "7   {'algorithm': 'auto', 'n_neighbors': 10, 'weig...           0.515337   \n",
       "8   {'algorithm': 'auto', 'n_neighbors': 50, 'weig...           0.576687   \n",
       "9   {'algorithm': 'auto', 'n_neighbors': 50, 'weig...           0.576687   \n",
       "10  {'algorithm': 'auto', 'n_neighbors': 100, 'wei...           0.576687   \n",
       "11  {'algorithm': 'auto', 'n_neighbors': 100, 'wei...           0.576687   \n",
       "12  {'algorithm': 'ball_tree', 'n_neighbors': 3, '...           0.417178   \n",
       "13  {'algorithm': 'ball_tree', 'n_neighbors': 3, '...           0.417178   \n",
       "14  {'algorithm': 'ball_tree', 'n_neighbors': 5, '...           0.423313   \n",
       "15  {'algorithm': 'ball_tree', 'n_neighbors': 5, '...           0.466258   \n",
       "16  {'algorithm': 'ball_tree', 'n_neighbors': 7, '...           0.496933   \n",
       "17  {'algorithm': 'ball_tree', 'n_neighbors': 7, '...           0.515337   \n",
       "18  {'algorithm': 'ball_tree', 'n_neighbors': 10, ...           0.503067   \n",
       "19  {'algorithm': 'ball_tree', 'n_neighbors': 10, ...           0.515337   \n",
       "20  {'algorithm': 'ball_tree', 'n_neighbors': 50, ...           0.576687   \n",
       "21  {'algorithm': 'ball_tree', 'n_neighbors': 50, ...           0.576687   \n",
       "22  {'algorithm': 'ball_tree', 'n_neighbors': 100,...           0.576687   \n",
       "23  {'algorithm': 'ball_tree', 'n_neighbors': 100,...           0.576687   \n",
       "24  {'algorithm': 'kd_tree', 'n_neighbors': 3, 'we...           0.417178   \n",
       "25  {'algorithm': 'kd_tree', 'n_neighbors': 3, 'we...           0.417178   \n",
       "26  {'algorithm': 'kd_tree', 'n_neighbors': 5, 'we...           0.423313   \n",
       "27  {'algorithm': 'kd_tree', 'n_neighbors': 5, 'we...           0.466258   \n",
       "28  {'algorithm': 'kd_tree', 'n_neighbors': 7, 'we...           0.496933   \n",
       "29  {'algorithm': 'kd_tree', 'n_neighbors': 7, 'we...           0.515337   \n",
       "30  {'algorithm': 'kd_tree', 'n_neighbors': 10, 'w...           0.503067   \n",
       "31  {'algorithm': 'kd_tree', 'n_neighbors': 10, 'w...           0.515337   \n",
       "32  {'algorithm': 'kd_tree', 'n_neighbors': 50, 'w...           0.576687   \n",
       "33  {'algorithm': 'kd_tree', 'n_neighbors': 50, 'w...           0.576687   \n",
       "34  {'algorithm': 'kd_tree', 'n_neighbors': 100, '...           0.576687   \n",
       "35  {'algorithm': 'kd_tree', 'n_neighbors': 100, '...           0.576687   \n",
       "36  {'algorithm': 'brute', 'n_neighbors': 3, 'weig...           0.417178   \n",
       "37  {'algorithm': 'brute', 'n_neighbors': 3, 'weig...           0.417178   \n",
       "38  {'algorithm': 'brute', 'n_neighbors': 5, 'weig...           0.423313   \n",
       "39  {'algorithm': 'brute', 'n_neighbors': 5, 'weig...           0.466258   \n",
       "40  {'algorithm': 'brute', 'n_neighbors': 7, 'weig...           0.496933   \n",
       "41  {'algorithm': 'brute', 'n_neighbors': 7, 'weig...           0.515337   \n",
       "42  {'algorithm': 'brute', 'n_neighbors': 10, 'wei...           0.503067   \n",
       "43  {'algorithm': 'brute', 'n_neighbors': 10, 'wei...           0.515337   \n",
       "44  {'algorithm': 'brute', 'n_neighbors': 50, 'wei...           0.576687   \n",
       "45  {'algorithm': 'brute', 'n_neighbors': 50, 'wei...           0.576687   \n",
       "46  {'algorithm': 'brute', 'n_neighbors': 100, 'we...           0.576687   \n",
       "47  {'algorithm': 'brute', 'n_neighbors': 100, 'we...           0.576687   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.404908           0.478528           0.404908   \n",
       "1            0.423313           0.484663           0.460123   \n",
       "2            0.429448           0.453988           0.423313   \n",
       "3            0.429448           0.521472           0.466258   \n",
       "4            0.423313           0.509202           0.435583   \n",
       "5            0.472393           0.527607           0.496933   \n",
       "6            0.453988           0.576687           0.515337   \n",
       "7            0.478528           0.558282           0.527607   \n",
       "8            0.576687           0.564417           0.570552   \n",
       "9            0.576687           0.564417           0.570552   \n",
       "10           0.576687           0.570552           0.570552   \n",
       "11           0.576687           0.570552           0.570552   \n",
       "12           0.404908           0.478528           0.404908   \n",
       "13           0.423313           0.484663           0.460123   \n",
       "14           0.429448           0.453988           0.423313   \n",
       "15           0.429448           0.521472           0.466258   \n",
       "16           0.423313           0.509202           0.435583   \n",
       "17           0.472393           0.527607           0.496933   \n",
       "18           0.453988           0.576687           0.515337   \n",
       "19           0.478528           0.558282           0.527607   \n",
       "20           0.576687           0.564417           0.570552   \n",
       "21           0.576687           0.564417           0.570552   \n",
       "22           0.576687           0.570552           0.570552   \n",
       "23           0.576687           0.570552           0.570552   \n",
       "24           0.404908           0.478528           0.404908   \n",
       "25           0.423313           0.484663           0.460123   \n",
       "26           0.429448           0.453988           0.423313   \n",
       "27           0.429448           0.521472           0.466258   \n",
       "28           0.423313           0.509202           0.435583   \n",
       "29           0.472393           0.527607           0.496933   \n",
       "30           0.453988           0.576687           0.515337   \n",
       "31           0.478528           0.558282           0.527607   \n",
       "32           0.576687           0.564417           0.570552   \n",
       "33           0.576687           0.564417           0.570552   \n",
       "34           0.576687           0.570552           0.570552   \n",
       "35           0.576687           0.570552           0.570552   \n",
       "36           0.404908           0.478528           0.404908   \n",
       "37           0.423313           0.484663           0.460123   \n",
       "38           0.429448           0.453988           0.423313   \n",
       "39           0.429448           0.521472           0.466258   \n",
       "40           0.423313           0.509202           0.435583   \n",
       "41           0.472393           0.527607           0.496933   \n",
       "42           0.453988           0.576687           0.515337   \n",
       "43           0.478528           0.558282           0.527607   \n",
       "44           0.576687           0.564417           0.570552   \n",
       "45           0.576687           0.564417           0.570552   \n",
       "46           0.576687           0.570552           0.570552   \n",
       "47           0.576687           0.570552           0.570552   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.407407         0.422586        0.028334               45  \n",
       "1            0.432099         0.443475        0.025302               37  \n",
       "2            0.432099         0.432432        0.011314               41  \n",
       "3            0.438272         0.464341        0.032151               29  \n",
       "4            0.450617         0.463130        0.033959               33  \n",
       "5            0.481481         0.498750        0.020514               25  \n",
       "6            0.512346         0.512285        0.039091               21  \n",
       "7            0.493827         0.514716        0.027606               17  \n",
       "8            0.567901         0.571249        0.004848                9  \n",
       "9            0.567901         0.571249        0.004848                9  \n",
       "10           0.574074         0.573711        0.002750                1  \n",
       "11           0.574074         0.573711        0.002750                1  \n",
       "12           0.407407         0.422586        0.028334               45  \n",
       "13           0.432099         0.443475        0.025302               37  \n",
       "14           0.432099         0.432432        0.011314               41  \n",
       "15           0.438272         0.464341        0.032151               29  \n",
       "16           0.450617         0.463130        0.033959               33  \n",
       "17           0.481481         0.498750        0.020514               25  \n",
       "18           0.512346         0.512285        0.039091               21  \n",
       "19           0.493827         0.514716        0.027606               17  \n",
       "20           0.567901         0.571249        0.004848                9  \n",
       "21           0.567901         0.571249        0.004848                9  \n",
       "22           0.574074         0.573711        0.002750                1  \n",
       "23           0.574074         0.573711        0.002750                1  \n",
       "24           0.407407         0.422586        0.028334               45  \n",
       "25           0.432099         0.443475        0.025302               37  \n",
       "26           0.432099         0.432432        0.011314               41  \n",
       "27           0.438272         0.464341        0.032151               29  \n",
       "28           0.450617         0.463130        0.033959               33  \n",
       "29           0.481481         0.498750        0.020514               25  \n",
       "30           0.512346         0.512285        0.039091               21  \n",
       "31           0.493827         0.514716        0.027606               17  \n",
       "32           0.567901         0.571249        0.004848                9  \n",
       "33           0.567901         0.571249        0.004848                9  \n",
       "34           0.574074         0.573711        0.002750                1  \n",
       "35           0.574074         0.573711        0.002750                1  \n",
       "36           0.407407         0.422586        0.028334               45  \n",
       "37           0.432099         0.443475        0.025302               37  \n",
       "38           0.432099         0.432432        0.011314               41  \n",
       "39           0.438272         0.464341        0.032151               29  \n",
       "40           0.450617         0.463130        0.033959               33  \n",
       "41           0.481481         0.498750        0.020514               25  \n",
       "42           0.512346         0.512285        0.039091               21  \n",
       "43           0.493827         0.514716        0.027606               17  \n",
       "44           0.567901         0.571249        0.004848                9  \n",
       "45           0.567901         0.571249        0.004848                9  \n",
       "46           0.574074         0.573711        0.002750                1  \n",
       "47           0.574074         0.573711        0.002750                1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### KNN ###\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "params = {'n_neighbors':[3,5,7,10,50,100], 'weights':['uniform', 'distance'], \n",
    "         'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "clf = KNeighborsClassifier()\n",
    "run_classifier(clf, params, X_train, X_test, y_train, y_test)\n",
    "\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050721</td>\n",
       "      <td>0.010715</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.165644</td>\n",
       "      <td>0.141104</td>\n",
       "      <td>0.171779</td>\n",
       "      <td>0.159509</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.160941</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time params  \\\n",
       "0       0.050721      0.010715         0.016474          0.0032     {}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.165644           0.141104           0.171779           0.159509   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.166667         0.160941        0.010658                1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Naive Bayes ###\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "params = {}\n",
    "clf = GaussianNB()\n",
    "run_classifier(clf, params, X_train, X_test, y_train, y_test)\n",
    "\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.775285</td>\n",
       "      <td>0.243573</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.509202</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.475309</td>\n",
       "      <td>0.485246</td>\n",
       "      <td>0.015588</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200402</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.465637</td>\n",
       "      <td>0.034828</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.828984</td>\n",
       "      <td>0.167304</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.533742</td>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.479050</td>\n",
       "      <td>0.066557</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.211651</td>\n",
       "      <td>0.025861</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.386503</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.423835</td>\n",
       "      <td>0.026049</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.773990</td>\n",
       "      <td>0.217166</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'min_samples_leaf': 1, '...</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.454525</td>\n",
       "      <td>0.028184</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.047766</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.205830</td>\n",
       "      <td>0.026781</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.533742</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.566349</td>\n",
       "      <td>0.016458</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.046678</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.544164</td>\n",
       "      <td>0.037509</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.204022</td>\n",
       "      <td>0.029220</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.533742</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.566349</td>\n",
       "      <td>0.016458</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.064324</td>\n",
       "      <td>0.008963</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>entropy</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.775285      0.243573         0.002612        0.001410   \n",
       "1         0.200402      0.042105         0.002283        0.001846   \n",
       "2         0.828984      0.167304         0.003966        0.002289   \n",
       "3         0.211651      0.025861         0.003319        0.002500   \n",
       "4         0.773990      0.217166         0.001538        0.000658   \n",
       "..             ...           ...              ...             ...   \n",
       "191       0.047766      0.005323         0.002232        0.001473   \n",
       "192       0.205830      0.026781         0.002623        0.001385   \n",
       "193       0.046678      0.004399         0.002715        0.002463   \n",
       "194       0.204022      0.029220         0.002805        0.001619   \n",
       "195       0.064324      0.008963         0.002717        0.002122   \n",
       "\n",
       "    param_criterion param_min_samples_leaf param_min_samples_split  \\\n",
       "0              gini                      1                       2   \n",
       "1              gini                      1                       2   \n",
       "2              gini                      1                       4   \n",
       "3              gini                      1                       4   \n",
       "4              gini                      1                       6   \n",
       "..              ...                    ...                     ...   \n",
       "191         entropy                    100                      20   \n",
       "192         entropy                    100                      50   \n",
       "193         entropy                    100                      50   \n",
       "194         entropy                    100                     100   \n",
       "195         entropy                    100                     100   \n",
       "\n",
       "    param_splitter                                             params  \\\n",
       "0             best  {'criterion': 'gini', 'min_samples_leaf': 1, '...   \n",
       "1           random  {'criterion': 'gini', 'min_samples_leaf': 1, '...   \n",
       "2             best  {'criterion': 'gini', 'min_samples_leaf': 1, '...   \n",
       "3           random  {'criterion': 'gini', 'min_samples_leaf': 1, '...   \n",
       "4             best  {'criterion': 'gini', 'min_samples_leaf': 1, '...   \n",
       "..             ...                                                ...   \n",
       "191         random  {'criterion': 'entropy', 'min_samples_leaf': 1...   \n",
       "192           best  {'criterion': 'entropy', 'min_samples_leaf': 1...   \n",
       "193         random  {'criterion': 'entropy', 'min_samples_leaf': 1...   \n",
       "194           best  {'criterion': 'entropy', 'min_samples_leaf': 1...   \n",
       "195         random  {'criterion': 'entropy', 'min_samples_leaf': 1...   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0             0.509202           0.496933           0.466258   \n",
       "1             0.472393           0.503067           0.453988   \n",
       "2             0.533742           0.582822           0.423313   \n",
       "3             0.386503           0.460123           0.441718   \n",
       "4             0.496933           0.478528           0.435583   \n",
       "..                 ...                ...                ...   \n",
       "191           0.576687           0.576687           0.570552   \n",
       "192           0.576687           0.576687           0.570552   \n",
       "193           0.576687           0.576687           0.503067   \n",
       "194           0.576687           0.576687           0.570552   \n",
       "195           0.576687           0.576687           0.570552   \n",
       "\n",
       "     split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.478528           0.475309         0.485246        0.015588   \n",
       "1             0.404908           0.493827         0.465637        0.034828   \n",
       "2             0.429448           0.425926         0.479050        0.066557   \n",
       "3             0.404908           0.425926         0.423835        0.026049   \n",
       "4             0.423313           0.438272         0.454525        0.028184   \n",
       "..                 ...                ...              ...             ...   \n",
       "191           0.570552           0.574074         0.573711        0.002750   \n",
       "192           0.533742           0.574074         0.566349        0.016458   \n",
       "193           0.570552           0.493827         0.544164        0.037509   \n",
       "194           0.533742           0.574074         0.566349        0.016458   \n",
       "195           0.570552           0.574074         0.573711        0.002750   \n",
       "\n",
       "     rank_test_score  \n",
       "0                 88  \n",
       "1                124  \n",
       "2                101  \n",
       "3                189  \n",
       "4                146  \n",
       "..               ...  \n",
       "191                1  \n",
       "192               10  \n",
       "193               22  \n",
       "194               10  \n",
       "195                1  \n",
       "\n",
       "[196 rows x 17 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Decision Tree ###\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "params = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], 'min_samples_split':[2,4,6,10,20,50,100],\n",
    "         'min_samples_leaf':[1,2,5,10,20,50,100]}\n",
    "clf = DecisionTreeClassifier()\n",
    "run_classifier(clf, params, X_train, X_test, y_train, y_test)\n",
    "\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.571869</td>\n",
       "      <td>0.884096</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>0.003832</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0001, 's...</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.445944</td>\n",
       "      <td>0.009825</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.098583</td>\n",
       "      <td>1.228455</td>\n",
       "      <td>0.010216</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0001, 's...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.435321</td>\n",
       "      <td>0.685468</td>\n",
       "      <td>0.007613</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0001, 's...</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.450822</td>\n",
       "      <td>0.029653</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.398101</td>\n",
       "      <td>1.495140</td>\n",
       "      <td>0.013222</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0005, 's...</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.413580</td>\n",
       "      <td>0.440998</td>\n",
       "      <td>0.018803</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.059047</td>\n",
       "      <td>1.249738</td>\n",
       "      <td>0.013498</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0005, 's...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.160743</td>\n",
       "      <td>3.016507</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0005, 's...</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.450617</td>\n",
       "      <td>0.453314</td>\n",
       "      <td>0.024881</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.649228</td>\n",
       "      <td>1.079807</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.002</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.002, 'so...</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.454525</td>\n",
       "      <td>0.018914</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.665708</td>\n",
       "      <td>0.760709</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.002</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.002, 'so...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.940325</td>\n",
       "      <td>3.069058</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>0.008469</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.002</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.002, 'so...</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.456972</td>\n",
       "      <td>0.028187</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.478896</td>\n",
       "      <td>0.934396</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.005</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.005, 'so...</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.444687</td>\n",
       "      <td>0.027112</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.313731</td>\n",
       "      <td>0.491971</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.005, 'so...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.644181</td>\n",
       "      <td>0.669853</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.005</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.005, 'so...</td>\n",
       "      <td>0.490798</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.443467</td>\n",
       "      <td>0.029831</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.986429</td>\n",
       "      <td>0.332487</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>identity</td>\n",
       "      <td>0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0, 'solv...</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.453283</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.157151</td>\n",
       "      <td>0.497217</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>identity</td>\n",
       "      <td>0</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0, 'solv...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.337076</td>\n",
       "      <td>0.411165</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>identity</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0, 'solv...</td>\n",
       "      <td>0.490798</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.413580</td>\n",
       "      <td>0.445906</td>\n",
       "      <td>0.028341</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.720818</td>\n",
       "      <td>0.914924</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0001, 's...</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.450829</td>\n",
       "      <td>0.024478</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.884062</td>\n",
       "      <td>0.179035</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0001, 's...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.684771</td>\n",
       "      <td>0.320664</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0001, 's...</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.490798</td>\n",
       "      <td>0.490798</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.483996</td>\n",
       "      <td>0.015661</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.283853</td>\n",
       "      <td>1.455875</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0005, 's...</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.450829</td>\n",
       "      <td>0.021533</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.922708</td>\n",
       "      <td>0.137706</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0005, 's...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.982043</td>\n",
       "      <td>0.551425</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0005, 's...</td>\n",
       "      <td>0.490798</td>\n",
       "      <td>0.490798</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.509202</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.490116</td>\n",
       "      <td>0.024848</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.810995</td>\n",
       "      <td>0.740816</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.002</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.002, 'so...</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.447141</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.280305</td>\n",
       "      <td>0.169611</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.002</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.002, 'so...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.806746</td>\n",
       "      <td>0.338297</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.002</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.002, 'so...</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.490116</td>\n",
       "      <td>0.024848</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.067111</td>\n",
       "      <td>0.509807</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.005</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.005, 'so...</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.444687</td>\n",
       "      <td>0.014939</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.032425</td>\n",
       "      <td>0.098738</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.005, 'so...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.349439</td>\n",
       "      <td>0.439856</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.005</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.005, 'so...</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.495054</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.702866</td>\n",
       "      <td>0.794384</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0, 'solv...</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.401235</td>\n",
       "      <td>0.433621</td>\n",
       "      <td>0.020684</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.107342</td>\n",
       "      <td>0.261758</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0, 'solv...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.296127</td>\n",
       "      <td>0.171031</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0, 'solv...</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.490798</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.471688</td>\n",
       "      <td>0.024890</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.089971</td>\n",
       "      <td>0.366383</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'solve...</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.413580</td>\n",
       "      <td>0.439771</td>\n",
       "      <td>0.015406</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.053945</td>\n",
       "      <td>0.392026</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'solve...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9.322507</td>\n",
       "      <td>0.203478</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'solve...</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.455752</td>\n",
       "      <td>0.032014</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.496426</td>\n",
       "      <td>0.642650</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0005, 'solve...</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.439779</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.958174</td>\n",
       "      <td>0.487184</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0005, 'solve...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9.842098</td>\n",
       "      <td>0.239234</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0005, 'solve...</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.450837</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.288308</td>\n",
       "      <td>0.512816</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.002</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.002, 'solver...</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.413580</td>\n",
       "      <td>0.454495</td>\n",
       "      <td>0.028294</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.259313</td>\n",
       "      <td>0.888719</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.002</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.002, 'solver...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>16.554283</td>\n",
       "      <td>2.860282</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.002</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.002, 'solver...</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.448368</td>\n",
       "      <td>0.025435</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10.169121</td>\n",
       "      <td>3.333308</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.005</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.005, 'solver...</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.413580</td>\n",
       "      <td>0.450814</td>\n",
       "      <td>0.019793</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.527405</td>\n",
       "      <td>0.757066</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.005, 'solver...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>11.580311</td>\n",
       "      <td>0.352188</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.005</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.005, 'solver...</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.490798</td>\n",
       "      <td>0.435583</td>\n",
       "      <td>0.413580</td>\n",
       "      <td>0.453268</td>\n",
       "      <td>0.033972</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.385355</td>\n",
       "      <td>0.350784</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0, 'solver':...</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.447111</td>\n",
       "      <td>0.026878</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4.806516</td>\n",
       "      <td>0.716063</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0, 'solver':...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10.728490</td>\n",
       "      <td>0.599049</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0, 'solver':...</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.453276</td>\n",
       "      <td>0.029559</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3.397865</td>\n",
       "      <td>0.089463</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'solve...</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.376543</td>\n",
       "      <td>0.421321</td>\n",
       "      <td>0.023854</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.494610</td>\n",
       "      <td>0.630914</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'solve...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10.633173</td>\n",
       "      <td>0.552874</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'solve...</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.469242</td>\n",
       "      <td>0.026857</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.553774</td>\n",
       "      <td>1.410590</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0005, 'solve...</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.438272</td>\n",
       "      <td>0.455752</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.168610</td>\n",
       "      <td>0.308279</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0005, 'solve...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>10.627517</td>\n",
       "      <td>0.641247</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0005, 'solve...</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.465561</td>\n",
       "      <td>0.023592</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>8.568624</td>\n",
       "      <td>0.824094</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.002</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.002, 'solver...</td>\n",
       "      <td>0.509202</td>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.453245</td>\n",
       "      <td>0.038721</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.046410</td>\n",
       "      <td>0.526309</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.002</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.002, 'solver...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>10.438459</td>\n",
       "      <td>0.595510</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.002</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.002, 'solver...</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.413580</td>\n",
       "      <td>0.458176</td>\n",
       "      <td>0.033496</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>10.867945</td>\n",
       "      <td>0.880349</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.005</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.005, 'solver...</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.401235</td>\n",
       "      <td>0.464296</td>\n",
       "      <td>0.034358</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.496347</td>\n",
       "      <td>1.047874</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.005</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.005, 'solver...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>11.251464</td>\n",
       "      <td>0.771553</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.005</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.005, 'solver...</td>\n",
       "      <td>0.484663</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.476589</td>\n",
       "      <td>0.029713</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3.289107</td>\n",
       "      <td>0.241681</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0, 'solver':...</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.447853</td>\n",
       "      <td>0.401235</td>\n",
       "      <td>0.443437</td>\n",
       "      <td>0.022146</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5.637649</td>\n",
       "      <td>0.474090</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0, 'solver':...</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.573711</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>10.832905</td>\n",
       "      <td>0.380958</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0, 'solver':...</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.453988</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.464326</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        6.571869      0.884096         0.008951        0.003832   \n",
       "1       11.098583      1.228455         0.010216        0.003759   \n",
       "2       22.435321      0.685468         0.007613        0.002786   \n",
       "3        7.398101      1.495140         0.013222        0.008197   \n",
       "4       11.059047      1.249738         0.013498        0.001135   \n",
       "5       19.160743      3.016507         0.005290        0.001598   \n",
       "6        5.649228      1.079807         0.005861        0.002931   \n",
       "7        5.665708      0.760709         0.004726        0.000768   \n",
       "8       15.940325      3.069058         0.011694        0.008469   \n",
       "9        6.478896      0.934396         0.003456        0.000616   \n",
       "10       4.313731      0.491971         0.005904        0.003394   \n",
       "11       9.644181      0.669853         0.003454        0.000541   \n",
       "12       2.986429      0.332487         0.003405        0.000194   \n",
       "13       4.157151      0.497217         0.003955        0.001544   \n",
       "14       9.337076      0.411165         0.003348        0.000213   \n",
       "15       5.720818      0.914924         0.006794        0.006185   \n",
       "16       0.884062      0.179035         0.003666        0.000106   \n",
       "17       9.684771      0.320664         0.003560        0.000062   \n",
       "18       7.283853      1.455875         0.003542        0.000049   \n",
       "19       0.922708      0.137706         0.003952        0.000250   \n",
       "20       9.982043      0.551425         0.004809        0.002469   \n",
       "21       9.810995      0.740816         0.005210        0.002067   \n",
       "22       1.280305      0.169611         0.004188        0.000913   \n",
       "23       9.806746      0.338297         0.006769        0.003998   \n",
       "24      10.067111      0.509807         0.003591        0.000088   \n",
       "25       1.032425      0.098738         0.004651        0.001275   \n",
       "26      10.349439      0.439856         0.007013        0.006752   \n",
       "27       4.702866      0.794384         0.005449        0.002258   \n",
       "28       1.107342      0.261758         0.004601        0.001915   \n",
       "29       9.296127      0.171031         0.003719        0.000078   \n",
       "30       3.089971      0.366383         0.004006        0.000050   \n",
       "31       4.053945      0.392026         0.003787        0.000106   \n",
       "32       9.322507      0.203478         0.006984        0.003549   \n",
       "33       3.496426      0.642650         0.004717        0.001213   \n",
       "34       4.958174      0.487184         0.007061        0.006577   \n",
       "35       9.842098      0.239234         0.003813        0.000142   \n",
       "36       5.288308      0.512816         0.004057        0.000184   \n",
       "37       5.259313      0.888719         0.004597        0.000958   \n",
       "38      16.554283      2.860282         0.004749        0.000517   \n",
       "39      10.169121      3.333308         0.006146        0.002153   \n",
       "40       5.527405      0.757066         0.005497        0.001421   \n",
       "41      11.580311      0.352188         0.004399        0.000335   \n",
       "42       3.385355      0.350784         0.006027        0.003163   \n",
       "43       4.806516      0.716063         0.004230        0.000118   \n",
       "44      10.728490      0.599049         0.004161        0.000080   \n",
       "45       3.397865      0.089463         0.003665        0.000027   \n",
       "46       5.494610      0.630914         0.003969        0.000419   \n",
       "47      10.633173      0.552874         0.006750        0.006161   \n",
       "48       5.553774      1.410590         0.003727        0.000073   \n",
       "49       5.168610      0.308279         0.003915        0.000134   \n",
       "50      10.627517      0.641247         0.003792        0.000135   \n",
       "51       8.568624      0.824094         0.005231        0.003100   \n",
       "52       6.046410      0.526309         0.006372        0.004887   \n",
       "53      10.438459      0.595510         0.006256        0.003959   \n",
       "54      10.867945      0.880349         0.004797        0.001690   \n",
       "55       5.496347      1.047874         0.003775        0.000076   \n",
       "56      11.251464      0.771553         0.006073        0.004769   \n",
       "57       3.289107      0.241681         0.004926        0.002140   \n",
       "58       5.637649      0.474090         0.003820        0.000105   \n",
       "59      10.832905      0.380958         0.003646        0.000017   \n",
       "\n",
       "   param_activation param_alpha param_solver  \\\n",
       "0          identity      0.0001        lbfgs   \n",
       "1          identity      0.0001          sgd   \n",
       "2          identity      0.0001         adam   \n",
       "3          identity      0.0005        lbfgs   \n",
       "4          identity      0.0005          sgd   \n",
       "5          identity      0.0005         adam   \n",
       "6          identity       0.002        lbfgs   \n",
       "7          identity       0.002          sgd   \n",
       "8          identity       0.002         adam   \n",
       "9          identity       0.005        lbfgs   \n",
       "10         identity       0.005          sgd   \n",
       "11         identity       0.005         adam   \n",
       "12         identity           0        lbfgs   \n",
       "13         identity           0          sgd   \n",
       "14         identity           0         adam   \n",
       "15         logistic      0.0001        lbfgs   \n",
       "16         logistic      0.0001          sgd   \n",
       "17         logistic      0.0001         adam   \n",
       "18         logistic      0.0005        lbfgs   \n",
       "19         logistic      0.0005          sgd   \n",
       "20         logistic      0.0005         adam   \n",
       "21         logistic       0.002        lbfgs   \n",
       "22         logistic       0.002          sgd   \n",
       "23         logistic       0.002         adam   \n",
       "24         logistic       0.005        lbfgs   \n",
       "25         logistic       0.005          sgd   \n",
       "26         logistic       0.005         adam   \n",
       "27         logistic           0        lbfgs   \n",
       "28         logistic           0          sgd   \n",
       "29         logistic           0         adam   \n",
       "30             tanh      0.0001        lbfgs   \n",
       "31             tanh      0.0001          sgd   \n",
       "32             tanh      0.0001         adam   \n",
       "33             tanh      0.0005        lbfgs   \n",
       "34             tanh      0.0005          sgd   \n",
       "35             tanh      0.0005         adam   \n",
       "36             tanh       0.002        lbfgs   \n",
       "37             tanh       0.002          sgd   \n",
       "38             tanh       0.002         adam   \n",
       "39             tanh       0.005        lbfgs   \n",
       "40             tanh       0.005          sgd   \n",
       "41             tanh       0.005         adam   \n",
       "42             tanh           0        lbfgs   \n",
       "43             tanh           0          sgd   \n",
       "44             tanh           0         adam   \n",
       "45             relu      0.0001        lbfgs   \n",
       "46             relu      0.0001          sgd   \n",
       "47             relu      0.0001         adam   \n",
       "48             relu      0.0005        lbfgs   \n",
       "49             relu      0.0005          sgd   \n",
       "50             relu      0.0005         adam   \n",
       "51             relu       0.002        lbfgs   \n",
       "52             relu       0.002          sgd   \n",
       "53             relu       0.002         adam   \n",
       "54             relu       0.005        lbfgs   \n",
       "55             relu       0.005          sgd   \n",
       "56             relu       0.005         adam   \n",
       "57             relu           0        lbfgs   \n",
       "58             relu           0          sgd   \n",
       "59             relu           0         adam   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'activation': 'identity', 'alpha': 0.0001, 's...           0.435583   \n",
       "1   {'activation': 'identity', 'alpha': 0.0001, 's...           0.576687   \n",
       "2   {'activation': 'identity', 'alpha': 0.0001, 's...           0.484663   \n",
       "3   {'activation': 'identity', 'alpha': 0.0005, 's...           0.453988   \n",
       "4   {'activation': 'identity', 'alpha': 0.0005, 's...           0.576687   \n",
       "5   {'activation': 'identity', 'alpha': 0.0005, 's...           0.484663   \n",
       "6   {'activation': 'identity', 'alpha': 0.002, 'so...           0.478528   \n",
       "7   {'activation': 'identity', 'alpha': 0.002, 'so...           0.576687   \n",
       "8   {'activation': 'identity', 'alpha': 0.002, 'so...           0.496933   \n",
       "9   {'activation': 'identity', 'alpha': 0.005, 'so...           0.472393   \n",
       "10  {'activation': 'identity', 'alpha': 0.005, 'so...           0.576687   \n",
       "11  {'activation': 'identity', 'alpha': 0.005, 'so...           0.490798   \n",
       "12  {'activation': 'identity', 'alpha': 0.0, 'solv...           0.478528   \n",
       "13  {'activation': 'identity', 'alpha': 0.0, 'solv...           0.576687   \n",
       "14  {'activation': 'identity', 'alpha': 0.0, 'solv...           0.490798   \n",
       "15  {'activation': 'logistic', 'alpha': 0.0001, 's...           0.472393   \n",
       "16  {'activation': 'logistic', 'alpha': 0.0001, 's...           0.576687   \n",
       "17  {'activation': 'logistic', 'alpha': 0.0001, 's...           0.478528   \n",
       "18  {'activation': 'logistic', 'alpha': 0.0005, 's...           0.478528   \n",
       "19  {'activation': 'logistic', 'alpha': 0.0005, 's...           0.576687   \n",
       "20  {'activation': 'logistic', 'alpha': 0.0005, 's...           0.490798   \n",
       "21  {'activation': 'logistic', 'alpha': 0.002, 'so...           0.472393   \n",
       "22  {'activation': 'logistic', 'alpha': 0.002, 'so...           0.576687   \n",
       "23  {'activation': 'logistic', 'alpha': 0.002, 'so...           0.484663   \n",
       "24  {'activation': 'logistic', 'alpha': 0.005, 'so...           0.453988   \n",
       "25  {'activation': 'logistic', 'alpha': 0.005, 'so...           0.576687   \n",
       "26  {'activation': 'logistic', 'alpha': 0.005, 'so...           0.484663   \n",
       "27  {'activation': 'logistic', 'alpha': 0.0, 'solv...           0.435583   \n",
       "28  {'activation': 'logistic', 'alpha': 0.0, 'solv...           0.576687   \n",
       "29  {'activation': 'logistic', 'alpha': 0.0, 'solv...           0.472393   \n",
       "30  {'activation': 'tanh', 'alpha': 0.0001, 'solve...           0.447853   \n",
       "31  {'activation': 'tanh', 'alpha': 0.0001, 'solve...           0.576687   \n",
       "32  {'activation': 'tanh', 'alpha': 0.0001, 'solve...           0.503067   \n",
       "33  {'activation': 'tanh', 'alpha': 0.0005, 'solve...           0.447853   \n",
       "34  {'activation': 'tanh', 'alpha': 0.0005, 'solve...           0.576687   \n",
       "35  {'activation': 'tanh', 'alpha': 0.0005, 'solve...           0.484663   \n",
       "36  {'activation': 'tanh', 'alpha': 0.002, 'solver...           0.496933   \n",
       "37  {'activation': 'tanh', 'alpha': 0.002, 'solver...           0.576687   \n",
       "38  {'activation': 'tanh', 'alpha': 0.002, 'solver...           0.472393   \n",
       "39  {'activation': 'tanh', 'alpha': 0.005, 'solver...           0.472393   \n",
       "40  {'activation': 'tanh', 'alpha': 0.005, 'solver...           0.576687   \n",
       "41  {'activation': 'tanh', 'alpha': 0.005, 'solver...           0.496933   \n",
       "42  {'activation': 'tanh', 'alpha': 0.0, 'solver':...           0.472393   \n",
       "43  {'activation': 'tanh', 'alpha': 0.0, 'solver':...           0.576687   \n",
       "44  {'activation': 'tanh', 'alpha': 0.0, 'solver':...           0.496933   \n",
       "45  {'activation': 'relu', 'alpha': 0.0001, 'solve...           0.429448   \n",
       "46  {'activation': 'relu', 'alpha': 0.0001, 'solve...           0.576687   \n",
       "47  {'activation': 'relu', 'alpha': 0.0001, 'solve...           0.472393   \n",
       "48  {'activation': 'relu', 'alpha': 0.0005, 'solve...           0.472393   \n",
       "49  {'activation': 'relu', 'alpha': 0.0005, 'solve...           0.576687   \n",
       "50  {'activation': 'relu', 'alpha': 0.0005, 'solve...           0.484663   \n",
       "51  {'activation': 'relu', 'alpha': 0.002, 'solver...           0.509202   \n",
       "52  {'activation': 'relu', 'alpha': 0.002, 'solver...           0.576687   \n",
       "53  {'activation': 'relu', 'alpha': 0.002, 'solver...           0.466258   \n",
       "54  {'activation': 'relu', 'alpha': 0.005, 'solver...           0.503067   \n",
       "55  {'activation': 'relu', 'alpha': 0.005, 'solver...           0.576687   \n",
       "56  {'activation': 'relu', 'alpha': 0.005, 'solver...           0.484663   \n",
       "57  {'activation': 'relu', 'alpha': 0.0, 'solver':...           0.447853   \n",
       "58  {'activation': 'relu', 'alpha': 0.0, 'solver':...           0.576687   \n",
       "59  {'activation': 'relu', 'alpha': 0.0, 'solver':...           0.460123   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.435583           0.460123           0.453988   \n",
       "1            0.576687           0.570552           0.570552   \n",
       "2            0.417178           0.484663           0.447853   \n",
       "3            0.423313           0.453988           0.460123   \n",
       "4            0.576687           0.570552           0.570552   \n",
       "5            0.423313           0.478528           0.429448   \n",
       "6            0.429448           0.472393           0.453988   \n",
       "7            0.576687           0.570552           0.570552   \n",
       "8            0.441718           0.484663           0.429448   \n",
       "9            0.404908           0.460123           0.466258   \n",
       "10           0.576687           0.570552           0.570552   \n",
       "11           0.417178           0.466258           0.417178   \n",
       "12           0.441718           0.453988           0.466258   \n",
       "13           0.576687           0.570552           0.570552   \n",
       "14           0.429448           0.466258           0.429448   \n",
       "15           0.447853           0.423313           0.484663   \n",
       "16           0.576687           0.570552           0.570552   \n",
       "17           0.490798           0.490798           0.503067   \n",
       "18           0.429448           0.447853           0.472393   \n",
       "19           0.576687           0.570552           0.570552   \n",
       "20           0.490798           0.515337           0.509202   \n",
       "21           0.435583           0.460123           0.447853   \n",
       "22           0.576687           0.570552           0.570552   \n",
       "23           0.503067           0.503067           0.515337   \n",
       "24           0.435583           0.460123           0.453988   \n",
       "25           0.576687           0.570552           0.570552   \n",
       "26           0.503067           0.503067           0.515337   \n",
       "27           0.466258           0.435583           0.429448   \n",
       "28           0.576687           0.570552           0.570552   \n",
       "29           0.472393           0.496933           0.490798   \n",
       "30           0.460123           0.435583           0.441718   \n",
       "31           0.576687           0.570552           0.570552   \n",
       "32           0.423313           0.484663           0.429448   \n",
       "33           0.447853           0.441718           0.441718   \n",
       "34           0.576687           0.570552           0.570552   \n",
       "35           0.429448           0.478528           0.429448   \n",
       "36           0.447853           0.472393           0.441718   \n",
       "37           0.576687           0.570552           0.570552   \n",
       "38           0.435583           0.484663           0.429448   \n",
       "39           0.453988           0.453988           0.460123   \n",
       "40           0.576687           0.570552           0.570552   \n",
       "41           0.429448           0.490798           0.435583   \n",
       "42           0.453988           0.460123           0.453988   \n",
       "43           0.576687           0.570552           0.570552   \n",
       "44           0.429448           0.478528           0.441718   \n",
       "45           0.429448           0.423313           0.447853   \n",
       "46           0.576687           0.570552           0.570552   \n",
       "47           0.460123           0.515337           0.466258   \n",
       "48           0.460123           0.441718           0.466258   \n",
       "49           0.576687           0.570552           0.570552   \n",
       "50           0.447853           0.496933           0.466258   \n",
       "51           0.472393           0.429448           0.460123   \n",
       "52           0.576687           0.570552           0.570552   \n",
       "53           0.441718           0.515337           0.453988   \n",
       "54           0.484663           0.466258           0.466258   \n",
       "55           0.576687           0.570552           0.570552   \n",
       "56           0.478528           0.496933           0.503067   \n",
       "57           0.466258           0.453988           0.447853   \n",
       "58           0.576687           0.570552           0.570552   \n",
       "59           0.453988           0.515337           0.466258   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.444444         0.445944        0.009825               50  \n",
       "1            0.574074         0.573711        0.002750                1  \n",
       "2            0.419753         0.450822        0.029653               45  \n",
       "3            0.413580         0.440998        0.018803               56  \n",
       "4            0.574074         0.573711        0.002750                1  \n",
       "5            0.450617         0.453314        0.024881               37  \n",
       "6            0.438272         0.454525        0.018914               35  \n",
       "7            0.574074         0.573711        0.002750                1  \n",
       "8            0.432099         0.456972        0.028187               32  \n",
       "9            0.419753         0.444687        0.027112               52  \n",
       "10           0.574074         0.573711        0.002750                1  \n",
       "11           0.425926         0.443467        0.029831               54  \n",
       "12           0.425926         0.453283        0.018375               38  \n",
       "13           0.574074         0.573711        0.002750                1  \n",
       "14           0.413580         0.445906        0.028341               51  \n",
       "15           0.425926         0.450829        0.024478               43  \n",
       "16           0.574074         0.573711        0.002750                1  \n",
       "17           0.456790         0.483996        0.015661               24  \n",
       "18           0.425926         0.450829        0.021533               43  \n",
       "19           0.574074         0.573711        0.002750                1  \n",
       "20           0.444444         0.490116        0.024848               22  \n",
       "21           0.419753         0.447141        0.018387               48  \n",
       "22           0.574074         0.573711        0.002750                1  \n",
       "23           0.444444         0.490116        0.024848               22  \n",
       "24           0.419753         0.444687        0.014939               52  \n",
       "25           0.574074         0.573711        0.002750                1  \n",
       "26           0.469136         0.495054        0.016246               21  \n",
       "27           0.401235         0.433621        0.020684               59  \n",
       "28           0.574074         0.573711        0.002750                1  \n",
       "29           0.425926         0.471688        0.024890               26  \n",
       "30           0.413580         0.439771        0.015406               58  \n",
       "31           0.574074         0.573711        0.002750                1  \n",
       "32           0.438272         0.455752        0.032014               34  \n",
       "33           0.419753         0.439779        0.010382               57  \n",
       "34           0.574074         0.573711        0.002750                1  \n",
       "35           0.432099         0.450837        0.025207               42  \n",
       "36           0.413580         0.454495        0.028294               36  \n",
       "37           0.574074         0.573711        0.002750                1  \n",
       "38           0.419753         0.448368        0.025435               47  \n",
       "39           0.413580         0.450814        0.019793               46  \n",
       "40           0.574074         0.573711        0.002750                1  \n",
       "41           0.413580         0.453268        0.033972               40  \n",
       "42           0.395062         0.447111        0.026878               49  \n",
       "43           0.574074         0.573711        0.002750                1  \n",
       "44           0.419753         0.453276        0.029559               39  \n",
       "45           0.376543         0.421321        0.023854               60  \n",
       "46           0.574074         0.573711        0.002750                1  \n",
       "47           0.432099         0.469242        0.026857               27  \n",
       "48           0.438272         0.455752        0.013483               33  \n",
       "49           0.574074         0.573711        0.002750                1  \n",
       "50           0.432099         0.465561        0.023592               28  \n",
       "51           0.395062         0.453245        0.038721               41  \n",
       "52           0.574074         0.573711        0.002750                1  \n",
       "53           0.413580         0.458176        0.033496               31  \n",
       "54           0.401235         0.464296        0.034358               30  \n",
       "55           0.574074         0.573711        0.002750                1  \n",
       "56           0.419753         0.476589        0.029713               25  \n",
       "57           0.401235         0.443437        0.022146               55  \n",
       "58           0.574074         0.573711        0.002750                1  \n",
       "59           0.425926         0.464326        0.029000               29  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MLP classifier ###\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "params = {\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.0005, 0.0020, 0.0050, 0., ] }\n",
    "\n",
    "clf = MLPClassifier()\n",
    "run_classifier(clf, params, X_train, X_test, y_train, y_test)\n",
    "\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traincnn = np.expand_dims(X_train, axis=0)\n",
    "X_testcnn = np.expand_dims(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(1, len(X_train), 504)\n",
    "X_test = X_test.reshape(1, len(X_test), 504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 998 samples, validate on 428 samples\n",
      "Epoch 1/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.1022 - accuracy: 0.2275 - val_loss: 1.0966 - val_accuracy: 0.4112\n",
      "Epoch 2/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0964 - accuracy: 0.4248 - val_loss: 1.0918 - val_accuracy: 0.4112\n",
      "Epoch 3/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0912 - accuracy: 0.4248 - val_loss: 1.0875 - val_accuracy: 0.4112\n",
      "Epoch 4/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0864 - accuracy: 0.4248 - val_loss: 1.0836 - val_accuracy: 0.4112\n",
      "Epoch 5/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0823 - accuracy: 0.4248 - val_loss: 1.0799 - val_accuracy: 0.4112\n",
      "Epoch 6/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0784 - accuracy: 0.4248 - val_loss: 1.0765 - val_accuracy: 0.4112\n",
      "Epoch 7/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0748 - accuracy: 0.4248 - val_loss: 1.0734 - val_accuracy: 0.4112\n",
      "Epoch 8/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0717 - accuracy: 0.4248 - val_loss: 1.0705 - val_accuracy: 0.4112\n",
      "Epoch 9/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0687 - accuracy: 0.4248 - val_loss: 1.0679 - val_accuracy: 0.4112\n",
      "Epoch 10/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0661 - accuracy: 0.4248 - val_loss: 1.0653 - val_accuracy: 0.4112\n",
      "Epoch 11/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0638 - accuracy: 0.4248 - val_loss: 1.0630 - val_accuracy: 0.4112\n",
      "Epoch 12/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0615 - accuracy: 0.4248 - val_loss: 1.0610 - val_accuracy: 0.4112\n",
      "Epoch 13/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0595 - accuracy: 0.4248 - val_loss: 1.0590 - val_accuracy: 0.4112\n",
      "Epoch 14/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0576 - accuracy: 0.4248 - val_loss: 1.0573 - val_accuracy: 0.4112\n",
      "Epoch 15/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0560 - accuracy: 0.4248 - val_loss: 1.0557 - val_accuracy: 0.4112\n",
      "Epoch 16/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0546 - accuracy: 0.4248 - val_loss: 1.0542 - val_accuracy: 0.4112\n",
      "Epoch 17/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0533 - accuracy: 0.4248 - val_loss: 1.0529 - val_accuracy: 0.4112\n",
      "Epoch 18/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0522 - accuracy: 0.4248 - val_loss: 1.0518 - val_accuracy: 0.4112\n",
      "Epoch 19/100\n",
      "998/998 [==============================] - 11s 11ms/step - loss: 1.0512 - accuracy: 0.4248 - val_loss: 1.0507 - val_accuracy: 0.4112\n",
      "Epoch 20/100\n",
      "998/998 [==============================] - 10s 10ms/step - loss: 1.0504 - accuracy: 0.4248 - val_loss: 1.0499 - val_accuracy: 0.4112\n",
      "Epoch 21/100\n",
      "998/998 [==============================] - 10s 10ms/step - loss: 1.0498 - accuracy: 0.4248 - val_loss: 1.0491 - val_accuracy: 0.4112\n",
      "Epoch 22/100\n",
      "998/998 [==============================] - 10s 10ms/step - loss: 1.0492 - accuracy: 0.4248 - val_loss: 1.0485 - val_accuracy: 0.4112\n",
      "Epoch 23/100\n",
      "998/998 [==============================] - 10s 10ms/step - loss: 1.0486 - accuracy: 0.4248 - val_loss: 1.0478 - val_accuracy: 0.4112\n",
      "Epoch 24/100\n",
      "998/998 [==============================] - 11s 11ms/step - loss: 1.0482 - accuracy: 0.4248 - val_loss: 1.0473 - val_accuracy: 0.4112\n",
      "Epoch 25/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0479 - accuracy: 0.4248 - val_loss: 1.0469 - val_accuracy: 0.4112\n",
      "Epoch 26/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0476 - accuracy: 0.4248 - val_loss: 1.0465 - val_accuracy: 0.4112\n",
      "Epoch 27/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0473 - accuracy: 0.4248 - val_loss: 1.0462 - val_accuracy: 0.4112\n",
      "Epoch 28/100\n",
      "998/998 [==============================] - 10s 10ms/step - loss: 1.0473 - accuracy: 0.4248 - val_loss: 1.0460 - val_accuracy: 0.4112\n",
      "Epoch 29/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0469 - accuracy: 0.4248 - val_loss: 1.0457 - val_accuracy: 0.4112\n",
      "Epoch 30/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0469 - accuracy: 0.4248 - val_loss: 1.0455 - val_accuracy: 0.4112\n",
      "Epoch 31/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0467 - accuracy: 0.4248 - val_loss: 1.0453 - val_accuracy: 0.4112\n",
      "Epoch 32/100\n",
      "998/998 [==============================] - 12s 12ms/step - loss: 1.0467 - accuracy: 0.4248 - val_loss: 1.0452 - val_accuracy: 0.4112\n",
      "Epoch 33/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0467 - accuracy: 0.4248 - val_loss: 1.0451 - val_accuracy: 0.4112\n",
      "Epoch 34/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0465 - accuracy: 0.4248 - val_loss: 1.0450 - val_accuracy: 0.4112\n",
      "Epoch 35/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0465 - accuracy: 0.4248 - val_loss: 1.0449 - val_accuracy: 0.4112\n",
      "Epoch 36/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0448 - val_accuracy: 0.4112\n",
      "Epoch 37/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0465 - accuracy: 0.4248 - val_loss: 1.0447 - val_accuracy: 0.4112\n",
      "Epoch 38/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0447 - val_accuracy: 0.4112\n",
      "Epoch 39/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0447 - val_accuracy: 0.4112\n",
      "Epoch 40/100\n",
      "998/998 [==============================] - 8s 8ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0446 - val_accuracy: 0.4112\n",
      "Epoch 41/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0465 - accuracy: 0.4248 - val_loss: 1.0446 - val_accuracy: 0.4112\n",
      "Epoch 42/100\n",
      "998/998 [==============================] - 11s 11ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 43/100\n",
      "998/998 [==============================] - 11s 11ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0446 - val_accuracy: 0.4112\n",
      "Epoch 44/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0446 - val_accuracy: 0.4112\n",
      "Epoch 45/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 46/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 47/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 48/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 49/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 50/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 51/100\n",
      "998/998 [==============================] - 10s 10ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 52/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 53/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0465 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 54/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 55/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 56/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0465 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 57/100\n",
      "998/998 [==============================] - 11s 11ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 58/100\n",
      "998/998 [==============================] - 13s 13ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 59/100\n",
      "998/998 [==============================] - 12s 12ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 60/100\n",
      "998/998 [==============================] - 10s 10ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 61/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 62/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 63/100\n",
      "998/998 [==============================] - 12s 12ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 64/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 65/100\n",
      "998/998 [==============================] - 10s 10ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 66/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0445 - val_accuracy: 0.4112\n",
      "Epoch 67/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 68/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 69/100\n",
      "998/998 [==============================] - 11s 11ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 70/100\n",
      "998/998 [==============================] - 14s 14ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 71/100\n",
      "998/998 [==============================] - 15s 15ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 72/100\n",
      "998/998 [==============================] - 11s 11ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 73/100\n",
      "998/998 [==============================] - 13s 13ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 74/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 75/100\n",
      "998/998 [==============================] - 10s 10ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 76/100\n",
      "998/998 [==============================] - 8s 8ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 77/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 78/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 79/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 80/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 81/100\n",
      "998/998 [==============================] - 8s 8ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 82/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 83/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 84/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 85/100\n",
      "998/998 [==============================] - 8s 8ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 86/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 87/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0465 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 88/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 89/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 90/100\n",
      "998/998 [==============================] - 9s 9ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0443 - val_accuracy: 0.4112\n",
      "Epoch 91/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0443 - val_accuracy: 0.4112\n",
      "Epoch 92/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 93/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 94/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 95/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 96/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 97/100\n",
      "998/998 [==============================] - 8s 8ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 98/100\n",
      "998/998 [==============================] - 8s 8ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 99/100\n",
      "998/998 [==============================] - 7s 7ms/step - loss: 1.0463 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n",
      "Epoch 100/100\n",
      "998/998 [==============================] - 6s 6ms/step - loss: 1.0464 - accuracy: 0.4248 - val_loss: 1.0444 - val_accuracy: 0.4112\n"
     ]
    }
   ],
   "source": [
    "embedding_size  = 128\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "lstm_output_size = 70\n",
    "\n",
    "# Training\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(1, embedding_size, input_length=504))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=pool_size))\n",
    "model.add(LSTM(lstm_output_size))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=['accuracy'])\n",
    "cnnhistory=model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 500\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics=['accuracy'])\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.0000001)\n",
    "mcp_save = ModelCheckpoint('../model_checkpoints/two_split.h5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_5 to have shape (1,) but got array with shape (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-40554bcf0dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnnhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# , callbacks=[mcp_save, lr_reduce]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_5 to have shape (1,) but got array with shape (3,)"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, y_test))\n",
    "# , callbacks=[mcp_save, lr_reduce]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 504, 128)          768       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 504, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 504, 64)           41024     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 504, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 504, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 63, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 63, 32)            10272     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 63, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2016)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 6051      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 58,115\n",
      "Trainable params: 58,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  6.404657  ,  -1.402514  ,  -2.236425  , ...,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [  0.8584499 ,  -0.06234932,   0.6381655 , ...,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [  5.846846  , -10.07883   , -11.02912   , ...,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        ...,\n",
       "        [ 12.99762   ,  -7.800581  ,  -1.155792  , ...,  -0.5558    ,\n",
       "          -1.747546  ,   3.087212  ],\n",
       "        [  3.280588  ,   2.007889  ,  -2.019495  , ...,  -0.9734643 ,\n",
       "           0.8074539 ,   2.71006   ],\n",
       "        [  5.084667  ,  -3.900648  ,  12.28177   , ...,  -0.7672844 ,\n",
       "           2.181755  ,   4.326027  ]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' More Preprocessing '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scalers = {}\n",
    "for i in range(X.shape[1]):\n",
    "    scalers[i] = RobustScaler()\n",
    "    X[:, i, :] = scalers[i].fit_transform(X[:, i, :]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scalers = {}\n",
    "for i in range(X.shape[1]):\n",
    "    scalers[i] = Normalizer()\n",
    "    X[:, i, :] = scalers[i].fit_transform(X[:, i, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.28221284,  0.08020835, -0.09187018,\n",
       "       -0.10788761,  0.62792463,  0.3675004 ,  0.16599244,  0.18636285,\n",
       "       -0.35420188,  0.19850305, -0.14629544, -0.18601133, -0.21646694,\n",
       "        0.18571278])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 502992 into shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a444714b1a9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 502992 into shape (1,)"
     ]
    }
   ],
   "source": [
    "X_train.reshape(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Finishing Preprocessing '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See X and y details\n",
    "print(X[:2])\n",
    "print(X.shape)\n",
    "\n",
    "print(y[:3])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "9.105775999999999\n",
      "(1364, 504)\n",
      "\n",
      "X_test:\n",
      "\n",
      "-0.1714754\n",
      "(585, 504)\n",
      "\n",
      "y_train:\n",
      "\n",
      "[2 1 2]\n",
      "(1364,)\n",
      "\n",
      "y_test:\n",
      "\n",
      "[1 2 2]\n",
      "(585,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in train and test\n",
    "\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train[0][0])\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(X_test[0][0])\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"\\ny_train:\\n\")\n",
    "print(y_train[:3])\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\ny_test:\\n\")\n",
    "print(y_test[:3])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical matrices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-9ae14aac2254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnum_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "num_rows = X[0].shape[0]\n",
    "num_columns = X[0].shape[1]\n",
    "num_channels = 1\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train[0][0])\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(X_test[0][0])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-k category accuracy\n",
    "import functools\n",
    "import keras\n",
    "top3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv1d_3_input to have 3 dimensions, but got array with shape (1364, 504)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-f7b1a1c48611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlr_reduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmcp_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../models/model_checkpoints/two_split.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcnnhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmcp_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_reduce\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv1d_3_input to have 3 dimensions, but got array with shape (1364, 504)"
     ]
    }
   ],
   "source": [
    "# Define bath and epochs\n",
    "batch_size = 256\n",
    "epochs = 400\n",
    "checkpoint_file = '../models/model_checkpoints/original_window_2.h5'\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',top3_acc])\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.0000001)\n",
    "mcp_save = ModelCheckpoint('../models/model_checkpoints/two_split.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "cnnhistory=model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, y_test), callbacks=[mcp_save, lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6239316463470459\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = cnnhistory.history['val_accuracy']\n",
    "highest_index = cnnhistory.history['val_accuracy'].index(np.sort(cnnhistory.history['val_accuracy'])[-1])\n",
    "print(cnnhistory.history['val_accuracy'][highest_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without prepocessing: 0.5863248109817505\n",
    "# robust preprocessing: 0.6034188270568848\n",
    "# normalization: 0.6239316463470459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model Summary\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# PLT History info\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
