{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and program variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split # to split dataset into train and test\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from time_series_dataset_loader import TimeSeriesDatasetLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../vote_daset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa530b48085b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../vote_daset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../vote_daset.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('../../vote_daset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize_dataset(dataset):\n",
    "    ''' Returns a 1 dimensional representation from the dataset '''\n",
    "    new_dataset = []\n",
    "\n",
    "    for data_instance in dataset:\n",
    "        new_dataset_cell = []\n",
    "        for t_instance in data_instance:\n",
    "            for value in t_instance[2:]:\n",
    "                new_dataset_cell.append(value)\n",
    "\n",
    "        new_dataset.append(new_dataset_cell)\n",
    "    return np.asarray(new_dataset)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../../vote_daset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(X, y):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    max_len = len(X[0])\n",
    "    for row in X:\n",
    "        if len(row) > max_len:\n",
    "            max_len = len(row)\n",
    "\n",
    "    X = pad_sequences(X, maxlen=max_len, padding='post', dtype='float64')\n",
    "    X = linearize_dataset(X)\n",
    "    return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(128, 5,padding='same', input_shape=(504, 504)))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "#     model.add(Conv1D(64, 5,padding='same'))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(MaxPooling1D(pool_size=(8)))\n",
    "#     model.add(Conv1D(32, 5,padding='same',))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(3))\n",
    "#     model.add(Activation('softmax'))\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(1, 504))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.full(100, 2)\n",
    "b = np.full(2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_VALUES = np.where(y==1)[0]\n",
    "NEUTRAL_VALUES = np.where(y==0)[0]\n",
    "NEGATIVE_VALUES = np.where(y==2)[0][0:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(X, y):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    POSITIVE_VALUES = np.where(y==1)[0]\n",
    "    NEUTRAL_VALUES = np.where(y==0)[0]\n",
    "    NEGATIVE_VALUES = np.where(y==2)[0][0:600]\n",
    "    all_indexes = POSITIVE_VALUES.tolist() + NEUTRAL_VALUES.tolist() + NEGATIVE_VALUES.tolist()\n",
    "    new_y = np.full(len(POSITIVE_VALUES), 1).tolist() \\\n",
    "        + np.full(len(NEUTRAL_VALUES), 0).tolist() \\\n",
    "        + np.full(len(NEGATIVE_VALUES), 2).tolist()\n",
    "    \n",
    "    \n",
    "    return np.take(X, all_indexes), new_y\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.take(X, all_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../../vote_dataset.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(DATASET_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe[['0', '1', '2', '3', '4', '5', '6']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataframe['7'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 0, ..., 0, 6, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_X = []\n",
    "for instx in X:\n",
    "    binary_X.append([val for val in map(lambda x: 1 if x>0.5 else 0, instx)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 1],\n",
       " [1, 0, 0, 0, 1, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 1, 0, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1, 1, 0],\n",
       " [0, 0, 1, 0, 1, 0, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 1, 0, 1, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 1, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 1, 0, 0, 0, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 1, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 1, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 1, 0],\n",
       " [1, 1, 0, 0, 1, 0, 0],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [0, 1, 1, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 1, 0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 1, 0, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 1],\n",
       " [1, 0, 1, 0, 1, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0],\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def run_classifier(classifier, params, X, y):\n",
    "    clf = GridSearchCV(classifier, params)\n",
    "    clf.fit(X, y)\n",
    "#     clf.transform(X)\n",
    "    return pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear Regression ##\n",
    "\n",
    "from sklearn import linear_model\n",
    "classifier = linear_model.LinearRegression()\n",
    "params = {}\n",
    "# run_classifier(clf, params, X, to_categorical(y))\n",
    "\n",
    "##########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 0, ..., 0, 6, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003890</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>svd</td>\n",
       "      <td>{'solver': 'svd'}</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.27897</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.331897</td>\n",
       "      <td>0.301572</td>\n",
       "      <td>0.019891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>{'solver': 'lsqr'}</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.27897</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.331897</td>\n",
       "      <td>0.301572</td>\n",
       "      <td>0.019891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007504</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>eigen</td>\n",
       "      <td>{'solver': 'eigen'}</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.27897</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.331897</td>\n",
       "      <td>0.301572</td>\n",
       "      <td>0.019891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_solver  \\\n",
       "0       0.003890      0.000596         0.000725        0.000240          svd   \n",
       "1       0.006782      0.002962         0.001145        0.000435         lsqr   \n",
       "2       0.007504      0.002470         0.001119        0.000714        eigen   \n",
       "\n",
       "                params  split0_test_score  split1_test_score  \\\n",
       "0    {'solver': 'svd'}           0.287554           0.317597   \n",
       "1   {'solver': 'lsqr'}           0.287554           0.317597   \n",
       "2  {'solver': 'eigen'}           0.287554           0.317597   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0            0.27897           0.291845           0.331897         0.301572   \n",
       "1            0.27897           0.291845           0.331897         0.301572   \n",
       "2            0.27897           0.291845           0.331897         0.301572   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.019891                1  \n",
       "1        0.019891                1  \n",
       "2        0.019891                1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LDA ####\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "params = {'solver': ['svd', 'lsqr', 'eigen']} \n",
    "run_classifier(clf, params, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.248927</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.271552</td>\n",
       "      <td>0.273194</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.533699</td>\n",
       "      <td>0.058332</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1, 'kernel': 'poly'}</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.360515</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.330768</td>\n",
       "      <td>0.023205</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.049277</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.008504</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.339056</td>\n",
       "      <td>0.323276</td>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104571</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 1, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.145923</td>\n",
       "      <td>0.137339</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>0.150374</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 2, 'kernel': 'linear'}</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.275788</td>\n",
       "      <td>0.015486</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.103830</td>\n",
       "      <td>0.108768</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>2</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 2, 'kernel': 'poly'}</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.356223</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>0.335929</td>\n",
       "      <td>0.020879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.055323</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.008697</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 2, 'kernel': 'rbf'}</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.336207</td>\n",
       "      <td>0.322177</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.107927</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 2, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.145923</td>\n",
       "      <td>0.137339</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>0.150374</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.037819</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 4, 'kernel': 'linear'}</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.301724</td>\n",
       "      <td>0.284379</td>\n",
       "      <td>0.017713</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.123775</td>\n",
       "      <td>0.126752</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>4</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 4, 'kernel': 'poly'}</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.343348</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.335086</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.052284</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>4</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 4, 'kernel': 'rbf'}</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.340517</td>\n",
       "      <td>0.323897</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.097933</td>\n",
       "      <td>0.007676</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>4</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 4, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.145923</td>\n",
       "      <td>0.137339</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>0.150374</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.034834</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 5, 'kernel': 'linear'}</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.301724</td>\n",
       "      <td>0.290388</td>\n",
       "      <td>0.015201</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.488437</td>\n",
       "      <td>0.182542</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 5, 'kernel': 'poly'}</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.351931</td>\n",
       "      <td>0.343348</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.339367</td>\n",
       "      <td>0.017563</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.053115</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>5</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 5, 'kernel': 'rbf'}</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.347639</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.323901</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.088936</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.013445</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>5</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 5, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.145923</td>\n",
       "      <td>0.137339</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>0.150374</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.033728</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>6</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 6, 'kernel': 'linear'}</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.301724</td>\n",
       "      <td>0.285238</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.965027</td>\n",
       "      <td>0.153609</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>6</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 6, 'kernel': 'poly'}</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.347639</td>\n",
       "      <td>0.343348</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.337650</td>\n",
       "      <td>0.017718</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.051291</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>6</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 6, 'kernel': 'rbf'}</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.339056</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.353448</td>\n",
       "      <td>0.327342</td>\n",
       "      <td>0.016399</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.089539</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.012479</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>6</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 6, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.145923</td>\n",
       "      <td>0.137339</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>0.150374</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.032985</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 8, 'kernel': 'linear'}</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.297414</td>\n",
       "      <td>0.288667</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.949007</td>\n",
       "      <td>0.416374</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>8</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 8, 'kernel': 'poly'}</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.356223</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>0.335071</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.058003</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.007994</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>8</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 8, 'kernel': 'rbf'}</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>0.324771</td>\n",
       "      <td>0.018269</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.118523</td>\n",
       "      <td>0.019701</td>\n",
       "      <td>0.018170</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>8</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 8, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.145923</td>\n",
       "      <td>0.137339</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>0.150374</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.010839</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.301724</td>\n",
       "      <td>0.288671</td>\n",
       "      <td>0.017858</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.956560</td>\n",
       "      <td>0.251317</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 10, 'kernel': 'poly'}</td>\n",
       "      <td>0.343348</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.360515</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.370690</td>\n",
       "      <td>0.339374</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.067598</td>\n",
       "      <td>0.009504</td>\n",
       "      <td>0.008327</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.336207</td>\n",
       "      <td>0.319602</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.104509</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>0.014667</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 10, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.145923</td>\n",
       "      <td>0.137339</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.141631</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>0.150374</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.035000      0.004433         0.005815        0.001282       1   \n",
       "1        0.533699      0.058332         0.007199        0.000941       1   \n",
       "2        0.049277      0.002601         0.008504        0.001260       1   \n",
       "3        0.104571      0.005356         0.015046        0.001674       1   \n",
       "4        0.033715      0.001987         0.006013        0.001080       2   \n",
       "5        1.103830      0.108768         0.006635        0.001061       2   \n",
       "6        0.055323      0.002872         0.008697        0.001151       2   \n",
       "7        0.107927      0.004644         0.015555        0.001673       2   \n",
       "8        0.037819      0.002624         0.006433        0.000792       4   \n",
       "9        2.123775      0.126752         0.005666        0.001152       4   \n",
       "10       0.052284      0.004593         0.007646        0.000474       4   \n",
       "11       0.097933      0.007676         0.013889        0.002420       4   \n",
       "12       0.034834      0.002049         0.005162        0.000583       5   \n",
       "13       2.488437      0.182542         0.005311        0.000935       5   \n",
       "14       0.053115      0.002447         0.007596        0.001058       5   \n",
       "15       0.088936      0.003143         0.013445        0.002062       5   \n",
       "16       0.033728      0.001564         0.005769        0.001423       6   \n",
       "17       2.965027      0.153609         0.005334        0.000369       6   \n",
       "18       0.051291      0.001388         0.007246        0.000944       6   \n",
       "19       0.089539      0.003393         0.012479        0.000907       6   \n",
       "20       0.032985      0.001336         0.005069        0.001118       8   \n",
       "21       3.949007      0.416374         0.005790        0.001121       8   \n",
       "22       0.058003      0.001185         0.007994        0.000607       8   \n",
       "23       0.118523      0.019701         0.018170        0.003799       8   \n",
       "24       0.061200      0.008979         0.010839        0.002320      10   \n",
       "25       4.956560      0.251317         0.005471        0.001113      10   \n",
       "26       0.067598      0.009504         0.008327        0.002549      10   \n",
       "27       0.104509      0.007626         0.014667        0.001154      10   \n",
       "\n",
       "   param_kernel                          params  split0_test_score  \\\n",
       "0        linear    {'C': 1, 'kernel': 'linear'}           0.296137   \n",
       "1          poly      {'C': 1, 'kernel': 'poly'}           0.321888   \n",
       "2           rbf       {'C': 1, 'kernel': 'rbf'}           0.330472   \n",
       "3       sigmoid   {'C': 1, 'kernel': 'sigmoid'}           0.145923   \n",
       "4        linear    {'C': 2, 'kernel': 'linear'}           0.287554   \n",
       "5          poly      {'C': 2, 'kernel': 'poly'}           0.330472   \n",
       "6           rbf       {'C': 2, 'kernel': 'rbf'}           0.330472   \n",
       "7       sigmoid   {'C': 2, 'kernel': 'sigmoid'}           0.145923   \n",
       "8        linear    {'C': 4, 'kernel': 'linear'}           0.300429   \n",
       "9          poly      {'C': 4, 'kernel': 'poly'}           0.321888   \n",
       "10          rbf       {'C': 4, 'kernel': 'rbf'}           0.326180   \n",
       "11      sigmoid   {'C': 4, 'kernel': 'sigmoid'}           0.145923   \n",
       "12       linear    {'C': 5, 'kernel': 'linear'}           0.300429   \n",
       "13         poly      {'C': 5, 'kernel': 'poly'}           0.326180   \n",
       "14          rbf       {'C': 5, 'kernel': 'rbf'}           0.313305   \n",
       "15      sigmoid   {'C': 5, 'kernel': 'sigmoid'}           0.145923   \n",
       "16       linear    {'C': 6, 'kernel': 'linear'}           0.304721   \n",
       "17         poly      {'C': 6, 'kernel': 'poly'}           0.321888   \n",
       "18          rbf       {'C': 6, 'kernel': 'rbf'}           0.317597   \n",
       "19      sigmoid   {'C': 6, 'kernel': 'sigmoid'}           0.145923   \n",
       "20       linear    {'C': 8, 'kernel': 'linear'}           0.304721   \n",
       "21         poly      {'C': 8, 'kernel': 'poly'}           0.334764   \n",
       "22          rbf       {'C': 8, 'kernel': 'rbf'}           0.309013   \n",
       "23      sigmoid   {'C': 8, 'kernel': 'sigmoid'}           0.145923   \n",
       "24       linear   {'C': 10, 'kernel': 'linear'}           0.309013   \n",
       "25         poly     {'C': 10, 'kernel': 'poly'}           0.343348   \n",
       "26          rbf      {'C': 10, 'kernel': 'rbf'}           0.313305   \n",
       "27      sigmoid  {'C': 10, 'kernel': 'sigmoid'}           0.145923   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.248927           0.266094           0.283262   \n",
       "1            0.334764           0.360515           0.291845   \n",
       "2            0.317597           0.296137           0.339056   \n",
       "3            0.137339           0.141631           0.141631   \n",
       "4            0.261803           0.283262           0.253219   \n",
       "5            0.334764           0.356223           0.300429   \n",
       "6            0.317597           0.296137           0.330472   \n",
       "7            0.137339           0.141631           0.141631   \n",
       "8            0.278970           0.287554           0.253219   \n",
       "9            0.317597           0.343348           0.317597   \n",
       "10           0.313305           0.330472           0.309013   \n",
       "11           0.137339           0.141631           0.141631   \n",
       "12           0.278970           0.304721           0.266094   \n",
       "13           0.313305           0.351931           0.343348   \n",
       "14           0.309013           0.347639           0.304721   \n",
       "15           0.137339           0.141631           0.141631   \n",
       "16           0.270386           0.296137           0.253219   \n",
       "17           0.313305           0.347639           0.343348   \n",
       "18           0.317597           0.339056           0.309013   \n",
       "19           0.137339           0.141631           0.141631   \n",
       "20           0.283262           0.300429           0.257511   \n",
       "21           0.313305           0.356223           0.313305   \n",
       "22           0.317597           0.330472           0.309013   \n",
       "23           0.137339           0.141631           0.141631   \n",
       "24           0.283262           0.291845           0.257511   \n",
       "25           0.304721           0.360515           0.317597   \n",
       "26           0.300429           0.334764           0.313305   \n",
       "27           0.137339           0.141631           0.141631   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.271552         0.273194        0.015936               21  \n",
       "1            0.344828         0.330768        0.023205                7  \n",
       "2            0.323276         0.321308        0.014493               13  \n",
       "3            0.185345         0.150374        0.017695               22  \n",
       "4            0.293103         0.275788        0.015486               20  \n",
       "5            0.357759         0.335929        0.020879                4  \n",
       "6            0.336207         0.322177        0.014377               12  \n",
       "7            0.185345         0.150374        0.017695               22  \n",
       "8            0.301724         0.284379        0.017713               19  \n",
       "9            0.375000         0.335086        0.022124                5  \n",
       "10           0.340517         0.323897        0.011475               11  \n",
       "11           0.185345         0.150374        0.017695               22  \n",
       "12           0.301724         0.290388        0.015201               15  \n",
       "13           0.362069         0.339367        0.017563                2  \n",
       "14           0.344828         0.323901        0.018457               10  \n",
       "15           0.185345         0.150374        0.017695               22  \n",
       "16           0.301724         0.285238        0.020080               18  \n",
       "17           0.362069         0.337650        0.017718                3  \n",
       "18           0.353448         0.327342        0.016399                8  \n",
       "19           0.185345         0.150374        0.017695               22  \n",
       "20           0.297414         0.288667        0.017161               17  \n",
       "21           0.357759         0.335071        0.019544                6  \n",
       "22           0.357759         0.324771        0.018269                9  \n",
       "23           0.185345         0.150374        0.017695               22  \n",
       "24           0.301724         0.288671        0.017858               16  \n",
       "25           0.370690         0.339374        0.024974                1  \n",
       "26           0.336207         0.319602        0.013802               14  \n",
       "27           0.185345         0.150374        0.017695               22  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SVM ###\n",
    "from sklearn.svm import SVC\n",
    "params = {'kernel':['linear', 'poly', 'rbf', 'sigmoid'], 'C':[1, 2, 4,5, 6, 8, 10]}\n",
    "svc = svm.SVC()\n",
    "run_classifier(svc, params,X, y)\n",
    "\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "NotImplementedError: shrinkage not supported\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_shrinkage</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003832</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>None</td>\n",
       "      <td>svd</td>\n",
       "      <td>{'shrinkage': None, 'solver': 'svd'}</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.331897</td>\n",
       "      <td>0.301572</td>\n",
       "      <td>0.019891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>None</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>{'shrinkage': None, 'solver': 'lsqr'}</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.331897</td>\n",
       "      <td>0.301572</td>\n",
       "      <td>0.019891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004455</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>None</td>\n",
       "      <td>eigen</td>\n",
       "      <td>{'shrinkage': None, 'solver': 'eigen'}</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.331897</td>\n",
       "      <td>0.301572</td>\n",
       "      <td>0.019891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>svd</td>\n",
       "      <td>{'shrinkage': 'auto', 'solver': 'svd'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>auto</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>{'shrinkage': 'auto', 'solver': 'lsqr'}</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.349138</td>\n",
       "      <td>0.297295</td>\n",
       "      <td>0.026949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>auto</td>\n",
       "      <td>eigen</td>\n",
       "      <td>{'shrinkage': 'auto', 'solver': 'eigen'}</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.349138</td>\n",
       "      <td>0.297295</td>\n",
       "      <td>0.026949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.003832      0.001135         0.000810        0.000289   \n",
       "1       0.004070      0.001029         0.000833        0.000468   \n",
       "2       0.004455      0.001658         0.000548        0.000164   \n",
       "3       0.000967      0.000155         0.000000        0.000000   \n",
       "4       0.011783      0.001667         0.000741        0.000338   \n",
       "5       0.013245      0.000364         0.000744        0.000197   \n",
       "\n",
       "  param_shrinkage param_solver                                    params  \\\n",
       "0            None          svd      {'shrinkage': None, 'solver': 'svd'}   \n",
       "1            None         lsqr     {'shrinkage': None, 'solver': 'lsqr'}   \n",
       "2            None        eigen    {'shrinkage': None, 'solver': 'eigen'}   \n",
       "3            auto          svd    {'shrinkage': 'auto', 'solver': 'svd'}   \n",
       "4            auto         lsqr   {'shrinkage': 'auto', 'solver': 'lsqr'}   \n",
       "5            auto        eigen  {'shrinkage': 'auto', 'solver': 'eigen'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.287554           0.317597           0.278970           0.291845   \n",
       "1           0.287554           0.317597           0.278970           0.291845   \n",
       "2           0.287554           0.317597           0.278970           0.291845   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4           0.287554           0.291845           0.270386           0.287554   \n",
       "5           0.287554           0.291845           0.270386           0.287554   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.331897         0.301572        0.019891                1  \n",
       "1           0.331897         0.301572        0.019891                1  \n",
       "2           0.331897         0.301572        0.019891                1  \n",
       "3                NaN              NaN             NaN                6  \n",
       "4           0.349138         0.297295        0.026949                4  \n",
       "5           0.349138         0.297295        0.026949                4  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LDA ###\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "params = {'solver':['svd', 'lsqr', 'eigen'], 'shrinkage':[None, 'auto']}\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "run_classifier(clf, params, )\n",
    "\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_algorithm</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 3, 'weigh...</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.223176</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.265473</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 3, 'weigh...</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.271552</td>\n",
       "      <td>0.292079</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.015342</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 5, 'weigh...</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>0.280949</td>\n",
       "      <td>0.030512</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 5, 'weigh...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.284357</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.016133</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>auto</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 7, 'weigh...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.279207</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>auto</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 7, 'weigh...</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>0.287802</td>\n",
       "      <td>0.024883</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.018849</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 10, 'weig...</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.269742</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 10, 'weig...</td>\n",
       "      <td>0.356223</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.295531</td>\n",
       "      <td>0.031328</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 50, 'weig...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.267241</td>\n",
       "      <td>0.288641</td>\n",
       "      <td>0.015364</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.007641</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 50, 'weig...</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.304114</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.022120</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 100, 'wei...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>0.294683</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 100, 'wei...</td>\n",
       "      <td>0.339056</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.323276</td>\n",
       "      <td>0.307574</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.016624</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 3, '...</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.223176</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.265473</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 3, '...</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.271552</td>\n",
       "      <td>0.292079</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 5, '...</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>0.280949</td>\n",
       "      <td>0.030512</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 5, '...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.284357</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.021170</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 7, '...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.279207</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 7, '...</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>0.287802</td>\n",
       "      <td>0.024883</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 10, ...</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.269742</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 10, ...</td>\n",
       "      <td>0.356223</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.295531</td>\n",
       "      <td>0.031328</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.023912</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 50, ...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.267241</td>\n",
       "      <td>0.288641</td>\n",
       "      <td>0.015364</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 50, ...</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.304114</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.023075</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 100,...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>0.294683</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.011971</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 100,...</td>\n",
       "      <td>0.339056</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.323276</td>\n",
       "      <td>0.307574</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.016118</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 3, 'we...</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.223176</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.265473</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 3, 'we...</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.271552</td>\n",
       "      <td>0.292079</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.015197</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 5, 'we...</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>0.280949</td>\n",
       "      <td>0.030512</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 5, 'we...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.284357</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 7, 'we...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.279207</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 7, 'we...</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>0.287802</td>\n",
       "      <td>0.024883</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.022910</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 10, 'w...</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.269742</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 10, 'w...</td>\n",
       "      <td>0.356223</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.295531</td>\n",
       "      <td>0.031328</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 50, 'w...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.267241</td>\n",
       "      <td>0.288641</td>\n",
       "      <td>0.015364</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 50, 'w...</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.304114</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.021345</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 100, '...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>0.294683</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.010874</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 100, '...</td>\n",
       "      <td>0.339056</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.323276</td>\n",
       "      <td>0.307574</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.032928</td>\n",
       "      <td>0.005219</td>\n",
       "      <td>brute</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 3, 'weig...</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.223176</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.265473</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>brute</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 3, 'weig...</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.271552</td>\n",
       "      <td>0.292079</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.006926</td>\n",
       "      <td>brute</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 5, 'weig...</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>0.280949</td>\n",
       "      <td>0.030512</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>brute</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 5, 'weig...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.284357</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.064588</td>\n",
       "      <td>0.019139</td>\n",
       "      <td>brute</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 7, 'weig...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.279207</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.027686</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>brute</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 7, 'weig...</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>0.287802</td>\n",
       "      <td>0.024883</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.050677</td>\n",
       "      <td>0.007368</td>\n",
       "      <td>brute</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 10, 'wei...</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.269742</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.018155</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>brute</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 10, 'wei...</td>\n",
       "      <td>0.356223</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.295531</td>\n",
       "      <td>0.031328</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.039843</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 50, 'wei...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.267241</td>\n",
       "      <td>0.288641</td>\n",
       "      <td>0.015364</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.025823</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 50, 'wei...</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.304114</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.054366</td>\n",
       "      <td>0.011695</td>\n",
       "      <td>brute</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 100, 'we...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>0.294683</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.031161</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>brute</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 100, 'we...</td>\n",
       "      <td>0.339056</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.323276</td>\n",
       "      <td>0.307574</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.002100      0.000582         0.022827        0.004043   \n",
       "1        0.001633      0.000557         0.003875        0.001204   \n",
       "2        0.001514      0.000465         0.015342        0.000689   \n",
       "3        0.001476      0.000352         0.003824        0.000926   \n",
       "4        0.001474      0.000258         0.016133        0.002052   \n",
       "5        0.001438      0.000481         0.004006        0.000937   \n",
       "6        0.001647      0.000535         0.018849        0.002820   \n",
       "7        0.001200      0.000085         0.003962        0.000461   \n",
       "8        0.001315      0.000307         0.020377        0.001917   \n",
       "9        0.001397      0.000275         0.007641        0.000764   \n",
       "10       0.001475      0.000496         0.022120        0.001105   \n",
       "11       0.001452      0.000334         0.013172        0.001697   \n",
       "12       0.001040      0.000095         0.016624        0.002257   \n",
       "13       0.001730      0.000676         0.004543        0.000303   \n",
       "14       0.001566      0.000373         0.018919        0.002773   \n",
       "15       0.001260      0.000129         0.005481        0.000762   \n",
       "16       0.001677      0.000292         0.021170        0.003513   \n",
       "17       0.001274      0.000338         0.005046        0.001158   \n",
       "18       0.002065      0.000513         0.018401        0.001036   \n",
       "19       0.001542      0.000540         0.005586        0.000801   \n",
       "20       0.001518      0.000315         0.023912        0.001107   \n",
       "21       0.001282      0.000176         0.009651        0.002003   \n",
       "22       0.001064      0.000164         0.023075        0.001853   \n",
       "23       0.001431      0.000351         0.011971        0.000872   \n",
       "24       0.001600      0.000329         0.016118        0.002587   \n",
       "25       0.001437      0.000393         0.003903        0.001040   \n",
       "26       0.001669      0.000326         0.015197        0.001633   \n",
       "27       0.001310      0.000253         0.003820        0.001147   \n",
       "28       0.001254      0.000161         0.016558        0.000683   \n",
       "29       0.001677      0.000700         0.004966        0.001538   \n",
       "30       0.002408      0.000973         0.022910        0.002954   \n",
       "31       0.001621      0.000437         0.005847        0.001216   \n",
       "32       0.002370      0.000970         0.022207        0.002048   \n",
       "33       0.001543      0.000430         0.007650        0.001244   \n",
       "34       0.001164      0.000084         0.021345        0.001517   \n",
       "35       0.001197      0.000051         0.010874        0.001218   \n",
       "36       0.001174      0.000318         0.032928        0.005219   \n",
       "37       0.001192      0.000139         0.012943        0.005132   \n",
       "38       0.006642      0.005306         0.043593        0.006926   \n",
       "39       0.002465      0.002553         0.015533        0.005578   \n",
       "40       0.001379      0.000480         0.064588        0.019139   \n",
       "41       0.001658      0.000653         0.027686        0.005366   \n",
       "42       0.001094      0.000167         0.050677        0.007368   \n",
       "43       0.001492      0.000864         0.018155        0.007561   \n",
       "44       0.001237      0.000236         0.039843        0.007935   \n",
       "45       0.001041      0.000042         0.025823        0.006882   \n",
       "46       0.001307      0.000240         0.054366        0.011695   \n",
       "47       0.001486      0.000616         0.031161        0.003737   \n",
       "\n",
       "   param_algorithm param_n_neighbors param_weights  \\\n",
       "0             auto                 3       uniform   \n",
       "1             auto                 3      distance   \n",
       "2             auto                 5       uniform   \n",
       "3             auto                 5      distance   \n",
       "4             auto                 7       uniform   \n",
       "5             auto                 7      distance   \n",
       "6             auto                10       uniform   \n",
       "7             auto                10      distance   \n",
       "8             auto                50       uniform   \n",
       "9             auto                50      distance   \n",
       "10            auto               100       uniform   \n",
       "11            auto               100      distance   \n",
       "12       ball_tree                 3       uniform   \n",
       "13       ball_tree                 3      distance   \n",
       "14       ball_tree                 5       uniform   \n",
       "15       ball_tree                 5      distance   \n",
       "16       ball_tree                 7       uniform   \n",
       "17       ball_tree                 7      distance   \n",
       "18       ball_tree                10       uniform   \n",
       "19       ball_tree                10      distance   \n",
       "20       ball_tree                50       uniform   \n",
       "21       ball_tree                50      distance   \n",
       "22       ball_tree               100       uniform   \n",
       "23       ball_tree               100      distance   \n",
       "24         kd_tree                 3       uniform   \n",
       "25         kd_tree                 3      distance   \n",
       "26         kd_tree                 5       uniform   \n",
       "27         kd_tree                 5      distance   \n",
       "28         kd_tree                 7       uniform   \n",
       "29         kd_tree                 7      distance   \n",
       "30         kd_tree                10       uniform   \n",
       "31         kd_tree                10      distance   \n",
       "32         kd_tree                50       uniform   \n",
       "33         kd_tree                50      distance   \n",
       "34         kd_tree               100       uniform   \n",
       "35         kd_tree               100      distance   \n",
       "36           brute                 3       uniform   \n",
       "37           brute                 3      distance   \n",
       "38           brute                 5       uniform   \n",
       "39           brute                 5      distance   \n",
       "40           brute                 7       uniform   \n",
       "41           brute                 7      distance   \n",
       "42           brute                10       uniform   \n",
       "43           brute                10      distance   \n",
       "44           brute                50       uniform   \n",
       "45           brute                50      distance   \n",
       "46           brute               100       uniform   \n",
       "47           brute               100      distance   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'algorithm': 'auto', 'n_neighbors': 3, 'weigh...           0.287554   \n",
       "1   {'algorithm': 'auto', 'n_neighbors': 3, 'weigh...           0.309013   \n",
       "2   {'algorithm': 'auto', 'n_neighbors': 5, 'weigh...           0.326180   \n",
       "3   {'algorithm': 'auto', 'n_neighbors': 5, 'weigh...           0.313305   \n",
       "4   {'algorithm': 'auto', 'n_neighbors': 7, 'weigh...           0.313305   \n",
       "5   {'algorithm': 'auto', 'n_neighbors': 7, 'weigh...           0.330472   \n",
       "6   {'algorithm': 'auto', 'n_neighbors': 10, 'weig...           0.321888   \n",
       "7   {'algorithm': 'auto', 'n_neighbors': 10, 'weig...           0.356223   \n",
       "8   {'algorithm': 'auto', 'n_neighbors': 50, 'weig...           0.313305   \n",
       "9   {'algorithm': 'auto', 'n_neighbors': 50, 'weig...           0.321888   \n",
       "10  {'algorithm': 'auto', 'n_neighbors': 100, 'wei...           0.313305   \n",
       "11  {'algorithm': 'auto', 'n_neighbors': 100, 'wei...           0.339056   \n",
       "12  {'algorithm': 'ball_tree', 'n_neighbors': 3, '...           0.287554   \n",
       "13  {'algorithm': 'ball_tree', 'n_neighbors': 3, '...           0.309013   \n",
       "14  {'algorithm': 'ball_tree', 'n_neighbors': 5, '...           0.326180   \n",
       "15  {'algorithm': 'ball_tree', 'n_neighbors': 5, '...           0.313305   \n",
       "16  {'algorithm': 'ball_tree', 'n_neighbors': 7, '...           0.313305   \n",
       "17  {'algorithm': 'ball_tree', 'n_neighbors': 7, '...           0.330472   \n",
       "18  {'algorithm': 'ball_tree', 'n_neighbors': 10, ...           0.321888   \n",
       "19  {'algorithm': 'ball_tree', 'n_neighbors': 10, ...           0.356223   \n",
       "20  {'algorithm': 'ball_tree', 'n_neighbors': 50, ...           0.313305   \n",
       "21  {'algorithm': 'ball_tree', 'n_neighbors': 50, ...           0.321888   \n",
       "22  {'algorithm': 'ball_tree', 'n_neighbors': 100,...           0.313305   \n",
       "23  {'algorithm': 'ball_tree', 'n_neighbors': 100,...           0.339056   \n",
       "24  {'algorithm': 'kd_tree', 'n_neighbors': 3, 'we...           0.287554   \n",
       "25  {'algorithm': 'kd_tree', 'n_neighbors': 3, 'we...           0.309013   \n",
       "26  {'algorithm': 'kd_tree', 'n_neighbors': 5, 'we...           0.326180   \n",
       "27  {'algorithm': 'kd_tree', 'n_neighbors': 5, 'we...           0.313305   \n",
       "28  {'algorithm': 'kd_tree', 'n_neighbors': 7, 'we...           0.313305   \n",
       "29  {'algorithm': 'kd_tree', 'n_neighbors': 7, 'we...           0.330472   \n",
       "30  {'algorithm': 'kd_tree', 'n_neighbors': 10, 'w...           0.321888   \n",
       "31  {'algorithm': 'kd_tree', 'n_neighbors': 10, 'w...           0.356223   \n",
       "32  {'algorithm': 'kd_tree', 'n_neighbors': 50, 'w...           0.313305   \n",
       "33  {'algorithm': 'kd_tree', 'n_neighbors': 50, 'w...           0.321888   \n",
       "34  {'algorithm': 'kd_tree', 'n_neighbors': 100, '...           0.313305   \n",
       "35  {'algorithm': 'kd_tree', 'n_neighbors': 100, '...           0.339056   \n",
       "36  {'algorithm': 'brute', 'n_neighbors': 3, 'weig...           0.287554   \n",
       "37  {'algorithm': 'brute', 'n_neighbors': 3, 'weig...           0.309013   \n",
       "38  {'algorithm': 'brute', 'n_neighbors': 5, 'weig...           0.326180   \n",
       "39  {'algorithm': 'brute', 'n_neighbors': 5, 'weig...           0.313305   \n",
       "40  {'algorithm': 'brute', 'n_neighbors': 7, 'weig...           0.313305   \n",
       "41  {'algorithm': 'brute', 'n_neighbors': 7, 'weig...           0.330472   \n",
       "42  {'algorithm': 'brute', 'n_neighbors': 10, 'wei...           0.321888   \n",
       "43  {'algorithm': 'brute', 'n_neighbors': 10, 'wei...           0.356223   \n",
       "44  {'algorithm': 'brute', 'n_neighbors': 50, 'wei...           0.313305   \n",
       "45  {'algorithm': 'brute', 'n_neighbors': 50, 'wei...           0.321888   \n",
       "46  {'algorithm': 'brute', 'n_neighbors': 100, 'we...           0.313305   \n",
       "47  {'algorithm': 'brute', 'n_neighbors': 100, 'we...           0.339056   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.270386           0.270386           0.223176   \n",
       "1            0.274678           0.309013           0.296137   \n",
       "2            0.270386           0.257511           0.244635   \n",
       "3            0.278970           0.296137           0.257511   \n",
       "4            0.274678           0.257511           0.274678   \n",
       "5            0.278970           0.287554           0.253219   \n",
       "6            0.278970           0.253219           0.244635   \n",
       "7            0.270386           0.283262           0.274678   \n",
       "8            0.283262           0.296137           0.283262   \n",
       "9            0.309013           0.309013           0.287554   \n",
       "10           0.296137           0.283262           0.274678   \n",
       "11           0.296137           0.283262           0.296137   \n",
       "12           0.270386           0.270386           0.223176   \n",
       "13           0.274678           0.309013           0.296137   \n",
       "14           0.270386           0.257511           0.244635   \n",
       "15           0.278970           0.296137           0.257511   \n",
       "16           0.274678           0.257511           0.274678   \n",
       "17           0.278970           0.287554           0.253219   \n",
       "18           0.278970           0.253219           0.244635   \n",
       "19           0.270386           0.283262           0.274678   \n",
       "20           0.283262           0.296137           0.283262   \n",
       "21           0.309013           0.309013           0.287554   \n",
       "22           0.296137           0.283262           0.274678   \n",
       "23           0.296137           0.283262           0.296137   \n",
       "24           0.270386           0.270386           0.223176   \n",
       "25           0.274678           0.309013           0.296137   \n",
       "26           0.270386           0.257511           0.244635   \n",
       "27           0.278970           0.296137           0.257511   \n",
       "28           0.274678           0.257511           0.274678   \n",
       "29           0.278970           0.287554           0.253219   \n",
       "30           0.278970           0.253219           0.244635   \n",
       "31           0.270386           0.283262           0.274678   \n",
       "32           0.283262           0.296137           0.283262   \n",
       "33           0.309013           0.309013           0.287554   \n",
       "34           0.296137           0.283262           0.274678   \n",
       "35           0.296137           0.283262           0.296137   \n",
       "36           0.270386           0.270386           0.223176   \n",
       "37           0.274678           0.309013           0.296137   \n",
       "38           0.270386           0.257511           0.244635   \n",
       "39           0.278970           0.296137           0.257511   \n",
       "40           0.274678           0.257511           0.274678   \n",
       "41           0.278970           0.287554           0.253219   \n",
       "42           0.278970           0.253219           0.244635   \n",
       "43           0.270386           0.283262           0.274678   \n",
       "44           0.283262           0.296137           0.283262   \n",
       "45           0.309013           0.309013           0.287554   \n",
       "46           0.296137           0.283262           0.274678   \n",
       "47           0.296137           0.283262           0.296137   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.275862         0.265473        0.022058               45  \n",
       "1            0.271552         0.292079        0.016212               17  \n",
       "2            0.306034         0.280949        0.030512               33  \n",
       "3            0.275862         0.284357        0.018967               29  \n",
       "4            0.275862         0.279207        0.018361               37  \n",
       "5            0.288793         0.287802        0.024883               25  \n",
       "6            0.250000         0.269742        0.028627               41  \n",
       "7            0.293103         0.295531        0.031328                9  \n",
       "8            0.267241         0.288641        0.015364               21  \n",
       "9            0.293103         0.304114        0.012324                5  \n",
       "10           0.306034         0.294683        0.014201               13  \n",
       "11           0.323276         0.307574        0.020447                1  \n",
       "12           0.275862         0.265473        0.022058               45  \n",
       "13           0.271552         0.292079        0.016212               17  \n",
       "14           0.306034         0.280949        0.030512               33  \n",
       "15           0.275862         0.284357        0.018967               29  \n",
       "16           0.275862         0.279207        0.018361               37  \n",
       "17           0.288793         0.287802        0.024883               25  \n",
       "18           0.250000         0.269742        0.028627               41  \n",
       "19           0.293103         0.295531        0.031328                9  \n",
       "20           0.267241         0.288641        0.015364               21  \n",
       "21           0.293103         0.304114        0.012324                5  \n",
       "22           0.306034         0.294683        0.014201               13  \n",
       "23           0.323276         0.307574        0.020447                1  \n",
       "24           0.275862         0.265473        0.022058               45  \n",
       "25           0.271552         0.292079        0.016212               17  \n",
       "26           0.306034         0.280949        0.030512               33  \n",
       "27           0.275862         0.284357        0.018967               29  \n",
       "28           0.275862         0.279207        0.018361               37  \n",
       "29           0.288793         0.287802        0.024883               25  \n",
       "30           0.250000         0.269742        0.028627               41  \n",
       "31           0.293103         0.295531        0.031328                9  \n",
       "32           0.267241         0.288641        0.015364               21  \n",
       "33           0.293103         0.304114        0.012324                5  \n",
       "34           0.306034         0.294683        0.014201               13  \n",
       "35           0.323276         0.307574        0.020447                1  \n",
       "36           0.275862         0.265473        0.022058               45  \n",
       "37           0.271552         0.292079        0.016212               17  \n",
       "38           0.306034         0.280949        0.030512               33  \n",
       "39           0.275862         0.284357        0.018967               29  \n",
       "40           0.275862         0.279207        0.018361               37  \n",
       "41           0.288793         0.287802        0.024883               25  \n",
       "42           0.250000         0.269742        0.028627               41  \n",
       "43           0.293103         0.295531        0.031328                9  \n",
       "44           0.267241         0.288641        0.015364               21  \n",
       "45           0.293103         0.304114        0.012324                5  \n",
       "46           0.306034         0.294683        0.014201               13  \n",
       "47           0.323276         0.307574        0.020447                1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### KNN ###\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "params = {'n_neighbors':[3,5,7,10,50,100], 'weights':['uniform', 'distance'], \n",
    "         'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "clf = KNeighborsClassifier()\n",
    "run_classifier(clf, params, X, y)\n",
    "\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Naive Bayes ###\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "params = {}\n",
    "clf = GaussianNB()\n",
    "run_classifier(clf, params, X_train, X_test, y_train, y_test)\n",
    "\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decision Tree ###\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "params = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], 'min_samples_split':[2,4,6,10,20,50,100],\n",
    "         'min_samples_leaf':[1,2,5,10,20,50,100]}\n",
    "clf = DecisionTreeClassifier()\n",
    "run_classifier(clf, params, X_train, X_test, y_train, y_test)\n",
    "\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/gabriel/.pyenv/versions/machine-learning/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.099216</td>\n",
       "      <td>0.254667</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0001, 'm...</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.311884</td>\n",
       "      <td>0.022416</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.805539</td>\n",
       "      <td>0.208784</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0001, 'm...</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.284483</td>\n",
       "      <td>0.269772</td>\n",
       "      <td>0.008730</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.320917</td>\n",
       "      <td>0.346581</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0001, 'm...</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.323276</td>\n",
       "      <td>0.289548</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.093038</td>\n",
       "      <td>0.869015</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0005, 'm...</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.311884</td>\n",
       "      <td>0.023695</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.776346</td>\n",
       "      <td>0.199324</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0005, 'm...</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.240343</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.280172</td>\n",
       "      <td>0.268910</td>\n",
       "      <td>0.016128</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.402398</td>\n",
       "      <td>0.378572</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0005, 'm...</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.336207</td>\n",
       "      <td>0.294709</td>\n",
       "      <td>0.023001</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.269989</td>\n",
       "      <td>0.341112</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.005964</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.002, 'ma...</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.311026</td>\n",
       "      <td>0.025646</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.919401</td>\n",
       "      <td>0.388047</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.002, 'ma...</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.240343</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.267241</td>\n",
       "      <td>0.268041</td>\n",
       "      <td>0.015949</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.582799</td>\n",
       "      <td>0.709713</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.002, 'ma...</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.331897</td>\n",
       "      <td>0.289555</td>\n",
       "      <td>0.023947</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.981872</td>\n",
       "      <td>0.222343</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.005, 'ma...</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.312742</td>\n",
       "      <td>0.025015</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.578862</td>\n",
       "      <td>0.154729</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.005, 'ma...</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.256874</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.435497</td>\n",
       "      <td>0.644626</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.005, 'ma...</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.301724</td>\n",
       "      <td>0.286954</td>\n",
       "      <td>0.012847</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.821469</td>\n",
       "      <td>0.716492</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>identity</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0, 'max_...</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.340517</td>\n",
       "      <td>0.308447</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.951330</td>\n",
       "      <td>0.312144</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>identity</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0, 'max_...</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.231760</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.266331</td>\n",
       "      <td>0.019683</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.903097</td>\n",
       "      <td>0.338274</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>identity</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.0, 'max_...</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.336207</td>\n",
       "      <td>0.296426</td>\n",
       "      <td>0.020506</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.814913</td>\n",
       "      <td>0.689047</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0001, 'm...</td>\n",
       "      <td>0.339056</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.347639</td>\n",
       "      <td>0.347639</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.341953</td>\n",
       "      <td>0.024039</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.284586</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0001, 'm...</td>\n",
       "      <td>0.120172</td>\n",
       "      <td>0.124464</td>\n",
       "      <td>0.137339</td>\n",
       "      <td>0.137339</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.134897</td>\n",
       "      <td>0.012237</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.347305</td>\n",
       "      <td>0.702950</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0001, 'm...</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.240343</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.248927</td>\n",
       "      <td>0.271552</td>\n",
       "      <td>0.257744</td>\n",
       "      <td>0.011466</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.558898</td>\n",
       "      <td>0.922547</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0005, 'm...</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.339056</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.327586</td>\n",
       "      <td>0.328178</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.180795</td>\n",
       "      <td>0.044745</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0005, 'm...</td>\n",
       "      <td>0.145923</td>\n",
       "      <td>0.145923</td>\n",
       "      <td>0.107296</td>\n",
       "      <td>0.133047</td>\n",
       "      <td>0.133621</td>\n",
       "      <td>0.133162</td>\n",
       "      <td>0.014106</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.920418</td>\n",
       "      <td>0.714942</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0005, 'm...</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.280172</td>\n",
       "      <td>0.263760</td>\n",
       "      <td>0.012029</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16.432306</td>\n",
       "      <td>0.626465</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.002, 'ma...</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.347639</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.341113</td>\n",
       "      <td>0.031732</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.216270</td>\n",
       "      <td>0.040591</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.002, 'ma...</td>\n",
       "      <td>0.158798</td>\n",
       "      <td>0.133047</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.098712</td>\n",
       "      <td>0.211207</td>\n",
       "      <td>0.142671</td>\n",
       "      <td>0.039871</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.058304</td>\n",
       "      <td>1.364483</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.002, 'ma...</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>0.273209</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.126108</td>\n",
       "      <td>0.841944</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.005, 'ma...</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.356223</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.340517</td>\n",
       "      <td>0.327331</td>\n",
       "      <td>0.022936</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.308426</td>\n",
       "      <td>0.060859</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.005, 'ma...</td>\n",
       "      <td>0.188841</td>\n",
       "      <td>0.175966</td>\n",
       "      <td>0.227468</td>\n",
       "      <td>0.154506</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.190736</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.973568</td>\n",
       "      <td>0.930761</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.005, 'ma...</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.254310</td>\n",
       "      <td>0.270605</td>\n",
       "      <td>0.012734</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.359624</td>\n",
       "      <td>2.152116</td>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0, 'max_...</td>\n",
       "      <td>0.343348</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.351931</td>\n",
       "      <td>0.377682</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>0.345371</td>\n",
       "      <td>0.027087</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.193326</td>\n",
       "      <td>0.034694</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0, 'max_...</td>\n",
       "      <td>0.133047</td>\n",
       "      <td>0.098712</td>\n",
       "      <td>0.145923</td>\n",
       "      <td>0.188841</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.144339</td>\n",
       "      <td>0.029358</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.246054</td>\n",
       "      <td>0.310512</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.0, 'max_...</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>0.280935</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14.523076</td>\n",
       "      <td>2.103347</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'max_i...</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.369099</td>\n",
       "      <td>0.351931</td>\n",
       "      <td>0.331897</td>\n",
       "      <td>0.338482</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.814750</td>\n",
       "      <td>0.134360</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'max_i...</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.248927</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.280172</td>\n",
       "      <td>0.268910</td>\n",
       "      <td>0.011926</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.130306</td>\n",
       "      <td>1.657773</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'max_i...</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.291254</td>\n",
       "      <td>0.014297</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>13.302710</td>\n",
       "      <td>1.806738</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0005, 'max_i...</td>\n",
       "      <td>0.343348</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.349138</td>\n",
       "      <td>0.321330</td>\n",
       "      <td>0.023603</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.769271</td>\n",
       "      <td>0.526080</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0005, 'max_i...</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.248927</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.271552</td>\n",
       "      <td>0.268044</td>\n",
       "      <td>0.011123</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.595095</td>\n",
       "      <td>1.888811</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0005, 'max_i...</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.340517</td>\n",
       "      <td>0.305013</td>\n",
       "      <td>0.021160</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16.767321</td>\n",
       "      <td>7.305686</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.002, 'max_it...</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.347639</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.323276</td>\n",
       "      <td>0.323024</td>\n",
       "      <td>0.017670</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.882752</td>\n",
       "      <td>0.145504</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.002, 'max_it...</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.240343</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.280172</td>\n",
       "      <td>0.266335</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2.831321</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.002, 'max_it...</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.331897</td>\n",
       "      <td>0.298139</td>\n",
       "      <td>0.019033</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9.268254</td>\n",
       "      <td>0.191948</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.005, 'max_it...</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.347639</td>\n",
       "      <td>0.343348</td>\n",
       "      <td>0.301724</td>\n",
       "      <td>0.317856</td>\n",
       "      <td>0.028705</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2.809163</td>\n",
       "      <td>0.140297</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.005, 'max_it...</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.240343</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.267167</td>\n",
       "      <td>0.019073</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3.189790</td>\n",
       "      <td>1.096224</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.005, 'max_it...</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.353448</td>\n",
       "      <td>0.298157</td>\n",
       "      <td>0.028611</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9.130079</td>\n",
       "      <td>0.052426</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0, 'max_iter...</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.381974</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.346234</td>\n",
       "      <td>0.022199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.711890</td>\n",
       "      <td>0.157681</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0, 'max_iter...</td>\n",
       "      <td>0.287554</td>\n",
       "      <td>0.240343</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.262883</td>\n",
       "      <td>0.016537</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.545215</td>\n",
       "      <td>0.352429</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0, 'max_iter...</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.353448</td>\n",
       "      <td>0.295582</td>\n",
       "      <td>0.030483</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4.198092</td>\n",
       "      <td>0.047197</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'max_i...</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>0.316154</td>\n",
       "      <td>0.017543</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.556985</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'max_i...</td>\n",
       "      <td>0.240343</td>\n",
       "      <td>0.227468</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.256031</td>\n",
       "      <td>0.018775</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3.673250</td>\n",
       "      <td>0.486613</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'max_i...</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.317597</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4.235937</td>\n",
       "      <td>0.068112</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0005, 'max_i...</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.347639</td>\n",
       "      <td>0.343348</td>\n",
       "      <td>0.314655</td>\n",
       "      <td>0.314433</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2.556368</td>\n",
       "      <td>0.135463</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0005, 'max_i...</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.248927</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.262039</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3.388620</td>\n",
       "      <td>0.691839</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0005, 'max_i...</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>0.310178</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4.254443</td>\n",
       "      <td>0.145405</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.002, 'max_it...</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.323276</td>\n",
       "      <td>0.315299</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2.598247</td>\n",
       "      <td>0.158091</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.002, 'max_it...</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>0.259475</td>\n",
       "      <td>0.018715</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3.943520</td>\n",
       "      <td>0.265772</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.002, 'max_it...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.334764</td>\n",
       "      <td>0.370690</td>\n",
       "      <td>0.318773</td>\n",
       "      <td>0.031867</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4.406668</td>\n",
       "      <td>0.075866</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.005, 'max_it...</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>0.329921</td>\n",
       "      <td>0.015983</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2.606374</td>\n",
       "      <td>0.248942</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.005, 'max_it...</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.244635</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.280172</td>\n",
       "      <td>0.263760</td>\n",
       "      <td>0.012627</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3.663592</td>\n",
       "      <td>0.306095</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.005, 'max_it...</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.313305</td>\n",
       "      <td>0.370690</td>\n",
       "      <td>0.316198</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4.262458</td>\n",
       "      <td>0.085065</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0, 'max_iter...</td>\n",
       "      <td>0.330472</td>\n",
       "      <td>0.321888</td>\n",
       "      <td>0.339056</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.336207</td>\n",
       "      <td>0.325610</td>\n",
       "      <td>0.013890</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2.746862</td>\n",
       "      <td>0.184409</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0, 'max_iter...</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.261803</td>\n",
       "      <td>0.248927</td>\n",
       "      <td>0.236052</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>0.262050</td>\n",
       "      <td>0.018563</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3.748110</td>\n",
       "      <td>0.241889</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0, 'max_iter...</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.304721</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>0.311037</td>\n",
       "      <td>0.023577</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        4.099216      0.254667         0.001404        0.000194   \n",
       "1        2.805539      0.208784         0.001163        0.000336   \n",
       "2        2.320917      0.346581         0.000889        0.000136   \n",
       "3        4.093038      0.869015         0.002092        0.001009   \n",
       "4        2.776346      0.199324         0.000848        0.000207   \n",
       "5        2.402398      0.378572         0.001214        0.000305   \n",
       "6        4.269989      0.341112         0.006250        0.005964   \n",
       "7        2.919401      0.388047         0.001160        0.000568   \n",
       "8        2.582799      0.709713         0.000971        0.000495   \n",
       "9        3.981872      0.222343         0.001673        0.000435   \n",
       "10       2.578862      0.154729         0.001108        0.000475   \n",
       "11       2.435497      0.644626         0.001394        0.000622   \n",
       "12       4.821469      0.716492         0.001574        0.000543   \n",
       "13       2.951330      0.312144         0.001240        0.000468   \n",
       "14       1.903097      0.338274         0.000730        0.000032   \n",
       "15      15.814913      0.689047         0.002327        0.000658   \n",
       "16       0.284586      0.063965         0.001673        0.000226   \n",
       "17       2.347305      0.702950         0.001474        0.000545   \n",
       "18      16.558898      0.922547         0.002322        0.000565   \n",
       "19       0.180795      0.044745         0.001464        0.000342   \n",
       "20       2.920418      0.714942         0.001358        0.000243   \n",
       "21      16.432306      0.626465         0.003080        0.000738   \n",
       "22       0.216270      0.040591         0.001484        0.000492   \n",
       "23       3.058304      1.364483         0.001118        0.000159   \n",
       "24      16.126108      0.841944         0.002709        0.000464   \n",
       "25       0.308426      0.060859         0.002513        0.000738   \n",
       "26       2.973568      0.930761         0.001526        0.000738   \n",
       "27      13.359624      2.152116         0.005580        0.004653   \n",
       "28       0.193326      0.034694         0.001284        0.000397   \n",
       "29       2.246054      0.310512         0.001278        0.000367   \n",
       "30      14.523076      2.103347         0.003485        0.001253   \n",
       "31       3.814750      0.134360         0.001236        0.000249   \n",
       "32       5.130306      1.657773         0.001448        0.000484   \n",
       "33      13.302710      1.806738         0.002741        0.000297   \n",
       "34       3.769271      0.526080         0.001362        0.000458   \n",
       "35       5.595095      1.888811         0.001378        0.000203   \n",
       "36      16.767321      7.305686         0.002672        0.000369   \n",
       "37       2.882752      0.145504         0.001079        0.000033   \n",
       "38       2.831321      0.823988         0.001073        0.000007   \n",
       "39       9.268254      0.191948         0.002726        0.000073   \n",
       "40       2.809163      0.140297         0.001078        0.000040   \n",
       "41       3.189790      1.096224         0.001185        0.000184   \n",
       "42       9.130079      0.052426         0.002653        0.000029   \n",
       "43       2.711890      0.157681         0.001108        0.000041   \n",
       "44       2.545215      0.352429         0.001100        0.000028   \n",
       "45       4.198092      0.047197         0.001417        0.000015   \n",
       "46       2.556985      0.101743         0.000776        0.000049   \n",
       "47       3.673250      0.486613         0.001016        0.000215   \n",
       "48       4.235937      0.068112         0.001407        0.000017   \n",
       "49       2.556368      0.135463         0.000766        0.000031   \n",
       "50       3.388620      0.691839         0.000891        0.000180   \n",
       "51       4.254443      0.145405         0.001417        0.000011   \n",
       "52       2.598247      0.158091         0.000729        0.000015   \n",
       "53       3.943520      0.265772         0.001085        0.000163   \n",
       "54       4.406668      0.075866         0.001490        0.000065   \n",
       "55       2.606374      0.248942         0.000760        0.000009   \n",
       "56       3.663592      0.306095         0.000842        0.000159   \n",
       "57       4.262458      0.085065         0.001420        0.000036   \n",
       "58       2.746862      0.184409         0.000760        0.000037   \n",
       "59       3.748110      0.241889         0.000941        0.000195   \n",
       "\n",
       "   param_activation param_alpha param_max_iter param_solver  \\\n",
       "0          identity      0.0001           1000        lbfgs   \n",
       "1          identity      0.0001           1000          sgd   \n",
       "2          identity      0.0001           1000         adam   \n",
       "3          identity      0.0005           1000        lbfgs   \n",
       "4          identity      0.0005           1000          sgd   \n",
       "5          identity      0.0005           1000         adam   \n",
       "6          identity       0.002           1000        lbfgs   \n",
       "7          identity       0.002           1000          sgd   \n",
       "8          identity       0.002           1000         adam   \n",
       "9          identity       0.005           1000        lbfgs   \n",
       "10         identity       0.005           1000          sgd   \n",
       "11         identity       0.005           1000         adam   \n",
       "12         identity           0           1000        lbfgs   \n",
       "13         identity           0           1000          sgd   \n",
       "14         identity           0           1000         adam   \n",
       "15         logistic      0.0001           1000        lbfgs   \n",
       "16         logistic      0.0001           1000          sgd   \n",
       "17         logistic      0.0001           1000         adam   \n",
       "18         logistic      0.0005           1000        lbfgs   \n",
       "19         logistic      0.0005           1000          sgd   \n",
       "20         logistic      0.0005           1000         adam   \n",
       "21         logistic       0.002           1000        lbfgs   \n",
       "22         logistic       0.002           1000          sgd   \n",
       "23         logistic       0.002           1000         adam   \n",
       "24         logistic       0.005           1000        lbfgs   \n",
       "25         logistic       0.005           1000          sgd   \n",
       "26         logistic       0.005           1000         adam   \n",
       "27         logistic           0           1000        lbfgs   \n",
       "28         logistic           0           1000          sgd   \n",
       "29         logistic           0           1000         adam   \n",
       "30             tanh      0.0001           1000        lbfgs   \n",
       "31             tanh      0.0001           1000          sgd   \n",
       "32             tanh      0.0001           1000         adam   \n",
       "33             tanh      0.0005           1000        lbfgs   \n",
       "34             tanh      0.0005           1000          sgd   \n",
       "35             tanh      0.0005           1000         adam   \n",
       "36             tanh       0.002           1000        lbfgs   \n",
       "37             tanh       0.002           1000          sgd   \n",
       "38             tanh       0.002           1000         adam   \n",
       "39             tanh       0.005           1000        lbfgs   \n",
       "40             tanh       0.005           1000          sgd   \n",
       "41             tanh       0.005           1000         adam   \n",
       "42             tanh           0           1000        lbfgs   \n",
       "43             tanh           0           1000          sgd   \n",
       "44             tanh           0           1000         adam   \n",
       "45             relu      0.0001           1000        lbfgs   \n",
       "46             relu      0.0001           1000          sgd   \n",
       "47             relu      0.0001           1000         adam   \n",
       "48             relu      0.0005           1000        lbfgs   \n",
       "49             relu      0.0005           1000          sgd   \n",
       "50             relu      0.0005           1000         adam   \n",
       "51             relu       0.002           1000        lbfgs   \n",
       "52             relu       0.002           1000          sgd   \n",
       "53             relu       0.002           1000         adam   \n",
       "54             relu       0.005           1000        lbfgs   \n",
       "55             relu       0.005           1000          sgd   \n",
       "56             relu       0.005           1000         adam   \n",
       "57             relu           0           1000        lbfgs   \n",
       "58             relu           0           1000          sgd   \n",
       "59             relu           0           1000         adam   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'activation': 'identity', 'alpha': 0.0001, 'm...           0.300429   \n",
       "1   {'activation': 'identity', 'alpha': 0.0001, 'm...           0.266094   \n",
       "2   {'activation': 'identity', 'alpha': 0.0001, 'm...           0.270386   \n",
       "3   {'activation': 'identity', 'alpha': 0.0005, 'm...           0.300429   \n",
       "4   {'activation': 'identity', 'alpha': 0.0005, 'm...           0.283262   \n",
       "5   {'activation': 'identity', 'alpha': 0.0005, 'm...           0.300429   \n",
       "6   {'activation': 'identity', 'alpha': 0.002, 'ma...           0.300429   \n",
       "7   {'activation': 'identity', 'alpha': 0.002, 'ma...           0.278970   \n",
       "8   {'activation': 'identity', 'alpha': 0.002, 'ma...           0.283262   \n",
       "9   {'activation': 'identity', 'alpha': 0.005, 'ma...           0.300429   \n",
       "10  {'activation': 'identity', 'alpha': 0.005, 'ma...           0.257511   \n",
       "11  {'activation': 'identity', 'alpha': 0.005, 'ma...           0.278970   \n",
       "12  {'activation': 'identity', 'alpha': 0.0, 'max_...           0.300429   \n",
       "13  {'activation': 'identity', 'alpha': 0.0, 'max_...           0.283262   \n",
       "14  {'activation': 'identity', 'alpha': 0.0, 'max_...           0.291845   \n",
       "15  {'activation': 'logistic', 'alpha': 0.0001, 'm...           0.339056   \n",
       "16  {'activation': 'logistic', 'alpha': 0.0001, 'm...           0.120172   \n",
       "17  {'activation': 'logistic', 'alpha': 0.0001, 'm...           0.266094   \n",
       "18  {'activation': 'logistic', 'alpha': 0.0005, 'm...           0.330472   \n",
       "19  {'activation': 'logistic', 'alpha': 0.0005, 'm...           0.145923   \n",
       "20  {'activation': 'logistic', 'alpha': 0.0005, 'm...           0.266094   \n",
       "21  {'activation': 'logistic', 'alpha': 0.002, 'ma...           0.300429   \n",
       "22  {'activation': 'logistic', 'alpha': 0.002, 'ma...           0.158798   \n",
       "23  {'activation': 'logistic', 'alpha': 0.002, 'ma...           0.274678   \n",
       "24  {'activation': 'logistic', 'alpha': 0.005, 'ma...           0.330472   \n",
       "25  {'activation': 'logistic', 'alpha': 0.005, 'ma...           0.188841   \n",
       "26  {'activation': 'logistic', 'alpha': 0.005, 'ma...           0.270386   \n",
       "27  {'activation': 'logistic', 'alpha': 0.0, 'max_...           0.343348   \n",
       "28  {'activation': 'logistic', 'alpha': 0.0, 'max_...           0.133047   \n",
       "29  {'activation': 'logistic', 'alpha': 0.0, 'max_...           0.287554   \n",
       "30  {'activation': 'tanh', 'alpha': 0.0001, 'max_i...           0.326180   \n",
       "31  {'activation': 'tanh', 'alpha': 0.0001, 'max_i...           0.278970   \n",
       "32  {'activation': 'tanh', 'alpha': 0.0001, 'max_i...           0.291845   \n",
       "33  {'activation': 'tanh', 'alpha': 0.0005, 'max_i...           0.343348   \n",
       "34  {'activation': 'tanh', 'alpha': 0.0005, 'max_i...           0.283262   \n",
       "35  {'activation': 'tanh', 'alpha': 0.0005, 'max_i...           0.291845   \n",
       "36  {'activation': 'tanh', 'alpha': 0.002, 'max_it...           0.334764   \n",
       "37  {'activation': 'tanh', 'alpha': 0.002, 'max_it...           0.266094   \n",
       "38  {'activation': 'tanh', 'alpha': 0.002, 'max_it...           0.287554   \n",
       "39  {'activation': 'tanh', 'alpha': 0.005, 'max_it...           0.326180   \n",
       "40  {'activation': 'tanh', 'alpha': 0.005, 'max_it...           0.278970   \n",
       "41  {'activation': 'tanh', 'alpha': 0.005, 'max_it...           0.291845   \n",
       "42  {'activation': 'tanh', 'alpha': 0.0, 'max_iter...           0.326180   \n",
       "43  {'activation': 'tanh', 'alpha': 0.0, 'max_iter...           0.287554   \n",
       "44  {'activation': 'tanh', 'alpha': 0.0, 'max_iter...           0.283262   \n",
       "45  {'activation': 'relu', 'alpha': 0.0001, 'max_i...           0.334764   \n",
       "46  {'activation': 'relu', 'alpha': 0.0001, 'max_i...           0.240343   \n",
       "47  {'activation': 'relu', 'alpha': 0.0001, 'max_i...           0.317597   \n",
       "48  {'activation': 'relu', 'alpha': 0.0005, 'max_i...           0.300429   \n",
       "49  {'activation': 'relu', 'alpha': 0.0005, 'max_i...           0.261803   \n",
       "50  {'activation': 'relu', 'alpha': 0.0005, 'max_i...           0.309013   \n",
       "51  {'activation': 'relu', 'alpha': 0.002, 'max_it...           0.321888   \n",
       "52  {'activation': 'relu', 'alpha': 0.002, 'max_it...           0.244635   \n",
       "53  {'activation': 'relu', 'alpha': 0.002, 'max_it...           0.313305   \n",
       "54  {'activation': 'relu', 'alpha': 0.005, 'max_it...           0.309013   \n",
       "55  {'activation': 'relu', 'alpha': 0.005, 'max_it...           0.257511   \n",
       "56  {'activation': 'relu', 'alpha': 0.005, 'max_it...           0.313305   \n",
       "57  {'activation': 'relu', 'alpha': 0.0, 'max_iter...           0.330472   \n",
       "58  {'activation': 'relu', 'alpha': 0.0, 'max_iter...           0.274678   \n",
       "59  {'activation': 'relu', 'alpha': 0.0, 'max_iter...           0.300429   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.326180           0.278970           0.309013   \n",
       "1            0.261803           0.274678           0.261803   \n",
       "2            0.283262           0.287554           0.283262   \n",
       "3            0.326180           0.274678           0.313305   \n",
       "4            0.240343           0.261803           0.278970   \n",
       "5            0.270386           0.287554           0.278970   \n",
       "6            0.330472           0.270386           0.309013   \n",
       "7            0.240343           0.287554           0.266094   \n",
       "8            0.257511           0.287554           0.287554   \n",
       "9            0.334764           0.274678           0.309013   \n",
       "10           0.244635           0.261803           0.261803   \n",
       "11           0.266094           0.291845           0.296137   \n",
       "12           0.326180           0.270386           0.304721   \n",
       "13           0.231760           0.283262           0.257511   \n",
       "14           0.278970           0.291845           0.283262   \n",
       "15           0.300429           0.347639           0.347639   \n",
       "16           0.124464           0.137339           0.137339   \n",
       "17           0.240343           0.261803           0.248927   \n",
       "18           0.321888           0.339056           0.321888   \n",
       "19           0.145923           0.107296           0.133047   \n",
       "20           0.244635           0.270386           0.257511   \n",
       "21           0.326180           0.347639           0.334764   \n",
       "22           0.133047           0.111588           0.098712   \n",
       "23           0.257511           0.261803           0.283262   \n",
       "24           0.287554           0.356223           0.321888   \n",
       "25           0.175966           0.227468           0.154506   \n",
       "26           0.261803           0.274678           0.291845   \n",
       "27           0.296137           0.351931           0.377682   \n",
       "28           0.098712           0.145923           0.188841   \n",
       "29           0.270386           0.278970           0.278970   \n",
       "30           0.313305           0.369099           0.351931   \n",
       "31           0.248927           0.261803           0.274678   \n",
       "32           0.266094           0.296137           0.291845   \n",
       "33           0.283262           0.317597           0.313305   \n",
       "34           0.248927           0.270386           0.266094   \n",
       "35           0.283262           0.291845           0.317597   \n",
       "36           0.296137           0.347639           0.313305   \n",
       "37           0.240343           0.270386           0.274678   \n",
       "38           0.274678           0.296137           0.300429   \n",
       "39           0.270386           0.347639           0.343348   \n",
       "40           0.240343           0.291845           0.274678   \n",
       "41           0.270386           0.287554           0.287554   \n",
       "42           0.334764           0.326180           0.381974   \n",
       "43           0.240343           0.253219           0.274678   \n",
       "44           0.266094           0.296137           0.278970   \n",
       "45           0.300429           0.291845           0.334764   \n",
       "46           0.227468           0.270386           0.266094   \n",
       "47           0.309013           0.317597           0.334764   \n",
       "48           0.266094           0.347639           0.343348   \n",
       "49           0.253219           0.248927           0.270386   \n",
       "50           0.278970           0.300429           0.304721   \n",
       "51           0.291845           0.334764           0.304721   \n",
       "52           0.244635           0.274678           0.244635   \n",
       "53           0.278970           0.296137           0.334764   \n",
       "54           0.330472           0.321888           0.330472   \n",
       "55           0.244635           0.274678           0.261803   \n",
       "56           0.291845           0.291845           0.313305   \n",
       "57           0.321888           0.339056           0.300429   \n",
       "58           0.261803           0.248927           0.236052   \n",
       "59           0.296137           0.296137           0.304721   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.344828         0.311884        0.022416               20  \n",
       "1            0.284483         0.269772        0.008730               39  \n",
       "2            0.323276         0.289548        0.017820               34  \n",
       "3            0.344828         0.311884        0.023695               20  \n",
       "4            0.280172         0.268910        0.016128               40  \n",
       "5            0.336207         0.294709        0.023001               31  \n",
       "6            0.344828         0.311026        0.025646               23  \n",
       "7            0.267241         0.268041        0.015949               43  \n",
       "8            0.331897         0.289555        0.023947               33  \n",
       "9            0.344828         0.312742        0.025015               19  \n",
       "10           0.258621         0.256874        0.006353               54  \n",
       "11           0.301724         0.286954        0.012847               35  \n",
       "12           0.340517         0.308447        0.023957               25  \n",
       "13           0.275862         0.266331        0.019683               46  \n",
       "14           0.336207         0.296426        0.020506               29  \n",
       "15           0.375000         0.341953        0.024039                3  \n",
       "16           0.155172         0.134897        0.012237               59  \n",
       "17           0.271552         0.257744        0.011466               53  \n",
       "18           0.327586         0.328178        0.006373                7  \n",
       "19           0.133621         0.133162        0.014106               60  \n",
       "20           0.280172         0.263760        0.012029               47  \n",
       "21           0.396552         0.341113        0.031732                4  \n",
       "22           0.211207         0.142671        0.039871               58  \n",
       "23           0.288793         0.273209        0.012022               37  \n",
       "24           0.340517         0.327331        0.022936                9  \n",
       "25           0.206897         0.190736        0.025079               56  \n",
       "26           0.254310         0.270605        0.012734               38  \n",
       "27           0.357759         0.345371        0.027087                2  \n",
       "28           0.155172         0.144339        0.029358               57  \n",
       "29           0.288793         0.280935        0.006702               36  \n",
       "30           0.331897         0.338482        0.019733                5  \n",
       "31           0.280172         0.268910        0.011926               41  \n",
       "32           0.310345         0.291254        0.014297               32  \n",
       "33           0.349138         0.321330        0.023603               12  \n",
       "34           0.271552         0.268044        0.011123               42  \n",
       "35           0.340517         0.305013        0.021160               26  \n",
       "36           0.323276         0.323024        0.017670               11  \n",
       "37           0.280172         0.266335        0.013807               45  \n",
       "38           0.331897         0.298139        0.019033               28  \n",
       "39           0.301724         0.317856        0.028705               14  \n",
       "40           0.250000         0.267167        0.019073               44  \n",
       "41           0.353448         0.298157        0.028611               27  \n",
       "42           0.362069         0.346234        0.022199                1  \n",
       "43           0.258621         0.262883        0.016537               49  \n",
       "44           0.353448         0.295582        0.030483               30  \n",
       "45           0.318966         0.316154        0.017543               16  \n",
       "46           0.275862         0.256031        0.018775               55  \n",
       "47           0.357759         0.327346        0.017356                8  \n",
       "48           0.314655         0.314433        0.029905               18  \n",
       "49           0.275862         0.262039        0.010105               51  \n",
       "50           0.357759         0.310178        0.025939               24  \n",
       "51           0.323276         0.315299        0.015152               17  \n",
       "52           0.288793         0.259475        0.018715               52  \n",
       "53           0.370690         0.318773        0.031867               13  \n",
       "54           0.357759         0.329921        0.015983                6  \n",
       "55           0.280172         0.263760        0.012627               48  \n",
       "56           0.370690         0.316198        0.028887               15  \n",
       "57           0.336207         0.325610        0.013890               10  \n",
       "58           0.288793         0.262050        0.018563               50  \n",
       "59           0.357759         0.311037        0.023577               22  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MLP classifier ###\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "params = {\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.0005, 0.0020, 0.0050, 0., ] ,\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "clf = MLPClassifier()\n",
    "run_classifier(clf, params, X, y)\n",
    "\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traincnn = np.expand_dims(X_train, axis=0)\n",
    "X_testcnn = np.expand_dims(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(1, len(X_train), 504)\n",
    "X_test = X_test.reshape(1, len(X_test), 504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size  = 128\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "lstm_output_size = 70\n",
    "\n",
    "# Training\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(1, embedding_size, input_length=504))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=pool_size))\n",
    "model.add(LSTM(lstm_output_size))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=['accuracy'])\n",
    "cnnhistory=model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 500\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt, metrics=['accuracy'])\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.0000001)\n",
    "mcp_save = ModelCheckpoint('../model_checkpoints/two_split.h5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnhistory=model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, y_test))\n",
    "# , callbacks=[mcp_save, lr_reduce]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' More Preprocessing '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scalers = {}\n",
    "for i in range(X.shape[1]):\n",
    "    scalers[i] = RobustScaler()\n",
    "    X[:, i, :] = scalers[i].fit_transform(X[:, i, :]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scalers = {}\n",
    "for i in range(X.shape[1]):\n",
    "    scalers[i] = Normalizer()\n",
    "    X[:, i, :] = scalers[i].fit_transform(X[:, i, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reshape(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Finishing Preprocessing '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See X and y details\n",
    "print(X[:2])\n",
    "print(X.shape)\n",
    "\n",
    "print(y[:3])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset in train and test\n",
    "\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train[0][0])\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(X_test[0][0])\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"\\ny_train:\\n\")\n",
    "print(y_train[:3])\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\ny_test:\\n\")\n",
    "print(y_test[:3])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical matrices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = X[0].shape[0]\n",
    "num_columns = X[0].shape[1]\n",
    "num_channels = 1\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train[0][0])\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(X_test[0][0])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-k category accuracy\n",
    "import functools\n",
    "import keras\n",
    "top3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bath and epochs\n",
    "batch_size = 256\n",
    "epochs = 400\n",
    "checkpoint_file = '../models/model_checkpoints/original_window_2.h5'\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',top3_acc])\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.0000001)\n",
    "mcp_save = ModelCheckpoint('../models/model_checkpoints/two_split.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "cnnhistory=model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, y_test), callbacks=[mcp_save, lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = cnnhistory.history['val_accuracy']\n",
    "highest_index = cnnhistory.history['val_accuracy'].index(np.sort(cnnhistory.history['val_accuracy'])[-1])\n",
    "print(cnnhistory.history['val_accuracy'][highest_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without prepocessing: 0.5863248109817505\n",
    "# robust preprocessing: 0.6034188270568848\n",
    "# normalization: 0.6239316463470459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model Summary\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# PLT History info\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.4 64-bit ('machine-learning': venv)",
   "language": "python",
   "name": "python36464bitmachinelearningvenv22b173e40fb14778a7d876c9bd339153"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
