{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split # to split dataset into train and test\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from time_series_dataset_loader import TimeSeriesDatasetLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretization(X):\n",
    "    new_dataset = []\n",
    "    for data_instance in X:\n",
    "        new_instance = []\n",
    "        for row in data_instance:\n",
    "            new_instance.append(np.average(row[2:]))\n",
    "        new_dataset.append(new_instance)\n",
    "        \n",
    "    return np.asarray(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(X,y):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    max_len = len(X[0])\n",
    "    for row in X:\n",
    "        if len(row) > max_len:\n",
    "            max_len = len(row)\n",
    "\n",
    "    X = pad_sequences(X, maxlen=max_len, padding='post', dtype='float64')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_labels(labels, ignore_neutral=False):\n",
    "    new_labels = []\n",
    "    for value in labels:\n",
    "        if value in [3,5]:\n",
    "            new_labels.append(1)\n",
    "        else:\n",
    "            if value == 0 and not ignore_neutral:\n",
    "                new_labels.append(3)\n",
    "            else:\n",
    "                new_labels.append(2)\n",
    "    \n",
    "    return np.asarray(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(X):\n",
    "    new_dataset = []\n",
    "    for data_instance in X:\n",
    "        new_instance = []\n",
    "        for row in data_instance:\n",
    "            new_instance.append(row[2:])\n",
    "        new_dataset.append(new_instance)\n",
    "        \n",
    "    return np.asarray(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train, y_train, X_test, y_test):\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../../datasets/Original/MFCC_10'\n",
    "dataset_loader = TimeSeriesDatasetLoader(DATASET_PATH)\n",
    "X, y = dataset_loader.get_dataset(type_='default', ignore_neutral=False)\n",
    "X = data_preprocessing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = discretization(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = add_padding(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3)\n",
    "\n",
    "# Reshaping to apply smote\n",
    "shape_0 = X_train.shape[0]\n",
    "shape_1 = X_train.shape[1]\n",
    "shape_2 = X_train.shape[2]\n",
    "X_train = X_train.reshape(shape_0, shape_1 * shape_2)\n",
    "\n",
    "# Apply SMOTE\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)\n",
    "\n",
    "# Reshaping back to original shape dimensions 1 and 2\n",
    "X_train = X_train.reshape(X_train.shape[0], shape_1, shape_2)\n",
    "\n",
    "# Create categorical matrices\n",
    "y_test_labels = y_test\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Reshaping X to fit model\n",
    "num_rows = X[0].shape[0]\n",
    "num_columns = X[0].shape[1]\n",
    "num_channels = 1\n",
    "##############\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns,num_channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns,num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 854 samples, validate on 349 samples\n",
      "Epoch 1/300\n",
      " - 2s - loss: 2.0236 - accuracy: 0.1440 - val_loss: 1.9651 - val_accuracy: 0.1891\n",
      "Epoch 2/300\n",
      " - 2s - loss: 1.9644 - accuracy: 0.1546 - val_loss: 1.9310 - val_accuracy: 0.1777\n",
      "Epoch 3/300\n",
      " - 2s - loss: 1.9410 - accuracy: 0.1698 - val_loss: 1.9382 - val_accuracy: 0.1862\n",
      "Epoch 4/300\n",
      " - 2s - loss: 1.9292 - accuracy: 0.1897 - val_loss: 1.9310 - val_accuracy: 0.1748\n",
      "Epoch 5/300\n",
      " - 3s - loss: 1.9252 - accuracy: 0.1850 - val_loss: 1.9142 - val_accuracy: 0.2034\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.9180 - accuracy: 0.1920 - val_loss: 1.9015 - val_accuracy: 0.1777\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.9032 - accuracy: 0.1897 - val_loss: 1.8979 - val_accuracy: 0.2206\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.8948 - accuracy: 0.1932 - val_loss: 1.9021 - val_accuracy: 0.1891\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.8882 - accuracy: 0.2201 - val_loss: 1.8915 - val_accuracy: 0.2235\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.8701 - accuracy: 0.2283 - val_loss: 1.8975 - val_accuracy: 0.2092\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.8707 - accuracy: 0.2295 - val_loss: 1.8808 - val_accuracy: 0.2120\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.8551 - accuracy: 0.2166 - val_loss: 1.8732 - val_accuracy: 0.2006\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.8415 - accuracy: 0.2342 - val_loss: 1.8604 - val_accuracy: 0.2321\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.8359 - accuracy: 0.2400 - val_loss: 1.8497 - val_accuracy: 0.2521\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.8185 - accuracy: 0.2330 - val_loss: 1.8426 - val_accuracy: 0.2235\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.8116 - accuracy: 0.2670 - val_loss: 1.8499 - val_accuracy: 0.2350\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.8168 - accuracy: 0.2365 - val_loss: 1.8431 - val_accuracy: 0.2034\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.8063 - accuracy: 0.2635 - val_loss: 1.8797 - val_accuracy: 0.2235\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.7887 - accuracy: 0.2611 - val_loss: 1.8446 - val_accuracy: 0.2407\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.7892 - accuracy: 0.2623 - val_loss: 1.8295 - val_accuracy: 0.2350\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.7669 - accuracy: 0.2728 - val_loss: 1.8267 - val_accuracy: 0.2464\n",
      "Epoch 22/300\n",
      " - 3s - loss: 1.7614 - accuracy: 0.2705 - val_loss: 1.8272 - val_accuracy: 0.2436\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.7644 - accuracy: 0.3103 - val_loss: 1.8312 - val_accuracy: 0.2149\n",
      "Epoch 24/300\n",
      " - 3s - loss: 1.7581 - accuracy: 0.2728 - val_loss: 1.8586 - val_accuracy: 0.2464\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.7540 - accuracy: 0.2845 - val_loss: 1.8247 - val_accuracy: 0.2149\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.7289 - accuracy: 0.3091 - val_loss: 1.8171 - val_accuracy: 0.2321\n",
      "Epoch 27/300\n",
      " - 3s - loss: 1.7336 - accuracy: 0.3138 - val_loss: 1.8237 - val_accuracy: 0.2178\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.7263 - accuracy: 0.3208 - val_loss: 1.8137 - val_accuracy: 0.2378\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.6953 - accuracy: 0.3326 - val_loss: 1.8225 - val_accuracy: 0.2149\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.7130 - accuracy: 0.3126 - val_loss: 1.8362 - val_accuracy: 0.2235\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.6849 - accuracy: 0.3337 - val_loss: 1.8248 - val_accuracy: 0.2264\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.6823 - accuracy: 0.3326 - val_loss: 1.8294 - val_accuracy: 0.2178\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.6672 - accuracy: 0.3548 - val_loss: 1.8213 - val_accuracy: 0.2292\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.6448 - accuracy: 0.3489 - val_loss: 1.8248 - val_accuracy: 0.2264\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.6446 - accuracy: 0.3595 - val_loss: 1.8247 - val_accuracy: 0.2321\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.6524 - accuracy: 0.3255 - val_loss: 1.8409 - val_accuracy: 0.2378\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.6238 - accuracy: 0.3618 - val_loss: 1.8338 - val_accuracy: 0.2206\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.6423 - accuracy: 0.3431 - val_loss: 1.8282 - val_accuracy: 0.2436\n",
      "Epoch 39/300\n",
      " - 2s - loss: 1.6030 - accuracy: 0.3806 - val_loss: 1.8349 - val_accuracy: 0.2264\n",
      "Epoch 40/300\n",
      " - 3s - loss: 1.6019 - accuracy: 0.3607 - val_loss: 1.8349 - val_accuracy: 0.2321\n",
      "Epoch 41/300\n",
      " - 3s - loss: 1.6024 - accuracy: 0.3794 - val_loss: 1.8276 - val_accuracy: 0.2378\n",
      "Epoch 42/300\n",
      " - 2s - loss: 1.6018 - accuracy: 0.3841 - val_loss: 1.8481 - val_accuracy: 0.2350\n",
      "Epoch 43/300\n",
      " - 2s - loss: 1.5801 - accuracy: 0.3970 - val_loss: 1.8448 - val_accuracy: 0.2292\n",
      "Epoch 44/300\n",
      " - 2s - loss: 1.5892 - accuracy: 0.3770 - val_loss: 1.8318 - val_accuracy: 0.2407\n",
      "Epoch 45/300\n",
      " - 2s - loss: 1.5794 - accuracy: 0.3888 - val_loss: 1.8553 - val_accuracy: 0.2264\n",
      "Epoch 46/300\n",
      " - 2s - loss: 1.5627 - accuracy: 0.4028 - val_loss: 1.8380 - val_accuracy: 0.2579\n",
      "Epoch 47/300\n",
      " - 3s - loss: 1.5249 - accuracy: 0.4251 - val_loss: 1.8452 - val_accuracy: 0.2665\n",
      "Epoch 48/300\n",
      " - 2s - loss: 1.5285 - accuracy: 0.4262 - val_loss: 1.8724 - val_accuracy: 0.2464\n",
      "Epoch 49/300\n",
      " - 2s - loss: 1.5023 - accuracy: 0.4133 - val_loss: 1.8632 - val_accuracy: 0.2407\n",
      "Epoch 50/300\n",
      " - 2s - loss: 1.4829 - accuracy: 0.4356 - val_loss: 1.8665 - val_accuracy: 0.2350\n",
      "Epoch 51/300\n",
      " - 2s - loss: 1.4904 - accuracy: 0.4087 - val_loss: 1.8443 - val_accuracy: 0.2493\n",
      "Epoch 52/300\n",
      " - 2s - loss: 1.4640 - accuracy: 0.4403 - val_loss: 1.8577 - val_accuracy: 0.2579\n",
      "Epoch 53/300\n",
      " - 2s - loss: 1.4660 - accuracy: 0.4379 - val_loss: 1.8673 - val_accuracy: 0.2464\n",
      "Epoch 54/300\n",
      " - 2s - loss: 1.4326 - accuracy: 0.4532 - val_loss: 1.8882 - val_accuracy: 0.2550\n",
      "Epoch 55/300\n",
      " - 2s - loss: 1.4592 - accuracy: 0.4391 - val_loss: 1.9187 - val_accuracy: 0.2521\n",
      "Epoch 56/300\n",
      " - 2s - loss: 1.4338 - accuracy: 0.4637 - val_loss: 1.8790 - val_accuracy: 0.2693\n",
      "Epoch 57/300\n",
      " - 2s - loss: 1.4384 - accuracy: 0.4426 - val_loss: 1.8872 - val_accuracy: 0.2693\n",
      "Epoch 58/300\n",
      " - 2s - loss: 1.4118 - accuracy: 0.4649 - val_loss: 1.9325 - val_accuracy: 0.2149\n",
      "Epoch 59/300\n",
      " - 2s - loss: 1.4678 - accuracy: 0.4262 - val_loss: 1.8730 - val_accuracy: 0.2550\n",
      "Epoch 60/300\n",
      " - 2s - loss: 1.3949 - accuracy: 0.4883 - val_loss: 1.8985 - val_accuracy: 0.2178\n",
      "Epoch 61/300\n",
      " - 2s - loss: 1.3860 - accuracy: 0.4684 - val_loss: 1.8740 - val_accuracy: 0.2493\n",
      "Epoch 62/300\n",
      " - 2s - loss: 1.3622 - accuracy: 0.4977 - val_loss: 1.8964 - val_accuracy: 0.2665\n",
      "Epoch 63/300\n",
      " - 2s - loss: 1.3577 - accuracy: 0.5012 - val_loss: 1.8958 - val_accuracy: 0.2350\n",
      "Epoch 64/300\n",
      " - 2s - loss: 1.3456 - accuracy: 0.4965 - val_loss: 1.9106 - val_accuracy: 0.2378\n",
      "Epoch 65/300\n",
      " - 2s - loss: 1.3012 - accuracy: 0.4871 - val_loss: 1.9096 - val_accuracy: 0.2521\n",
      "Epoch 66/300\n",
      " - 2s - loss: 1.3486 - accuracy: 0.4859 - val_loss: 2.0091 - val_accuracy: 0.2206\n",
      "Epoch 67/300\n",
      " - 2s - loss: 1.3776 - accuracy: 0.4988 - val_loss: 1.9281 - val_accuracy: 0.2665\n",
      "Epoch 68/300\n",
      " - 2s - loss: 1.3145 - accuracy: 0.5000 - val_loss: 1.9758 - val_accuracy: 0.2378\n",
      "Epoch 69/300\n",
      " - 2s - loss: 1.3106 - accuracy: 0.5152 - val_loss: 1.9600 - val_accuracy: 0.2464\n",
      "Epoch 70/300\n",
      " - 2s - loss: 1.3014 - accuracy: 0.5141 - val_loss: 1.9762 - val_accuracy: 0.2378\n",
      "Epoch 71/300\n",
      " - 2s - loss: 1.2821 - accuracy: 0.5281 - val_loss: 1.9559 - val_accuracy: 0.2550\n",
      "Epoch 72/300\n",
      " - 2s - loss: 1.2526 - accuracy: 0.5468 - val_loss: 1.9723 - val_accuracy: 0.2464\n",
      "Epoch 73/300\n",
      " - 2s - loss: 1.2544 - accuracy: 0.5422 - val_loss: 1.9565 - val_accuracy: 0.2493\n",
      "Epoch 74/300\n",
      " - 2s - loss: 1.2404 - accuracy: 0.5398 - val_loss: 1.9722 - val_accuracy: 0.2636\n",
      "Epoch 75/300\n",
      " - 2s - loss: 1.2826 - accuracy: 0.5234 - val_loss: 1.9842 - val_accuracy: 0.2521\n",
      "Epoch 76/300\n",
      " - 2s - loss: 1.2528 - accuracy: 0.5234 - val_loss: 1.9521 - val_accuracy: 0.2407\n",
      "Epoch 77/300\n",
      " - 2s - loss: 1.2063 - accuracy: 0.5363 - val_loss: 1.9617 - val_accuracy: 0.2607\n",
      "Epoch 78/300\n",
      " - 2s - loss: 1.1990 - accuracy: 0.5632 - val_loss: 1.9826 - val_accuracy: 0.2636\n",
      "Epoch 79/300\n",
      " - 2s - loss: 1.2020 - accuracy: 0.5679 - val_loss: 1.9851 - val_accuracy: 0.2550\n",
      "Epoch 80/300\n",
      " - 2s - loss: 1.1809 - accuracy: 0.5761 - val_loss: 2.0032 - val_accuracy: 0.2521\n",
      "Epoch 81/300\n",
      " - 2s - loss: 1.1854 - accuracy: 0.5703 - val_loss: 1.9978 - val_accuracy: 0.2521\n",
      "Epoch 82/300\n",
      " - 2s - loss: 1.1918 - accuracy: 0.5691 - val_loss: 1.9929 - val_accuracy: 0.2550\n",
      "Epoch 83/300\n",
      " - 2s - loss: 1.1627 - accuracy: 0.5656 - val_loss: 1.9926 - val_accuracy: 0.2493\n",
      "Epoch 84/300\n",
      " - 2s - loss: 1.1591 - accuracy: 0.5726 - val_loss: 1.9834 - val_accuracy: 0.2751\n",
      "Epoch 85/300\n",
      " - 2s - loss: 1.1329 - accuracy: 0.5808 - val_loss: 2.0101 - val_accuracy: 0.2464\n",
      "Epoch 86/300\n",
      " - 2s - loss: 1.1589 - accuracy: 0.5726 - val_loss: 2.0687 - val_accuracy: 0.2521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/300\n",
      " - 2s - loss: 1.1171 - accuracy: 0.6124 - val_loss: 1.9941 - val_accuracy: 0.2579\n",
      "Epoch 88/300\n",
      " - 2s - loss: 1.1655 - accuracy: 0.5644 - val_loss: 2.0616 - val_accuracy: 0.2407\n",
      "Epoch 89/300\n",
      " - 2s - loss: 1.1275 - accuracy: 0.5948 - val_loss: 2.0273 - val_accuracy: 0.2607\n",
      "Epoch 90/300\n",
      " - 2s - loss: 1.0869 - accuracy: 0.6066 - val_loss: 2.0218 - val_accuracy: 0.2550\n",
      "Epoch 91/300\n",
      " - 2s - loss: 1.0778 - accuracy: 0.6148 - val_loss: 2.0562 - val_accuracy: 0.2407\n",
      "Epoch 92/300\n",
      " - 2s - loss: 1.0447 - accuracy: 0.6265 - val_loss: 2.0500 - val_accuracy: 0.2722\n",
      "Epoch 93/300\n",
      " - 2s - loss: 1.0649 - accuracy: 0.6124 - val_loss: 2.0941 - val_accuracy: 0.2321\n",
      "Epoch 94/300\n",
      " - 2s - loss: 1.0819 - accuracy: 0.5972 - val_loss: 2.0698 - val_accuracy: 0.2521\n",
      "Epoch 95/300\n",
      " - 2s - loss: 1.0499 - accuracy: 0.6276 - val_loss: 2.1035 - val_accuracy: 0.2436\n",
      "Epoch 96/300\n",
      " - 2s - loss: 1.0340 - accuracy: 0.6405 - val_loss: 2.0697 - val_accuracy: 0.2636\n",
      "Epoch 97/300\n",
      " - 2s - loss: 1.0284 - accuracy: 0.6347 - val_loss: 2.0733 - val_accuracy: 0.2722\n",
      "Epoch 98/300\n",
      " - 2s - loss: 1.0425 - accuracy: 0.6171 - val_loss: 2.0905 - val_accuracy: 0.2550\n",
      "Epoch 99/300\n",
      " - 2s - loss: 1.0483 - accuracy: 0.6171 - val_loss: 2.0815 - val_accuracy: 0.2521\n",
      "Epoch 100/300\n",
      " - 2s - loss: 0.9780 - accuracy: 0.6639 - val_loss: 2.1066 - val_accuracy: 0.2665\n",
      "Epoch 101/300\n",
      " - 2s - loss: 1.0075 - accuracy: 0.6417 - val_loss: 2.1072 - val_accuracy: 0.2636\n",
      "Epoch 102/300\n",
      " - 2s - loss: 1.0021 - accuracy: 0.6276 - val_loss: 2.1109 - val_accuracy: 0.2607\n",
      "Epoch 103/300\n",
      " - 2s - loss: 0.9697 - accuracy: 0.6534 - val_loss: 2.1113 - val_accuracy: 0.2579\n",
      "Epoch 104/300\n",
      " - 2s - loss: 0.9839 - accuracy: 0.6370 - val_loss: 2.0965 - val_accuracy: 0.2579\n",
      "Epoch 105/300\n",
      " - 2s - loss: 0.9952 - accuracy: 0.6405 - val_loss: 2.1110 - val_accuracy: 0.2436\n",
      "Epoch 106/300\n",
      " - 2s - loss: 0.9856 - accuracy: 0.6253 - val_loss: 2.1039 - val_accuracy: 0.2579\n",
      "Epoch 107/300\n",
      " - 3s - loss: 0.9656 - accuracy: 0.6358 - val_loss: 2.1251 - val_accuracy: 0.2464\n",
      "Epoch 108/300\n",
      " - 3s - loss: 0.9921 - accuracy: 0.6464 - val_loss: 2.1418 - val_accuracy: 0.2579\n",
      "Epoch 109/300\n",
      " - 3s - loss: 0.9704 - accuracy: 0.6429 - val_loss: 2.1201 - val_accuracy: 0.2579\n",
      "Epoch 110/300\n",
      " - 2s - loss: 0.9162 - accuracy: 0.6698 - val_loss: 2.1262 - val_accuracy: 0.2693\n",
      "Epoch 111/300\n",
      " - 2s - loss: 0.9289 - accuracy: 0.6815 - val_loss: 2.1267 - val_accuracy: 0.2579\n",
      "Epoch 112/300\n",
      " - 3s - loss: 0.9191 - accuracy: 0.6721 - val_loss: 2.1600 - val_accuracy: 0.2579\n",
      "Epoch 113/300\n",
      " - 2s - loss: 0.9424 - accuracy: 0.6475 - val_loss: 2.1495 - val_accuracy: 0.2464\n",
      "Epoch 114/300\n",
      " - 3s - loss: 0.8753 - accuracy: 0.6815 - val_loss: 2.1595 - val_accuracy: 0.2521\n",
      "Epoch 115/300\n",
      " - 3s - loss: 0.9026 - accuracy: 0.6768 - val_loss: 2.2225 - val_accuracy: 0.2378\n",
      "Epoch 116/300\n",
      " - 3s - loss: 0.8844 - accuracy: 0.6838 - val_loss: 2.1736 - val_accuracy: 0.2579\n",
      "Epoch 117/300\n",
      " - 3s - loss: 0.9588 - accuracy: 0.6674 - val_loss: 2.1781 - val_accuracy: 0.2607\n",
      "Epoch 118/300\n",
      " - 2s - loss: 0.8932 - accuracy: 0.6768 - val_loss: 2.1932 - val_accuracy: 0.2550\n",
      "Epoch 119/300\n",
      " - 2s - loss: 0.8689 - accuracy: 0.6838 - val_loss: 2.1866 - val_accuracy: 0.2607\n",
      "Epoch 120/300\n",
      " - 2s - loss: 0.8784 - accuracy: 0.6991 - val_loss: 2.1532 - val_accuracy: 0.2665\n",
      "Epoch 121/300\n",
      " - 2s - loss: 0.8668 - accuracy: 0.7037 - val_loss: 2.1915 - val_accuracy: 0.2550\n",
      "Epoch 122/300\n",
      " - 3s - loss: 0.8592 - accuracy: 0.6909 - val_loss: 2.1740 - val_accuracy: 0.2579\n",
      "Epoch 123/300\n",
      " - 2s - loss: 0.8825 - accuracy: 0.6792 - val_loss: 2.1855 - val_accuracy: 0.2607\n",
      "Epoch 124/300\n",
      " - 2s - loss: 0.8418 - accuracy: 0.7237 - val_loss: 2.1916 - val_accuracy: 0.2693\n",
      "Epoch 125/300\n",
      " - 2s - loss: 0.8711 - accuracy: 0.6792 - val_loss: 2.2008 - val_accuracy: 0.2808\n",
      "Epoch 126/300\n",
      " - 2s - loss: 0.8404 - accuracy: 0.7084 - val_loss: 2.2353 - val_accuracy: 0.2636\n",
      "Epoch 127/300\n",
      " - 2s - loss: 0.8358 - accuracy: 0.7026 - val_loss: 2.2070 - val_accuracy: 0.2665\n",
      "Epoch 128/300\n",
      " - 2s - loss: 0.8367 - accuracy: 0.7084 - val_loss: 2.2361 - val_accuracy: 0.2350\n",
      "Epoch 129/300\n",
      " - 2s - loss: 0.7814 - accuracy: 0.7248 - val_loss: 2.2348 - val_accuracy: 0.2579\n",
      "Epoch 130/300\n",
      " - 2s - loss: 0.7912 - accuracy: 0.7272 - val_loss: 2.2708 - val_accuracy: 0.2493\n",
      "Epoch 131/300\n",
      " - 2s - loss: 0.7765 - accuracy: 0.7248 - val_loss: 2.2205 - val_accuracy: 0.2521\n",
      "Epoch 132/300\n",
      " - 2s - loss: 0.7815 - accuracy: 0.7248 - val_loss: 2.2302 - val_accuracy: 0.2579\n",
      "Epoch 133/300\n",
      " - 2s - loss: 0.7700 - accuracy: 0.7424 - val_loss: 2.2437 - val_accuracy: 0.2779\n",
      "Epoch 134/300\n",
      " - 3s - loss: 0.7721 - accuracy: 0.7213 - val_loss: 2.2675 - val_accuracy: 0.2493\n",
      "Epoch 135/300\n",
      " - 2s - loss: 0.7856 - accuracy: 0.7096 - val_loss: 2.2874 - val_accuracy: 0.2550\n",
      "Epoch 136/300\n",
      " - 2s - loss: 0.8010 - accuracy: 0.6967 - val_loss: 2.2860 - val_accuracy: 0.2636\n",
      "Epoch 137/300\n",
      " - 3s - loss: 0.7898 - accuracy: 0.7295 - val_loss: 2.2834 - val_accuracy: 0.2436\n",
      "Epoch 138/300\n",
      " - 2s - loss: 0.7450 - accuracy: 0.7330 - val_loss: 2.3048 - val_accuracy: 0.2436\n",
      "Epoch 139/300\n",
      " - 2s - loss: 0.7348 - accuracy: 0.7494 - val_loss: 2.2748 - val_accuracy: 0.2779\n",
      "Epoch 140/300\n",
      " - 3s - loss: 0.7534 - accuracy: 0.7541 - val_loss: 2.2789 - val_accuracy: 0.2636\n",
      "Epoch 141/300\n",
      " - 2s - loss: 0.7517 - accuracy: 0.7482 - val_loss: 2.2937 - val_accuracy: 0.2722\n",
      "Epoch 142/300\n",
      " - 3s - loss: 0.7486 - accuracy: 0.7190 - val_loss: 2.3039 - val_accuracy: 0.2751\n",
      "Epoch 143/300\n",
      " - 2s - loss: 0.7573 - accuracy: 0.7447 - val_loss: 2.2941 - val_accuracy: 0.2521\n",
      "Epoch 144/300\n",
      " - 2s - loss: 0.7004 - accuracy: 0.7740 - val_loss: 2.3022 - val_accuracy: 0.2693\n",
      "Epoch 145/300\n",
      " - 2s - loss: 0.7409 - accuracy: 0.7342 - val_loss: 2.3113 - val_accuracy: 0.2579\n",
      "Epoch 146/300\n",
      " - 2s - loss: 0.7138 - accuracy: 0.7518 - val_loss: 2.3480 - val_accuracy: 0.2636\n",
      "Epoch 147/300\n",
      " - 2s - loss: 0.7277 - accuracy: 0.7459 - val_loss: 2.3624 - val_accuracy: 0.2521\n",
      "Epoch 148/300\n",
      " - 2s - loss: 0.7011 - accuracy: 0.7576 - val_loss: 2.3650 - val_accuracy: 0.2464\n",
      "Epoch 149/300\n",
      " - 2s - loss: 0.7286 - accuracy: 0.7471 - val_loss: 2.3681 - val_accuracy: 0.2579\n",
      "Epoch 150/300\n",
      " - 2s - loss: 0.6859 - accuracy: 0.7646 - val_loss: 2.3349 - val_accuracy: 0.2579\n",
      "Epoch 151/300\n",
      " - 2s - loss: 0.6748 - accuracy: 0.7752 - val_loss: 2.3477 - val_accuracy: 0.2464\n",
      "Epoch 152/300\n",
      " - 2s - loss: 0.6869 - accuracy: 0.7646 - val_loss: 2.3583 - val_accuracy: 0.2550\n",
      "Epoch 153/300\n",
      " - 2s - loss: 0.6768 - accuracy: 0.7646 - val_loss: 2.3697 - val_accuracy: 0.2579\n",
      "Epoch 154/300\n",
      " - 2s - loss: 0.6767 - accuracy: 0.7611 - val_loss: 2.3815 - val_accuracy: 0.2493\n",
      "Epoch 155/300\n",
      " - 2s - loss: 0.6473 - accuracy: 0.7799 - val_loss: 2.4113 - val_accuracy: 0.2493\n",
      "Epoch 156/300\n",
      " - 2s - loss: 0.6723 - accuracy: 0.7576 - val_loss: 2.3912 - val_accuracy: 0.2464\n",
      "Epoch 157/300\n",
      " - 2s - loss: 0.6498 - accuracy: 0.7693 - val_loss: 2.4039 - val_accuracy: 0.2579\n",
      "Epoch 158/300\n",
      " - 2s - loss: 0.7213 - accuracy: 0.7389 - val_loss: 2.3887 - val_accuracy: 0.2579\n",
      "Epoch 159/300\n",
      " - 2s - loss: 0.6758 - accuracy: 0.7635 - val_loss: 2.3883 - val_accuracy: 0.2636\n",
      "Epoch 160/300\n",
      " - 2s - loss: 0.6450 - accuracy: 0.7892 - val_loss: 2.3922 - val_accuracy: 0.2607\n",
      "Epoch 161/300\n",
      " - 2s - loss: 0.6642 - accuracy: 0.7728 - val_loss: 2.4217 - val_accuracy: 0.2722\n",
      "Epoch 162/300\n",
      " - 2s - loss: 0.5953 - accuracy: 0.7916 - val_loss: 2.4616 - val_accuracy: 0.2550\n",
      "Epoch 163/300\n",
      " - 2s - loss: 0.6384 - accuracy: 0.7904 - val_loss: 2.4550 - val_accuracy: 0.2693\n",
      "Epoch 164/300\n",
      " - 2s - loss: 0.6499 - accuracy: 0.7623 - val_loss: 2.4984 - val_accuracy: 0.2493\n",
      "Epoch 165/300\n",
      " - 2s - loss: 0.5967 - accuracy: 0.7904 - val_loss: 2.4521 - val_accuracy: 0.2521\n",
      "Epoch 166/300\n",
      " - 2s - loss: 0.6670 - accuracy: 0.7670 - val_loss: 2.4699 - val_accuracy: 0.2579\n",
      "Epoch 167/300\n",
      " - 2s - loss: 0.6389 - accuracy: 0.7775 - val_loss: 2.4736 - val_accuracy: 0.2579\n",
      "Epoch 168/300\n",
      " - 2s - loss: 0.6141 - accuracy: 0.7904 - val_loss: 2.4426 - val_accuracy: 0.2636\n",
      "Epoch 169/300\n",
      " - 2s - loss: 0.6416 - accuracy: 0.7787 - val_loss: 2.4530 - val_accuracy: 0.2693\n",
      "Epoch 170/300\n",
      " - 3s - loss: 0.6163 - accuracy: 0.7892 - val_loss: 2.4778 - val_accuracy: 0.2579\n",
      "Epoch 171/300\n",
      " - 2s - loss: 0.6459 - accuracy: 0.7916 - val_loss: 2.4631 - val_accuracy: 0.2693\n",
      "Epoch 172/300\n",
      " - 2s - loss: 0.6485 - accuracy: 0.7763 - val_loss: 2.4656 - val_accuracy: 0.2751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/300\n",
      " - 2s - loss: 0.6100 - accuracy: 0.7974 - val_loss: 2.4315 - val_accuracy: 0.2693\n",
      "Epoch 174/300\n",
      " - 2s - loss: 0.5934 - accuracy: 0.8185 - val_loss: 2.4092 - val_accuracy: 0.2693\n",
      "Epoch 175/300\n",
      " - 3s - loss: 0.6140 - accuracy: 0.7834 - val_loss: 2.4459 - val_accuracy: 0.2693\n",
      "Epoch 176/300\n",
      " - 3s - loss: 0.5923 - accuracy: 0.8080 - val_loss: 2.4506 - val_accuracy: 0.2665\n",
      "Epoch 177/300\n",
      " - 3s - loss: 0.5990 - accuracy: 0.7939 - val_loss: 2.4955 - val_accuracy: 0.2636\n",
      "Epoch 178/300\n",
      " - 2s - loss: 0.6046 - accuracy: 0.7869 - val_loss: 2.4756 - val_accuracy: 0.2636\n",
      "Epoch 179/300\n",
      " - 3s - loss: 0.5902 - accuracy: 0.7986 - val_loss: 2.4964 - val_accuracy: 0.2607\n",
      "Epoch 180/300\n",
      " - 2s - loss: 0.5661 - accuracy: 0.8185 - val_loss: 2.5369 - val_accuracy: 0.2837\n",
      "Epoch 181/300\n",
      " - 2s - loss: 0.6049 - accuracy: 0.8080 - val_loss: 2.5195 - val_accuracy: 0.2493\n",
      "Epoch 182/300\n",
      " - 2s - loss: 0.5774 - accuracy: 0.7998 - val_loss: 2.4979 - val_accuracy: 0.2722\n",
      "Epoch 183/300\n",
      " - 3s - loss: 0.5536 - accuracy: 0.8115 - val_loss: 2.4766 - val_accuracy: 0.2808\n",
      "Epoch 184/300\n",
      " - 2s - loss: 0.5889 - accuracy: 0.8033 - val_loss: 2.5091 - val_accuracy: 0.2722\n",
      "Epoch 185/300\n",
      " - 2s - loss: 0.5671 - accuracy: 0.8162 - val_loss: 2.4993 - val_accuracy: 0.2693\n",
      "Epoch 186/300\n",
      " - 2s - loss: 0.5203 - accuracy: 0.8279 - val_loss: 2.5484 - val_accuracy: 0.2808\n",
      "Epoch 187/300\n",
      " - 2s - loss: 0.5676 - accuracy: 0.8115 - val_loss: 2.5245 - val_accuracy: 0.2751\n",
      "Epoch 188/300\n",
      " - 2s - loss: 0.5556 - accuracy: 0.8126 - val_loss: 2.5274 - val_accuracy: 0.2665\n",
      "Epoch 189/300\n",
      " - 2s - loss: 0.5491 - accuracy: 0.8068 - val_loss: 2.5251 - val_accuracy: 0.2693\n",
      "Epoch 190/300\n",
      " - 2s - loss: 0.5355 - accuracy: 0.8232 - val_loss: 2.5509 - val_accuracy: 0.2693\n",
      "Epoch 191/300\n",
      " - 2s - loss: 0.5444 - accuracy: 0.8138 - val_loss: 2.5706 - val_accuracy: 0.2693\n",
      "Epoch 192/300\n",
      " - 2s - loss: 0.5551 - accuracy: 0.8126 - val_loss: 2.5783 - val_accuracy: 0.2693\n",
      "Epoch 193/300\n",
      " - 2s - loss: 0.5064 - accuracy: 0.8361 - val_loss: 2.5612 - val_accuracy: 0.2751\n",
      "Epoch 194/300\n",
      " - 2s - loss: 0.5681 - accuracy: 0.8033 - val_loss: 2.5532 - val_accuracy: 0.2722\n",
      "Epoch 195/300\n",
      " - 2s - loss: 0.5370 - accuracy: 0.8197 - val_loss: 2.5580 - val_accuracy: 0.2607\n",
      "Epoch 196/300\n",
      " - 2s - loss: 0.5226 - accuracy: 0.8466 - val_loss: 2.5541 - val_accuracy: 0.2607\n",
      "Epoch 197/300\n",
      " - 2s - loss: 0.5557 - accuracy: 0.8126 - val_loss: 2.5665 - val_accuracy: 0.2779\n",
      "Epoch 198/300\n",
      " - 2s - loss: 0.5082 - accuracy: 0.8197 - val_loss: 2.5725 - val_accuracy: 0.2779\n",
      "Epoch 199/300\n",
      " - 2s - loss: 0.4950 - accuracy: 0.8361 - val_loss: 2.5869 - val_accuracy: 0.2722\n",
      "Epoch 200/300\n",
      " - 2s - loss: 0.5478 - accuracy: 0.8091 - val_loss: 2.6031 - val_accuracy: 0.2837\n",
      "Epoch 201/300\n",
      " - 2s - loss: 0.5138 - accuracy: 0.8255 - val_loss: 2.5695 - val_accuracy: 0.2722\n",
      "Epoch 202/300\n",
      " - 2s - loss: 0.5245 - accuracy: 0.8232 - val_loss: 2.6244 - val_accuracy: 0.2665\n",
      "Epoch 203/300\n",
      " - 2s - loss: 0.5194 - accuracy: 0.8232 - val_loss: 2.5874 - val_accuracy: 0.2837\n",
      "Epoch 204/300\n",
      " - 2s - loss: 0.5286 - accuracy: 0.8150 - val_loss: 2.5935 - val_accuracy: 0.2607\n",
      "Epoch 205/300\n",
      " - 2s - loss: 0.5204 - accuracy: 0.8384 - val_loss: 2.5859 - val_accuracy: 0.2607\n",
      "Epoch 206/300\n",
      " - 2s - loss: 0.5094 - accuracy: 0.8302 - val_loss: 2.5973 - val_accuracy: 0.2722\n",
      "Epoch 207/300\n",
      " - 2s - loss: 0.4866 - accuracy: 0.8302 - val_loss: 2.6138 - val_accuracy: 0.2693\n",
      "Epoch 208/300\n",
      " - 2s - loss: 0.4794 - accuracy: 0.8361 - val_loss: 2.6532 - val_accuracy: 0.2464\n",
      "Epoch 209/300\n",
      " - 2s - loss: 0.5482 - accuracy: 0.8115 - val_loss: 2.6322 - val_accuracy: 0.2665\n",
      "Epoch 210/300\n",
      " - 2s - loss: 0.5006 - accuracy: 0.8361 - val_loss: 2.6410 - val_accuracy: 0.2636\n",
      "Epoch 211/300\n",
      " - 2s - loss: 0.4806 - accuracy: 0.8454 - val_loss: 2.6183 - val_accuracy: 0.2579\n",
      "Epoch 212/300\n",
      " - 2s - loss: 0.4764 - accuracy: 0.8431 - val_loss: 2.6196 - val_accuracy: 0.2779\n",
      "Epoch 213/300\n",
      " - 2s - loss: 0.4641 - accuracy: 0.8618 - val_loss: 2.6599 - val_accuracy: 0.2751\n",
      "Epoch 214/300\n",
      " - 2s - loss: 0.4683 - accuracy: 0.8501 - val_loss: 2.6654 - val_accuracy: 0.2779\n",
      "Epoch 215/300\n",
      " - 2s - loss: 0.4925 - accuracy: 0.8337 - val_loss: 2.7071 - val_accuracy: 0.2779\n",
      "Epoch 216/300\n",
      " - 2s - loss: 0.4954 - accuracy: 0.8326 - val_loss: 2.6983 - val_accuracy: 0.2665\n",
      "Epoch 217/300\n",
      " - 2s - loss: 0.5057 - accuracy: 0.8279 - val_loss: 2.6974 - val_accuracy: 0.2607\n",
      "Epoch 218/300\n",
      " - 2s - loss: 0.4781 - accuracy: 0.8407 - val_loss: 2.6373 - val_accuracy: 0.2636\n",
      "Epoch 219/300\n",
      " - 2s - loss: 0.4878 - accuracy: 0.8244 - val_loss: 2.6393 - val_accuracy: 0.2607\n",
      "Epoch 220/300\n",
      " - 2s - loss: 0.4820 - accuracy: 0.8314 - val_loss: 2.6621 - val_accuracy: 0.2493\n",
      "Epoch 221/300\n",
      " - 2s - loss: 0.4616 - accuracy: 0.8513 - val_loss: 2.6810 - val_accuracy: 0.2636\n",
      "Epoch 222/300\n",
      " - 2s - loss: 0.4537 - accuracy: 0.8466 - val_loss: 2.7290 - val_accuracy: 0.2579\n",
      "Epoch 223/300\n",
      " - 2s - loss: 0.4454 - accuracy: 0.8571 - val_loss: 2.6939 - val_accuracy: 0.2665\n",
      "Epoch 224/300\n",
      " - 2s - loss: 0.4413 - accuracy: 0.8607 - val_loss: 2.7226 - val_accuracy: 0.2665\n",
      "Epoch 225/300\n",
      " - 2s - loss: 0.4416 - accuracy: 0.8642 - val_loss: 2.7173 - val_accuracy: 0.2665\n",
      "Epoch 226/300\n",
      " - 2s - loss: 0.4384 - accuracy: 0.8454 - val_loss: 2.7588 - val_accuracy: 0.2607\n",
      "Epoch 227/300\n",
      " - 2s - loss: 0.4369 - accuracy: 0.8407 - val_loss: 2.7541 - val_accuracy: 0.2636\n",
      "Epoch 228/300\n",
      " - 2s - loss: 0.4853 - accuracy: 0.8478 - val_loss: 2.7492 - val_accuracy: 0.2665\n",
      "Epoch 229/300\n",
      " - 2s - loss: 0.4424 - accuracy: 0.8478 - val_loss: 2.7603 - val_accuracy: 0.2636\n",
      "Epoch 230/300\n",
      " - 2s - loss: 0.4385 - accuracy: 0.8642 - val_loss: 2.7210 - val_accuracy: 0.2665\n",
      "Epoch 231/300\n",
      " - 2s - loss: 0.4575 - accuracy: 0.8466 - val_loss: 2.7396 - val_accuracy: 0.2550\n",
      "Epoch 232/300\n",
      " - 2s - loss: 0.4282 - accuracy: 0.8677 - val_loss: 2.7233 - val_accuracy: 0.2693\n",
      "Epoch 233/300\n",
      " - 2s - loss: 0.4445 - accuracy: 0.8618 - val_loss: 2.7387 - val_accuracy: 0.2607\n",
      "Epoch 234/300\n",
      " - 2s - loss: 0.4431 - accuracy: 0.8595 - val_loss: 2.7796 - val_accuracy: 0.2722\n",
      "Epoch 235/300\n",
      " - 2s - loss: 0.4463 - accuracy: 0.8618 - val_loss: 2.7546 - val_accuracy: 0.2521\n",
      "Epoch 236/300\n",
      " - 2s - loss: 0.4549 - accuracy: 0.8337 - val_loss: 2.7703 - val_accuracy: 0.2693\n",
      "Epoch 237/300\n",
      " - 2s - loss: 0.4347 - accuracy: 0.8489 - val_loss: 2.7337 - val_accuracy: 0.2693\n",
      "Epoch 238/300\n",
      " - 2s - loss: 0.4119 - accuracy: 0.8478 - val_loss: 2.7050 - val_accuracy: 0.2665\n",
      "Epoch 239/300\n",
      " - 2s - loss: 0.4145 - accuracy: 0.8583 - val_loss: 2.7273 - val_accuracy: 0.2722\n",
      "Epoch 240/300\n",
      " - 2s - loss: 0.4342 - accuracy: 0.8571 - val_loss: 2.7352 - val_accuracy: 0.2636\n",
      "Epoch 241/300\n",
      " - 2s - loss: 0.4279 - accuracy: 0.8595 - val_loss: 2.7549 - val_accuracy: 0.2779\n",
      "Epoch 242/300\n",
      " - 2s - loss: 0.4437 - accuracy: 0.8454 - val_loss: 2.7619 - val_accuracy: 0.2693\n",
      "Epoch 243/300\n",
      " - 2s - loss: 0.4517 - accuracy: 0.8443 - val_loss: 2.7473 - val_accuracy: 0.2665\n",
      "Epoch 244/300\n",
      " - 2s - loss: 0.4256 - accuracy: 0.8489 - val_loss: 2.7273 - val_accuracy: 0.2636\n",
      "Epoch 245/300\n",
      " - 2s - loss: 0.4712 - accuracy: 0.8419 - val_loss: 2.7213 - val_accuracy: 0.2779\n",
      "Epoch 246/300\n",
      " - 2s - loss: 0.4139 - accuracy: 0.8595 - val_loss: 2.7549 - val_accuracy: 0.2779\n",
      "Epoch 247/300\n",
      " - 2s - loss: 0.4427 - accuracy: 0.8525 - val_loss: 2.7599 - val_accuracy: 0.2779\n",
      "Epoch 248/300\n",
      " - 2s - loss: 0.4061 - accuracy: 0.8712 - val_loss: 2.7813 - val_accuracy: 0.2779\n",
      "Epoch 249/300\n",
      " - 2s - loss: 0.3877 - accuracy: 0.8677 - val_loss: 2.7815 - val_accuracy: 0.2808\n",
      "Epoch 250/300\n",
      " - 2s - loss: 0.4497 - accuracy: 0.8478 - val_loss: 2.8254 - val_accuracy: 0.2980\n",
      "Epoch 251/300\n",
      " - 2s - loss: 0.4212 - accuracy: 0.8607 - val_loss: 2.8017 - val_accuracy: 0.2808\n",
      "Epoch 252/300\n",
      " - 2s - loss: 0.4042 - accuracy: 0.8747 - val_loss: 2.7975 - val_accuracy: 0.2693\n",
      "Epoch 253/300\n",
      " - 2s - loss: 0.3787 - accuracy: 0.8724 - val_loss: 2.7830 - val_accuracy: 0.2607\n",
      "Epoch 254/300\n",
      " - 2s - loss: 0.3907 - accuracy: 0.8712 - val_loss: 2.8122 - val_accuracy: 0.2665\n",
      "Epoch 255/300\n",
      " - 2s - loss: 0.4209 - accuracy: 0.8595 - val_loss: 2.7816 - val_accuracy: 0.2607\n",
      "Epoch 256/300\n",
      " - 2s - loss: 0.4539 - accuracy: 0.8443 - val_loss: 2.7726 - val_accuracy: 0.2550\n",
      "Epoch 257/300\n",
      " - 2s - loss: 0.4035 - accuracy: 0.8607 - val_loss: 2.7845 - val_accuracy: 0.2693\n",
      "Epoch 258/300\n",
      " - 2s - loss: 0.3931 - accuracy: 0.8724 - val_loss: 2.7640 - val_accuracy: 0.2579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/300\n",
      " - 2s - loss: 0.4317 - accuracy: 0.8595 - val_loss: 2.8131 - val_accuracy: 0.2579\n",
      "Epoch 260/300\n",
      " - 2s - loss: 0.4524 - accuracy: 0.8454 - val_loss: 2.7793 - val_accuracy: 0.2722\n",
      "Epoch 261/300\n",
      " - 2s - loss: 0.4187 - accuracy: 0.8665 - val_loss: 2.7668 - val_accuracy: 0.2808\n",
      "Epoch 262/300\n",
      " - 2s - loss: 0.3921 - accuracy: 0.8665 - val_loss: 2.8016 - val_accuracy: 0.2722\n",
      "Epoch 263/300\n",
      " - 2s - loss: 0.3762 - accuracy: 0.8770 - val_loss: 2.8419 - val_accuracy: 0.2722\n",
      "Epoch 264/300\n",
      " - 2s - loss: 0.3760 - accuracy: 0.8770 - val_loss: 2.8353 - val_accuracy: 0.2779\n",
      "Epoch 265/300\n",
      " - 2s - loss: 0.4059 - accuracy: 0.8595 - val_loss: 2.8440 - val_accuracy: 0.2751\n",
      "Epoch 266/300\n",
      " - 2s - loss: 0.3765 - accuracy: 0.8747 - val_loss: 2.8566 - val_accuracy: 0.2722\n",
      "Epoch 267/300\n",
      " - 2s - loss: 0.4220 - accuracy: 0.8712 - val_loss: 2.8261 - val_accuracy: 0.2521\n",
      "Epoch 268/300\n",
      " - 2s - loss: 0.4412 - accuracy: 0.8607 - val_loss: 2.8306 - val_accuracy: 0.2751\n",
      "Epoch 269/300\n",
      " - 2s - loss: 0.4201 - accuracy: 0.8665 - val_loss: 2.8195 - val_accuracy: 0.2779\n",
      "Epoch 270/300\n",
      " - 2s - loss: 0.3778 - accuracy: 0.8864 - val_loss: 2.8046 - val_accuracy: 0.2665\n",
      "Epoch 271/300\n",
      " - 2s - loss: 0.3596 - accuracy: 0.8794 - val_loss: 2.8492 - val_accuracy: 0.2579\n",
      "Epoch 272/300\n",
      " - 2s - loss: 0.3964 - accuracy: 0.8712 - val_loss: 2.8568 - val_accuracy: 0.2607\n",
      "Epoch 273/300\n",
      " - 2s - loss: 0.4146 - accuracy: 0.8607 - val_loss: 2.8878 - val_accuracy: 0.2636\n",
      "Epoch 274/300\n",
      " - 2s - loss: 0.4162 - accuracy: 0.8607 - val_loss: 2.8613 - val_accuracy: 0.2464\n",
      "Epoch 275/300\n",
      " - 2s - loss: 0.4208 - accuracy: 0.8571 - val_loss: 2.8333 - val_accuracy: 0.2636\n",
      "Epoch 276/300\n",
      " - 2s - loss: 0.3847 - accuracy: 0.8607 - val_loss: 2.8352 - val_accuracy: 0.2722\n",
      "Epoch 277/300\n",
      " - 2s - loss: 0.3911 - accuracy: 0.8677 - val_loss: 2.8487 - val_accuracy: 0.2550\n",
      "Epoch 278/300\n",
      " - 2s - loss: 0.4166 - accuracy: 0.8536 - val_loss: 2.8539 - val_accuracy: 0.2693\n",
      "Epoch 279/300\n",
      " - 2s - loss: 0.3915 - accuracy: 0.8735 - val_loss: 2.8739 - val_accuracy: 0.2665\n",
      "Epoch 280/300\n",
      " - 2s - loss: 0.3826 - accuracy: 0.8899 - val_loss: 2.8199 - val_accuracy: 0.2550\n",
      "Epoch 281/300\n",
      " - 2s - loss: 0.3910 - accuracy: 0.8642 - val_loss: 2.8280 - val_accuracy: 0.2837\n",
      "Epoch 282/300\n",
      " - 2s - loss: 0.4050 - accuracy: 0.8735 - val_loss: 2.8946 - val_accuracy: 0.2550\n",
      "Epoch 283/300\n",
      " - 2s - loss: 0.4301 - accuracy: 0.8548 - val_loss: 2.8587 - val_accuracy: 0.2693\n",
      "Epoch 284/300\n",
      " - 2s - loss: 0.3725 - accuracy: 0.8794 - val_loss: 2.8021 - val_accuracy: 0.2779\n",
      "Epoch 285/300\n",
      " - 2s - loss: 0.3726 - accuracy: 0.8770 - val_loss: 2.8311 - val_accuracy: 0.2693\n",
      "Epoch 286/300\n",
      " - 2s - loss: 0.4096 - accuracy: 0.8489 - val_loss: 2.8596 - val_accuracy: 0.2493\n",
      "Epoch 287/300\n",
      " - 2s - loss: 0.3790 - accuracy: 0.8770 - val_loss: 2.8275 - val_accuracy: 0.2693\n",
      "Epoch 288/300\n",
      " - 2s - loss: 0.3486 - accuracy: 0.8876 - val_loss: 2.8399 - val_accuracy: 0.2808\n",
      "Epoch 289/300\n",
      " - 2s - loss: 0.3303 - accuracy: 0.8934 - val_loss: 2.8654 - val_accuracy: 0.2521\n",
      "Epoch 290/300\n",
      " - 2s - loss: 0.3532 - accuracy: 0.8923 - val_loss: 2.9154 - val_accuracy: 0.2693\n",
      "Epoch 291/300\n",
      " - 2s - loss: 0.4061 - accuracy: 0.8583 - val_loss: 2.8923 - val_accuracy: 0.2722\n",
      "Epoch 292/300\n",
      " - 2s - loss: 0.3480 - accuracy: 0.8946 - val_loss: 2.9050 - val_accuracy: 0.2751\n",
      "Epoch 293/300\n",
      " - 2s - loss: 0.3848 - accuracy: 0.8618 - val_loss: 2.9637 - val_accuracy: 0.2665\n",
      "Epoch 294/300\n",
      " - 2s - loss: 0.3737 - accuracy: 0.8911 - val_loss: 2.9644 - val_accuracy: 0.2636\n",
      "Epoch 295/300\n",
      " - 2s - loss: 0.3762 - accuracy: 0.8806 - val_loss: 2.9030 - val_accuracy: 0.2636\n",
      "Epoch 296/300\n",
      " - 2s - loss: 0.3698 - accuracy: 0.8735 - val_loss: 2.9054 - val_accuracy: 0.2665\n",
      "Epoch 297/300\n",
      " - 2s - loss: 0.3481 - accuracy: 0.8899 - val_loss: 2.9240 - val_accuracy: 0.2665\n",
      "Epoch 298/300\n",
      " - 2s - loss: 0.3361 - accuracy: 0.8934 - val_loss: 2.9220 - val_accuracy: 0.2751\n",
      "Epoch 299/300\n",
      " - 2s - loss: 0.3663 - accuracy: 0.8817 - val_loss: 2.9020 - val_accuracy: 0.2751\n",
      "Epoch 300/300\n",
      " - 2s - loss: 0.3563 - accuracy: 0.8864 - val_loss: 2.9223 - val_accuracy: 0.2665\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "num_rows = X_train[0].shape[0]\n",
    "num_columns = X_train[0].shape[1]\n",
    "num_channels = 1\n",
    "####\n",
    "# Construct model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=128,\n",
    "                 kernel_size=2,\n",
    "                 input_shape=(num_rows, num_columns, num_channels),\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2,\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the keras model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define bath and epochs\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "\n",
    "# Callbacks and fitting model\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9,\n",
    "                              patience=20, min_lr=0.0000001)\n",
    "mcp_save = ModelCheckpoint('../model_checkpoints/new_test.h5',\n",
    "                           save_best_only=True, monitor='val_loss',\n",
    "                           mode='min')\n",
    "\n",
    "result = model.fit(X_train, y_train, batch_size=batch_size,\n",
    "                   epochs=epochs, validation_data=(X_test, y_test),\n",
    "                   callbacks=[mcp_save, lr_reduce], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation acc of epoch: 0.2979942560195923\n"
     ]
    }
   ],
   "source": [
    " validation_acc = np.amax(result.history['val_accuracy'])\n",
    "print('Best validation acc of epoch:', validation_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/349 [==============================] - 0s 589us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test, verbose=1)\n",
    "predictions_labels = []\n",
    "for predict in predictions:\n",
    "    predictions_labels.append(predict.tolist().index(np.amax(predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 0.2664756446991404\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(predictions_labels)\n",
    "for index in range(0, len(predictions_labels)):\n",
    "    if predictions_labels[index] == y_test_labels[index]:\n",
    "        correct += 1\n",
    "        \n",
    "print(\"average: {}\".format(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 0.49283667621776506\n"
     ]
    }
   ],
   "source": [
    "grouped_predictions = group_labels(predictions_labels)\n",
    "grouped_test_labels = group_labels(y_test_labels)\n",
    "correct = 0\n",
    "total = len(grouped_predictions)\n",
    "for index in range(0, len(grouped_predictions)):\n",
    "    if grouped_predictions[index] == grouped_test_labels[index]:\n",
    "        correct += 1\n",
    "        \n",
    "print(\"average: {}\".format(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 'neu': 0,\n",
    "                'des': 1,\n",
    "                'med': 2,\n",
    "                'ale': 3,\n",
    "                'rai': 4,\n",
    "                'sur': 5,\n",
    "                'tri': 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_indexes = ['neutro', 'des', 'medo', 'alegria', 'raiva', 'surpresa', 'tristeza']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_indexes = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_indexes = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "title = \"Confusion Matrix\"\n",
    "\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(predictions_labels, y_test_labels)\n",
    "\n",
    "\n",
    "df_cm = pd.DataFrame(cm)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "# df_cm = pd.DataFrame(array, range(6), range(6))\n",
    "# # plt.figure(figsize=(10,7))\n",
    "# sn.set(font_scale=1.4) # for label size\n",
    "# sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predictions = group_labels(svc.predict(X_test))\n",
    "correct_predictions = group_labels(y_test)\n",
    "\n",
    "correct = 0\n",
    "total = len(new_predictions)\n",
    "for index in range(0, len(new_predictions)):\n",
    "    if new_predictions[index] == correct_predictions[index]:\n",
    "        correct += 1\n",
    "        \n",
    "print(\"average: {}\".format(correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
