{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and program variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from time_series_dataset_loader import TimeSeriesDatasetLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split # to split dataset into train and test\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../src/Features/Original/MFCC/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = TimeSeriesDatasetLoader(DATASET_PATH)\n",
    "X, y = dataset_loader.get_dataset('emotion_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.          0.         -7.33182    19.48468    -7.506955    1.82857\n",
      "   5.773757  -13.56968     3.013354  -10.19034    13.51374    -1.628919\n",
      "   7.978467    0.7820195   2.435657   -2.008263 ]\n",
      "(1164,)\n",
      "[1 0 0]\n",
      "(1164,)\n"
     ]
    }
   ],
   "source": [
    "# See X and y details\n",
    "print(X[0][0])\n",
    "print(X.shape)\n",
    "\n",
    "print(y[:3])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0  -7  19  -7   1   5 -13   3 -10  13  -1   7   0   2  -2]\n",
      "(1164, 543, 16)\n"
     ]
    }
   ],
   "source": [
    "# Apply Pad Sequences\n",
    "max_len = len(X[0])\n",
    "for row in X:\n",
    "    if len(row) > max_len:\n",
    "        max_len = len(row)\n",
    "\n",
    "X = pad_sequences(X, maxlen=max_len, padding='post')\n",
    "\n",
    "# See X details\n",
    "print(X[0][0])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "[  0   0   8  -6  -6  -5   5   4   0   6  -4  11 -14  -6   1  -3]\n",
      "(814, 543, 16)\n",
      "\n",
      "X_test:\n",
      "\n",
      "[  0   0   7   0  10   0 -10  -6  -6   1  -1 -10   8  -1   0 -11]\n",
      "(350, 543, 16)\n",
      "\n",
      "y_train:\n",
      "\n",
      "[2 0 1]\n",
      "(814,)\n",
      "\n",
      "y_test:\n",
      "\n",
      "[2 1 0]\n",
      "(350,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3)\n",
    "\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train[0][0])\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(X_test[0][0])\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"\\ny_train:\\n\")\n",
    "print(y_train[:3])\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\ny_test:\\n\")\n",
    "print(y_test[:3])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814\n",
      "543\n",
      "16\n",
      "\n",
      "X_train:\n",
      "\n",
      "(814, 8688)\n",
      "\n",
      "y_train:\n",
      "\n",
      "(814,)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping to apply smote\n",
    "\n",
    "shape_0 = X_train.shape[0]\n",
    "shape_1 = X_train.shape[1]\n",
    "shape_2 = X_train.shape[2]\n",
    "print(shape_0)\n",
    "print(shape_1)\n",
    "print(shape_2)\n",
    "X_train = X_train.reshape(shape_0, shape_1 * shape_2)\n",
    "\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\ny_train:\\n\")\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "[  0   0   8  -6  -6  -5   5   4   0   6  -4  11 -14  -6   1  -3]\n",
      "(1392, 543, 16)\n",
      "\n",
      "y_train:\n",
      "\n",
      "[2 0 1]\n",
      "(1392,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)\n",
    "\n",
    "# Reshaping back to original shape dimensions 1 and 2\n",
    "X_train = X_train.reshape(X_train.shape[0], shape_1, shape_2)\n",
    "\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train[0][0])\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\ny_train:\\n\")\n",
    "print(y_train[:3])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical matrices\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "[[  0]\n",
      " [  0]\n",
      " [  8]\n",
      " [ -6]\n",
      " [ -6]\n",
      " [ -5]\n",
      " [  5]\n",
      " [  4]\n",
      " [  0]\n",
      " [  6]\n",
      " [ -4]\n",
      " [ 11]\n",
      " [-14]\n",
      " [ -6]\n",
      " [  1]\n",
      " [ -3]]\n",
      "(1392, 543, 16, 1)\n",
      "\n",
      "X_test:\n",
      "\n",
      "[[  0]\n",
      " [  0]\n",
      " [  7]\n",
      " [  0]\n",
      " [ 10]\n",
      " [  0]\n",
      " [-10]\n",
      " [ -6]\n",
      " [ -6]\n",
      " [  1]\n",
      " [ -1]\n",
      " [-10]\n",
      " [  8]\n",
      " [ -1]\n",
      " [  0]\n",
      " [-11]]\n",
      "(350, 543, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "num_rows = X[0].shape[0]\n",
    "num_columns = X[0].shape[1]\n",
    "num_channels = 1\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train[0][0])\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(X_test[0][0])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/moutinho/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct model 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-k category accuracy\n",
    "import functools\n",
    "import keras\n",
    "top3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/moutinho/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1392 samples, validate on 350 samples\n",
      "Epoch 1/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.6452 - accuracy: 0.3333 - top3_acc: 1.0000 - val_loss: 1.2973 - val_accuracy: 0.2457 - val_top3_acc: 1.0000\n",
      "Epoch 2/400\n",
      "1392/1392 [==============================] - 9s 7ms/step - loss: 1.2442 - accuracy: 0.3355 - top3_acc: 1.0000 - val_loss: 1.1262 - val_accuracy: 0.2600 - val_top3_acc: 1.0000\n",
      "Epoch 3/400\n",
      "1392/1392 [==============================] - 9s 7ms/step - loss: 1.1776 - accuracy: 0.3290 - top3_acc: 1.0000 - val_loss: 1.1193 - val_accuracy: 0.2629 - val_top3_acc: 1.0000\n",
      "Epoch 4/400\n",
      "1392/1392 [==============================] - 9s 7ms/step - loss: 1.1218 - accuracy: 0.3599 - top3_acc: 1.0000 - val_loss: 1.2023 - val_accuracy: 0.2286 - val_top3_acc: 1.0000\n",
      "Epoch 5/400\n",
      "1392/1392 [==============================] - 9s 7ms/step - loss: 1.1161 - accuracy: 0.3527 - top3_acc: 1.0000 - val_loss: 1.0665 - val_accuracy: 0.4686 - val_top3_acc: 1.0000\n",
      "Epoch 6/400\n",
      "1392/1392 [==============================] - 9s 7ms/step - loss: 1.1151 - accuracy: 0.3491 - top3_acc: 1.0000 - val_loss: 1.1561 - val_accuracy: 0.2771 - val_top3_acc: 1.0000\n",
      "Epoch 7/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.1004 - accuracy: 0.3901 - top3_acc: 1.0000 - val_loss: 1.0988 - val_accuracy: 0.2571 - val_top3_acc: 1.0000\n",
      "Epoch 8/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0969 - accuracy: 0.3707 - top3_acc: 1.0000 - val_loss: 1.1206 - val_accuracy: 0.3686 - val_top3_acc: 1.0000\n",
      "Epoch 9/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0850 - accuracy: 0.3772 - top3_acc: 1.0000 - val_loss: 1.0820 - val_accuracy: 0.3314 - val_top3_acc: 1.0000\n",
      "Epoch 10/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0807 - accuracy: 0.3822 - top3_acc: 1.0000 - val_loss: 1.1168 - val_accuracy: 0.2943 - val_top3_acc: 1.0000\n",
      "Epoch 11/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0830 - accuracy: 0.4124 - top3_acc: 1.0000 - val_loss: 1.0854 - val_accuracy: 0.4343 - val_top3_acc: 1.0000\n",
      "Epoch 12/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0750 - accuracy: 0.4059 - top3_acc: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.4686 - val_top3_acc: 1.0000\n",
      "Epoch 13/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0560 - accuracy: 0.4318 - top3_acc: 1.0000 - val_loss: 1.1355 - val_accuracy: 0.2571 - val_top3_acc: 1.0000\n",
      "Epoch 14/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0567 - accuracy: 0.4303 - top3_acc: 1.0000 - val_loss: 1.0561 - val_accuracy: 0.5114 - val_top3_acc: 1.0000\n",
      "Epoch 15/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0627 - accuracy: 0.4260 - top3_acc: 1.0000 - val_loss: 1.0773 - val_accuracy: 0.3600 - val_top3_acc: 1.0000\n",
      "Epoch 16/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0421 - accuracy: 0.4583 - top3_acc: 1.0000 - val_loss: 1.0706 - val_accuracy: 0.3171 - val_top3_acc: 1.0000\n",
      "Epoch 17/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0418 - accuracy: 0.4547 - top3_acc: 1.0000 - val_loss: 1.0662 - val_accuracy: 0.3543 - val_top3_acc: 1.0000\n",
      "Epoch 18/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0388 - accuracy: 0.4562 - top3_acc: 1.0000 - val_loss: 1.0371 - val_accuracy: 0.5286 - val_top3_acc: 1.0000\n",
      "Epoch 19/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0309 - accuracy: 0.4626 - top3_acc: 1.0000 - val_loss: 1.0554 - val_accuracy: 0.4714 - val_top3_acc: 1.0000\n",
      "Epoch 20/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0415 - accuracy: 0.4777 - top3_acc: 1.0000 - val_loss: 1.0822 - val_accuracy: 0.2629 - val_top3_acc: 1.0000\n",
      "Epoch 21/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0358 - accuracy: 0.4691 - top3_acc: 1.0000 - val_loss: 1.0995 - val_accuracy: 0.2600 - val_top3_acc: 1.0000\n",
      "Epoch 22/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0231 - accuracy: 0.4784 - top3_acc: 1.0000 - val_loss: 1.0092 - val_accuracy: 0.5371 - val_top3_acc: 1.0000\n",
      "Epoch 23/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0188 - accuracy: 0.4741 - top3_acc: 1.0000 - val_loss: 1.0184 - val_accuracy: 0.5257 - val_top3_acc: 1.0000\n",
      "Epoch 24/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0111 - accuracy: 0.5043 - top3_acc: 1.0000 - val_loss: 1.0922 - val_accuracy: 0.2686 - val_top3_acc: 1.0000\n",
      "Epoch 25/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0138 - accuracy: 0.4907 - top3_acc: 1.0000 - val_loss: 0.9777 - val_accuracy: 0.5686 - val_top3_acc: 1.0000\n",
      "Epoch 26/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0059 - accuracy: 0.4993 - top3_acc: 1.0000 - val_loss: 1.0445 - val_accuracy: 0.3800 - val_top3_acc: 1.0000\n",
      "Epoch 27/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0021 - accuracy: 0.5079 - top3_acc: 1.0000 - val_loss: 1.0092 - val_accuracy: 0.4914 - val_top3_acc: 1.0000\n",
      "Epoch 28/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 1.0015 - accuracy: 0.5108 - top3_acc: 1.0000 - val_loss: 0.9612 - val_accuracy: 0.5771 - val_top3_acc: 1.0000\n",
      "Epoch 29/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9857 - accuracy: 0.5144 - top3_acc: 1.0000 - val_loss: 1.0757 - val_accuracy: 0.2686 - val_top3_acc: 1.0000\n",
      "Epoch 30/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9925 - accuracy: 0.5237 - top3_acc: 1.0000 - val_loss: 0.9901 - val_accuracy: 0.4857 - val_top3_acc: 1.0000\n",
      "Epoch 31/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9709 - accuracy: 0.5524 - top3_acc: 1.0000 - val_loss: 1.0073 - val_accuracy: 0.4371 - val_top3_acc: 1.0000\n",
      "Epoch 32/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9705 - accuracy: 0.5618 - top3_acc: 1.0000 - val_loss: 0.9911 - val_accuracy: 0.4943 - val_top3_acc: 1.0000\n",
      "Epoch 33/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9651 - accuracy: 0.5611 - top3_acc: 1.0000 - val_loss: 0.9796 - val_accuracy: 0.4886 - val_top3_acc: 1.0000\n",
      "Epoch 34/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9454 - accuracy: 0.5812 - top3_acc: 1.0000 - val_loss: 0.9407 - val_accuracy: 0.5571 - val_top3_acc: 1.0000\n",
      "Epoch 35/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9672 - accuracy: 0.5496 - top3_acc: 1.0000 - val_loss: 0.9520 - val_accuracy: 0.5314 - val_top3_acc: 1.0000\n",
      "Epoch 36/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9384 - accuracy: 0.5603 - top3_acc: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.5629 - val_top3_acc: 1.0000\n",
      "Epoch 37/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9419 - accuracy: 0.5790 - top3_acc: 1.0000 - val_loss: 0.9792 - val_accuracy: 0.4971 - val_top3_acc: 1.0000\n",
      "Epoch 38/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.9367 - accuracy: 0.5611 - top3_acc: 1.0000 - val_loss: 0.9257 - val_accuracy: 0.5857 - val_top3_acc: 1.0000\n",
      "Epoch 39/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9211 - accuracy: 0.5783 - top3_acc: 1.0000 - val_loss: 0.9495 - val_accuracy: 0.5714 - val_top3_acc: 1.0000\n",
      "Epoch 40/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9287 - accuracy: 0.5517 - top3_acc: 1.0000 - val_loss: 1.0001 - val_accuracy: 0.4486 - val_top3_acc: 1.0000\n",
      "Epoch 41/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9334 - accuracy: 0.5553 - top3_acc: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.5514 - val_top3_acc: 1.0000\n",
      "Epoch 42/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9190 - accuracy: 0.5797 - top3_acc: 1.0000 - val_loss: 1.0102 - val_accuracy: 0.4171 - val_top3_acc: 1.0000\n",
      "Epoch 43/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9192 - accuracy: 0.5618 - top3_acc: 1.0000 - val_loss: 0.9121 - val_accuracy: 0.5743 - val_top3_acc: 1.0000\n",
      "Epoch 44/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9253 - accuracy: 0.5675 - top3_acc: 1.0000 - val_loss: 0.9084 - val_accuracy: 0.5686 - val_top3_acc: 1.0000\n",
      "Epoch 45/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9129 - accuracy: 0.5740 - top3_acc: 1.0000 - val_loss: 0.9094 - val_accuracy: 0.5600 - val_top3_acc: 1.0000\n",
      "Epoch 46/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8966 - accuracy: 0.5934 - top3_acc: 1.0000 - val_loss: 0.9069 - val_accuracy: 0.5686 - val_top3_acc: 1.0000\n",
      "Epoch 47/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9128 - accuracy: 0.5761 - top3_acc: 1.0000 - val_loss: 0.9033 - val_accuracy: 0.5714 - val_top3_acc: 1.0000\n",
      "Epoch 48/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8983 - accuracy: 0.5833 - top3_acc: 1.0000 - val_loss: 0.9144 - val_accuracy: 0.5914 - val_top3_acc: 1.0000\n",
      "Epoch 49/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8931 - accuracy: 0.5955 - top3_acc: 1.0000 - val_loss: 0.9304 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 50/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8996 - accuracy: 0.5790 - top3_acc: 1.0000 - val_loss: 0.9594 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 51/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8994 - accuracy: 0.5826 - top3_acc: 1.0000 - val_loss: 0.9053 - val_accuracy: 0.5657 - val_top3_acc: 1.0000\n",
      "Epoch 52/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9098 - accuracy: 0.5776 - top3_acc: 1.0000 - val_loss: 1.0288 - val_accuracy: 0.4086 - val_top3_acc: 1.0000\n",
      "Epoch 53/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9146 - accuracy: 0.5596 - top3_acc: 1.0000 - val_loss: 0.9520 - val_accuracy: 0.5257 - val_top3_acc: 1.0000\n",
      "Epoch 54/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8844 - accuracy: 0.6085 - top3_acc: 1.0000 - val_loss: 0.9146 - val_accuracy: 0.5714 - val_top3_acc: 1.0000\n",
      "Epoch 55/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8886 - accuracy: 0.5920 - top3_acc: 1.0000 - val_loss: 0.9465 - val_accuracy: 0.5971 - val_top3_acc: 1.0000\n",
      "Epoch 56/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.9015 - accuracy: 0.5740 - top3_acc: 1.0000 - val_loss: 0.9847 - val_accuracy: 0.4743 - val_top3_acc: 1.0000\n",
      "Epoch 57/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8652 - accuracy: 0.5984 - top3_acc: 1.0000 - val_loss: 0.9310 - val_accuracy: 0.5343 - val_top3_acc: 1.0000\n",
      "Epoch 58/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8632 - accuracy: 0.6085 - top3_acc: 1.0000 - val_loss: 0.8991 - val_accuracy: 0.5629 - val_top3_acc: 1.0000\n",
      "Epoch 59/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8620 - accuracy: 0.6042 - top3_acc: 1.0000 - val_loss: 0.9170 - val_accuracy: 0.5771 - val_top3_acc: 1.0000\n",
      "Epoch 60/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8479 - accuracy: 0.6336 - top3_acc: 1.0000 - val_loss: 0.9174 - val_accuracy: 0.5829 - val_top3_acc: 1.0000\n",
      "Epoch 61/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8487 - accuracy: 0.6250 - top3_acc: 1.0000 - val_loss: 0.9239 - val_accuracy: 0.5943 - val_top3_acc: 1.0000\n",
      "Epoch 62/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8352 - accuracy: 0.6185 - top3_acc: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.5343 - val_top3_acc: 1.0000\n",
      "Epoch 63/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8379 - accuracy: 0.6178 - top3_acc: 1.0000 - val_loss: 0.9505 - val_accuracy: 0.5086 - val_top3_acc: 1.0000\n",
      "Epoch 64/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8318 - accuracy: 0.6185 - top3_acc: 1.0000 - val_loss: 0.9921 - val_accuracy: 0.5029 - val_top3_acc: 1.0000\n",
      "Epoch 65/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8588 - accuracy: 0.6078 - top3_acc: 1.0000 - val_loss: 0.9643 - val_accuracy: 0.5571 - val_top3_acc: 1.0000\n",
      "Epoch 66/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8643 - accuracy: 0.6020 - top3_acc: 1.0000 - val_loss: 0.9487 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 67/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8425 - accuracy: 0.6343 - top3_acc: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.5914 - val_top3_acc: 1.0000\n",
      "Epoch 68/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8451 - accuracy: 0.6063 - top3_acc: 1.0000 - val_loss: 0.9258 - val_accuracy: 0.5714 - val_top3_acc: 1.0000\n",
      "Epoch 69/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8365 - accuracy: 0.6193 - top3_acc: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.4800 - val_top3_acc: 1.0000\n",
      "Epoch 70/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8443 - accuracy: 0.6092 - top3_acc: 1.0000 - val_loss: 0.9340 - val_accuracy: 0.5800 - val_top3_acc: 1.0000\n",
      "Epoch 71/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8063 - accuracy: 0.6530 - top3_acc: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.5771 - val_top3_acc: 1.0000\n",
      "Epoch 72/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8202 - accuracy: 0.6408 - top3_acc: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.5743 - val_top3_acc: 1.0000\n",
      "Epoch 73/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8190 - accuracy: 0.6315 - top3_acc: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.5914 - val_top3_acc: 1.0000\n",
      "Epoch 74/400\n",
      "1392/1392 [==============================] - 10s 8ms/step - loss: 0.8030 - accuracy: 0.6516 - top3_acc: 1.0000 - val_loss: 0.9383 - val_accuracy: 0.5257 - val_top3_acc: 1.0000\n",
      "Epoch 75/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8086 - accuracy: 0.6430 - top3_acc: 1.0000 - val_loss: 0.9849 - val_accuracy: 0.5343 - val_top3_acc: 1.0000\n",
      "Epoch 76/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.8204 - accuracy: 0.6250 - top3_acc: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.5286 - val_top3_acc: 1.0000\n",
      "Epoch 77/400\n",
      "1392/1392 [==============================] - 13s 9ms/step - loss: 0.8186 - accuracy: 0.6473 - top3_acc: 1.0000 - val_loss: 0.9730 - val_accuracy: 0.5286 - val_top3_acc: 1.0000\n",
      "Epoch 78/400\n",
      "1392/1392 [==============================] - 13s 9ms/step - loss: 0.7994 - accuracy: 0.6351 - top3_acc: 1.0000 - val_loss: 0.9365 - val_accuracy: 0.5400 - val_top3_acc: 1.0000\n",
      "Epoch 79/400\n",
      "1392/1392 [==============================] - 12s 9ms/step - loss: 0.7946 - accuracy: 0.6444 - top3_acc: 1.0000 - val_loss: 0.8931 - val_accuracy: 0.5829 - val_top3_acc: 1.0000\n",
      "Epoch 80/400\n",
      "1392/1392 [==============================] - 12s 9ms/step - loss: 0.7817 - accuracy: 0.6674 - top3_acc: 1.0000 - val_loss: 0.8750 - val_accuracy: 0.5857 - val_top3_acc: 1.0000\n",
      "Epoch 81/400\n",
      "1392/1392 [==============================] - 12s 8ms/step - loss: 0.7741 - accuracy: 0.6753 - top3_acc: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.5857 - val_top3_acc: 1.0000\n",
      "Epoch 82/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.7776 - accuracy: 0.6638 - top3_acc: 1.0000 - val_loss: 0.8869 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 83/400\n",
      "1392/1392 [==============================] - 12s 9ms/step - loss: 0.7838 - accuracy: 0.6444 - top3_acc: 1.0000 - val_loss: 0.8783 - val_accuracy: 0.5914 - val_top3_acc: 1.0000\n",
      "Epoch 84/400\n",
      "1392/1392 [==============================] - 12s 8ms/step - loss: 0.7606 - accuracy: 0.6659 - top3_acc: 1.0000 - val_loss: 0.9014 - val_accuracy: 0.5457 - val_top3_acc: 1.0000\n",
      "Epoch 85/400\n",
      "1392/1392 [==============================] - 16s 11ms/step - loss: 0.7658 - accuracy: 0.6710 - top3_acc: 1.0000 - val_loss: 0.8626 - val_accuracy: 0.5857 - val_top3_acc: 1.0000\n",
      "Epoch 86/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7599 - accuracy: 0.6695 - top3_acc: 1.0000 - val_loss: 0.8666 - val_accuracy: 0.5857 - val_top3_acc: 1.0000\n",
      "Epoch 87/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7808 - accuracy: 0.6545 - top3_acc: 1.0000 - val_loss: 0.8665 - val_accuracy: 0.5829 - val_top3_acc: 1.0000\n",
      "Epoch 88/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7828 - accuracy: 0.6602 - top3_acc: 1.0000 - val_loss: 0.9083 - val_accuracy: 0.5371 - val_top3_acc: 1.0000\n",
      "Epoch 89/400\n",
      "1392/1392 [==============================] - 15s 10ms/step - loss: 0.7814 - accuracy: 0.6588 - top3_acc: 1.0000 - val_loss: 0.9259 - val_accuracy: 0.5371 - val_top3_acc: 1.0000\n",
      "Epoch 90/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.7670 - accuracy: 0.6703 - top3_acc: 1.0000 - val_loss: 1.0005 - val_accuracy: 0.4914 - val_top3_acc: 1.0000\n",
      "Epoch 91/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.8045 - accuracy: 0.6293 - top3_acc: 1.0000 - val_loss: 0.9124 - val_accuracy: 0.5857 - val_top3_acc: 1.0000\n",
      "Epoch 92/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.7622 - accuracy: 0.6681 - top3_acc: 1.0000 - val_loss: 0.8874 - val_accuracy: 0.5800 - val_top3_acc: 1.0000\n",
      "Epoch 93/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.7871 - accuracy: 0.6580 - top3_acc: 1.0000 - val_loss: 0.8862 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 94/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.8022 - accuracy: 0.6401 - top3_acc: 1.0000 - val_loss: 0.9071 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 95/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.7538 - accuracy: 0.6667 - top3_acc: 1.0000 - val_loss: 0.9706 - val_accuracy: 0.5629 - val_top3_acc: 1.0000\n",
      "Epoch 96/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.7480 - accuracy: 0.6717 - top3_acc: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.5629 - val_top3_acc: 1.0000\n",
      "Epoch 97/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.7326 - accuracy: 0.6853 - top3_acc: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.6000 - val_top3_acc: 1.0000\n",
      "Epoch 98/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.7392 - accuracy: 0.6782 - top3_acc: 1.0000 - val_loss: 0.8915 - val_accuracy: 0.5971 - val_top3_acc: 1.0000\n",
      "Epoch 99/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.7270 - accuracy: 0.6839 - top3_acc: 1.0000 - val_loss: 0.9406 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 100/400\n",
      "1392/1392 [==============================] - 15s 11ms/step - loss: 0.7451 - accuracy: 0.6818 - top3_acc: 1.0000 - val_loss: 0.8804 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 101/400\n",
      "1392/1392 [==============================] - 15s 10ms/step - loss: 0.7621 - accuracy: 0.6746 - top3_acc: 1.0000 - val_loss: 0.8791 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 102/400\n",
      "1392/1392 [==============================] - 12s 9ms/step - loss: 0.7780 - accuracy: 0.6480 - top3_acc: 1.0000 - val_loss: 0.8634 - val_accuracy: 0.6086 - val_top3_acc: 1.0000\n",
      "Epoch 103/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.7901 - accuracy: 0.6566 - top3_acc: 1.0000 - val_loss: 0.8505 - val_accuracy: 0.5914 - val_top3_acc: 1.0000\n",
      "Epoch 104/400\n",
      "1392/1392 [==============================] - 16s 11ms/step - loss: 0.8119 - accuracy: 0.6580 - top3_acc: 1.0000 - val_loss: 0.8684 - val_accuracy: 0.5800 - val_top3_acc: 1.0000\n",
      "Epoch 105/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7961 - accuracy: 0.6659 - top3_acc: 1.0000 - val_loss: 0.9002 - val_accuracy: 0.5371 - val_top3_acc: 1.0000\n",
      "Epoch 106/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7909 - accuracy: 0.6588 - top3_acc: 1.0000 - val_loss: 0.8956 - val_accuracy: 0.5686 - val_top3_acc: 1.0000\n",
      "Epoch 107/400\n",
      "1392/1392 [==============================] - 13s 10ms/step - loss: 0.7773 - accuracy: 0.6530 - top3_acc: 1.0000 - val_loss: 0.8643 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 108/400\n",
      "1392/1392 [==============================] - 13s 10ms/step - loss: 0.7576 - accuracy: 0.6674 - top3_acc: 1.0000 - val_loss: 0.9468 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 109/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7554 - accuracy: 0.6782 - top3_acc: 1.0000 - val_loss: 0.9311 - val_accuracy: 0.5800 - val_top3_acc: 1.0000\n",
      "Epoch 110/400\n",
      "1392/1392 [==============================] - 15s 11ms/step - loss: 0.7285 - accuracy: 0.6925 - top3_acc: 1.0000 - val_loss: 0.8821 - val_accuracy: 0.5943 - val_top3_acc: 1.0000\n",
      "Epoch 111/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7219 - accuracy: 0.7126 - top3_acc: 1.0000 - val_loss: 0.8689 - val_accuracy: 0.5714 - val_top3_acc: 1.0000\n",
      "Epoch 112/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7174 - accuracy: 0.6861 - top3_acc: 1.0000 - val_loss: 0.8577 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 113/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7226 - accuracy: 0.6968 - top3_acc: 1.0000 - val_loss: 0.8679 - val_accuracy: 0.6000 - val_top3_acc: 1.0000\n",
      "Epoch 114/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7125 - accuracy: 0.7098 - top3_acc: 1.0000 - val_loss: 0.8986 - val_accuracy: 0.5971 - val_top3_acc: 1.0000\n",
      "Epoch 115/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7305 - accuracy: 0.6875 - top3_acc: 1.0000 - val_loss: 0.9952 - val_accuracy: 0.5943 - val_top3_acc: 1.0000\n",
      "Epoch 116/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7402 - accuracy: 0.6825 - top3_acc: 1.0000 - val_loss: 0.9476 - val_accuracy: 0.5886 - val_top3_acc: 1.0000\n",
      "Epoch 117/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7374 - accuracy: 0.6825 - top3_acc: 1.0000 - val_loss: 0.8763 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 118/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7555 - accuracy: 0.6659 - top3_acc: 1.0000 - val_loss: 0.8595 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 119/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7114 - accuracy: 0.7026 - top3_acc: 1.0000 - val_loss: 0.8509 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 120/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7157 - accuracy: 0.7004 - top3_acc: 1.0000 - val_loss: 0.8483 - val_accuracy: 0.5829 - val_top3_acc: 1.0000\n",
      "Epoch 121/400\n",
      "1392/1392 [==============================] - 13s 10ms/step - loss: 0.7065 - accuracy: 0.7019 - top3_acc: 1.0000 - val_loss: 0.8712 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 122/400\n",
      "1392/1392 [==============================] - 13s 10ms/step - loss: 0.6998 - accuracy: 0.7062 - top3_acc: 1.0000 - val_loss: 0.9242 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 123/400\n",
      "1392/1392 [==============================] - 15s 11ms/step - loss: 0.7061 - accuracy: 0.6961 - top3_acc: 1.0000 - val_loss: 0.9164 - val_accuracy: 0.5743 - val_top3_acc: 1.0000\n",
      "Epoch 124/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.6819 - accuracy: 0.7134 - top3_acc: 1.0000 - val_loss: 0.9000 - val_accuracy: 0.5857 - val_top3_acc: 1.0000\n",
      "Epoch 125/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.6940 - accuracy: 0.6961 - top3_acc: 1.0000 - val_loss: 0.8946 - val_accuracy: 0.5829 - val_top3_acc: 1.0000\n",
      "Epoch 126/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.6843 - accuracy: 0.7126 - top3_acc: 1.0000 - val_loss: 0.8500 - val_accuracy: 0.5886 - val_top3_acc: 1.0000\n",
      "Epoch 127/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.6755 - accuracy: 0.7213 - top3_acc: 1.0000 - val_loss: 0.8812 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 128/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.6759 - accuracy: 0.7148 - top3_acc: 1.0000 - val_loss: 0.8682 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 129/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.6810 - accuracy: 0.6932 - top3_acc: 1.0000 - val_loss: 0.9027 - val_accuracy: 0.5800 - val_top3_acc: 1.0000\n",
      "Epoch 130/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.6736 - accuracy: 0.7069 - top3_acc: 1.0000 - val_loss: 0.9532 - val_accuracy: 0.5486 - val_top3_acc: 1.0000\n",
      "Epoch 131/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.6906 - accuracy: 0.7069 - top3_acc: 1.0000 - val_loss: 0.8966 - val_accuracy: 0.5771 - val_top3_acc: 1.0000\n",
      "Epoch 132/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.6747 - accuracy: 0.7019 - top3_acc: 1.0000 - val_loss: 0.8988 - val_accuracy: 0.5886 - val_top3_acc: 1.0000\n",
      "Epoch 133/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7171 - accuracy: 0.6724 - top3_acc: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.4914 - val_top3_acc: 1.0000\n",
      "Epoch 134/400\n",
      "1392/1392 [==============================] - 13s 10ms/step - loss: 0.8000 - accuracy: 0.6473 - top3_acc: 1.0000 - val_loss: 0.8859 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 135/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.7510 - accuracy: 0.6803 - top3_acc: 1.0000 - val_loss: 0.9377 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 136/400\n",
      "1392/1392 [==============================] - 13s 10ms/step - loss: 0.6969 - accuracy: 0.7033 - top3_acc: 1.0000 - val_loss: 0.8779 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 137/400\n",
      "1392/1392 [==============================] - 13s 10ms/step - loss: 0.6948 - accuracy: 0.7076 - top3_acc: 1.0000 - val_loss: 0.8679 - val_accuracy: 0.5771 - val_top3_acc: 1.0000\n",
      "Epoch 138/400\n",
      "1392/1392 [==============================] - 16s 12ms/step - loss: 0.6807 - accuracy: 0.7148 - top3_acc: 1.0000 - val_loss: 0.9531 - val_accuracy: 0.5314 - val_top3_acc: 1.0000\n",
      "Epoch 139/400\n",
      "1392/1392 [==============================] - 16s 12ms/step - loss: 0.7304 - accuracy: 0.6918 - top3_acc: 1.0000 - val_loss: 0.8737 - val_accuracy: 0.5771 - val_top3_acc: 1.0000\n",
      "Epoch 140/400\n",
      "1392/1392 [==============================] - 12s 9ms/step - loss: 0.6937 - accuracy: 0.7004 - top3_acc: 1.0000 - val_loss: 0.9224 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 141/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.6871 - accuracy: 0.7177 - top3_acc: 1.0000 - val_loss: 0.8827 - val_accuracy: 0.5886 - val_top3_acc: 1.0000\n",
      "Epoch 142/400\n",
      "1392/1392 [==============================] - 16s 11ms/step - loss: 0.6863 - accuracy: 0.7062 - top3_acc: 1.0000 - val_loss: 0.8725 - val_accuracy: 0.5657 - val_top3_acc: 1.0000\n",
      "Epoch 143/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.6643 - accuracy: 0.7414 - top3_acc: 1.0000 - val_loss: 0.8644 - val_accuracy: 0.5686 - val_top3_acc: 1.0000\n",
      "Epoch 144/400\n",
      "1392/1392 [==============================] - 12s 9ms/step - loss: 0.6772 - accuracy: 0.7026 - top3_acc: 1.0000 - val_loss: 0.8642 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 145/400\n",
      "1392/1392 [==============================] - 14s 10ms/step - loss: 0.6582 - accuracy: 0.7170 - top3_acc: 1.0000 - val_loss: 0.8765 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 146/400\n",
      "1392/1392 [==============================] - 15s 11ms/step - loss: 0.6678 - accuracy: 0.7112 - top3_acc: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.5686 - val_top3_acc: 1.0000\n",
      "Epoch 147/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6724 - accuracy: 0.7162 - top3_acc: 1.0000 - val_loss: 0.9482 - val_accuracy: 0.5686 - val_top3_acc: 1.0000\n",
      "Epoch 148/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6620 - accuracy: 0.7249 - top3_acc: 1.0000 - val_loss: 0.9073 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 149/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.6384 - accuracy: 0.7277 - top3_acc: 1.0000 - val_loss: 0.8739 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 150/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6348 - accuracy: 0.7356 - top3_acc: 1.0000 - val_loss: 0.8982 - val_accuracy: 0.5971 - val_top3_acc: 1.0000\n",
      "Epoch 151/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6407 - accuracy: 0.7364 - top3_acc: 1.0000 - val_loss: 0.8772 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 152/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6422 - accuracy: 0.7234 - top3_acc: 1.0000 - val_loss: 0.9180 - val_accuracy: 0.5629 - val_top3_acc: 1.0000\n",
      "Epoch 153/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6483 - accuracy: 0.7249 - top3_acc: 1.0000 - val_loss: 0.9002 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 154/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6263 - accuracy: 0.7342 - top3_acc: 1.0000 - val_loss: 0.8871 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 155/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.6341 - accuracy: 0.7335 - top3_acc: 1.0000 - val_loss: 0.9273 - val_accuracy: 0.5886 - val_top3_acc: 1.0000\n",
      "Epoch 156/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6462 - accuracy: 0.7162 - top3_acc: 1.0000 - val_loss: 0.8981 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 157/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6338 - accuracy: 0.7385 - top3_acc: 1.0000 - val_loss: 0.9226 - val_accuracy: 0.5943 - val_top3_acc: 1.0000\n",
      "Epoch 158/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.6142 - accuracy: 0.7392 - top3_acc: 1.0000 - val_loss: 0.9078 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 159/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6670 - accuracy: 0.7134 - top3_acc: 1.0000 - val_loss: 0.9074 - val_accuracy: 0.5971 - val_top3_acc: 1.0000\n",
      "Epoch 160/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.6518 - accuracy: 0.7292 - top3_acc: 1.0000 - val_loss: 0.9106 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 161/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6258 - accuracy: 0.7392 - top3_acc: 1.0000 - val_loss: 0.8492 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 162/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6607 - accuracy: 0.7119 - top3_acc: 1.0000 - val_loss: 0.8845 - val_accuracy: 0.5829 - val_top3_acc: 1.0000\n",
      "Epoch 163/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6147 - accuracy: 0.7356 - top3_acc: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.5686 - val_top3_acc: 1.0000\n",
      "Epoch 164/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6684 - accuracy: 0.7062 - top3_acc: 1.0000 - val_loss: 0.9096 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 165/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6808 - accuracy: 0.7083 - top3_acc: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 166/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6794 - accuracy: 0.7105 - top3_acc: 1.0000 - val_loss: 0.9205 - val_accuracy: 0.5914 - val_top3_acc: 1.0000\n",
      "Epoch 167/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6372 - accuracy: 0.7349 - top3_acc: 1.0000 - val_loss: 0.9137 - val_accuracy: 0.5571 - val_top3_acc: 1.0000\n",
      "Epoch 168/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6323 - accuracy: 0.7263 - top3_acc: 1.0000 - val_loss: 0.8712 - val_accuracy: 0.5886 - val_top3_acc: 1.0000\n",
      "Epoch 169/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6294 - accuracy: 0.7349 - top3_acc: 1.0000 - val_loss: 0.8747 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 170/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6048 - accuracy: 0.7421 - top3_acc: 1.0000 - val_loss: 0.8929 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 171/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6136 - accuracy: 0.7507 - top3_acc: 1.0000 - val_loss: 0.9845 - val_accuracy: 0.5571 - val_top3_acc: 1.0000\n",
      "Epoch 172/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6196 - accuracy: 0.7364 - top3_acc: 1.0000 - val_loss: 0.9183 - val_accuracy: 0.5657 - val_top3_acc: 1.0000\n",
      "Epoch 173/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6212 - accuracy: 0.7356 - top3_acc: 1.0000 - val_loss: 0.8951 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 174/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6401 - accuracy: 0.7284 - top3_acc: 1.0000 - val_loss: 0.8741 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 175/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6174 - accuracy: 0.7522 - top3_acc: 1.0000 - val_loss: 0.8936 - val_accuracy: 0.5714 - val_top3_acc: 1.0000\n",
      "Epoch 176/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6384 - accuracy: 0.7342 - top3_acc: 1.0000 - val_loss: 0.8705 - val_accuracy: 0.5971 - val_top3_acc: 1.0000\n",
      "Epoch 177/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6084 - accuracy: 0.7407 - top3_acc: 1.0000 - val_loss: 0.8949 - val_accuracy: 0.6000 - val_top3_acc: 1.0000\n",
      "Epoch 178/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5907 - accuracy: 0.7457 - top3_acc: 1.0000 - val_loss: 0.8779 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 179/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5985 - accuracy: 0.7414 - top3_acc: 1.0000 - val_loss: 0.8830 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 180/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5911 - accuracy: 0.7457 - top3_acc: 1.0000 - val_loss: 0.8784 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 181/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5892 - accuracy: 0.7493 - top3_acc: 1.0000 - val_loss: 0.8845 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 182/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5758 - accuracy: 0.7493 - top3_acc: 1.0000 - val_loss: 0.8752 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 183/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6032 - accuracy: 0.7543 - top3_acc: 1.0000 - val_loss: 0.9060 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 184/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5935 - accuracy: 0.7522 - top3_acc: 1.0000 - val_loss: 0.8577 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 185/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5826 - accuracy: 0.7658 - top3_acc: 1.0000 - val_loss: 0.8675 - val_accuracy: 0.6086 - val_top3_acc: 1.0000\n",
      "Epoch 186/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5926 - accuracy: 0.7464 - top3_acc: 1.0000 - val_loss: 0.9262 - val_accuracy: 0.5743 - val_top3_acc: 1.0000\n",
      "Epoch 187/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5945 - accuracy: 0.7565 - top3_acc: 1.0000 - val_loss: 0.9156 - val_accuracy: 0.6086 - val_top3_acc: 1.0000\n",
      "Epoch 188/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5847 - accuracy: 0.7593 - top3_acc: 1.0000 - val_loss: 0.9387 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 189/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6139 - accuracy: 0.7378 - top3_acc: 1.0000 - val_loss: 0.9540 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 190/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5875 - accuracy: 0.7522 - top3_acc: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 191/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5913 - accuracy: 0.7507 - top3_acc: 1.0000 - val_loss: 0.9034 - val_accuracy: 0.5943 - val_top3_acc: 1.0000\n",
      "Epoch 192/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6022 - accuracy: 0.7493 - top3_acc: 1.0000 - val_loss: 0.9361 - val_accuracy: 0.5629 - val_top3_acc: 1.0000\n",
      "Epoch 193/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6014 - accuracy: 0.7471 - top3_acc: 1.0000 - val_loss: 0.9155 - val_accuracy: 0.5829 - val_top3_acc: 1.0000\n",
      "Epoch 194/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5890 - accuracy: 0.7428 - top3_acc: 1.0000 - val_loss: 0.9146 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 195/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6046 - accuracy: 0.7507 - top3_acc: 1.0000 - val_loss: 0.8819 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 196/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5847 - accuracy: 0.7586 - top3_acc: 1.0000 - val_loss: 0.9137 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 197/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5840 - accuracy: 0.7493 - top3_acc: 1.0000 - val_loss: 0.8764 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 198/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5735 - accuracy: 0.7601 - top3_acc: 1.0000 - val_loss: 0.8914 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 199/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5784 - accuracy: 0.7615 - top3_acc: 1.0000 - val_loss: 0.9222 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 200/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5837 - accuracy: 0.7680 - top3_acc: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 201/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5636 - accuracy: 0.7615 - top3_acc: 1.0000 - val_loss: 0.8837 - val_accuracy: 0.6000 - val_top3_acc: 1.0000\n",
      "Epoch 202/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5572 - accuracy: 0.7751 - top3_acc: 1.0000 - val_loss: 0.8716 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 203/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5618 - accuracy: 0.7744 - top3_acc: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 204/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6019 - accuracy: 0.7428 - top3_acc: 1.0000 - val_loss: 0.8751 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 205/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5798 - accuracy: 0.7529 - top3_acc: 1.0000 - val_loss: 1.0417 - val_accuracy: 0.5543 - val_top3_acc: 1.0000\n",
      "Epoch 206/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.6015 - accuracy: 0.7371 - top3_acc: 1.0000 - val_loss: 0.9547 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 207/400\n",
      "1392/1392 [==============================] - 10s 8ms/step - loss: 0.5952 - accuracy: 0.7457 - top3_acc: 1.0000 - val_loss: 0.9167 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 208/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5784 - accuracy: 0.7708 - top3_acc: 1.0000 - val_loss: 0.8718 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 209/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5675 - accuracy: 0.7644 - top3_acc: 1.0000 - val_loss: 0.9085 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 210/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5627 - accuracy: 0.7658 - top3_acc: 1.0000 - val_loss: 0.9127 - val_accuracy: 0.5857 - val_top3_acc: 1.0000\n",
      "Epoch 211/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5587 - accuracy: 0.7708 - top3_acc: 1.0000 - val_loss: 0.8734 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 212/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5526 - accuracy: 0.7759 - top3_acc: 1.0000 - val_loss: 0.8647 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 213/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5623 - accuracy: 0.7665 - top3_acc: 1.0000 - val_loss: 0.8938 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 214/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5861 - accuracy: 0.7593 - top3_acc: 1.0000 - val_loss: 0.8632 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 215/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5785 - accuracy: 0.7457 - top3_acc: 1.0000 - val_loss: 0.9338 - val_accuracy: 0.6086 - val_top3_acc: 1.0000\n",
      "Epoch 216/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5719 - accuracy: 0.7493 - top3_acc: 1.0000 - val_loss: 0.9425 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 217/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5545 - accuracy: 0.7658 - top3_acc: 1.0000 - val_loss: 0.9470 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 218/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5694 - accuracy: 0.7622 - top3_acc: 1.0000 - val_loss: 0.9097 - val_accuracy: 0.6086 - val_top3_acc: 1.0000\n",
      "Epoch 219/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5684 - accuracy: 0.7665 - top3_acc: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 220/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5609 - accuracy: 0.7672 - top3_acc: 1.0000 - val_loss: 0.9424 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 221/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5567 - accuracy: 0.7787 - top3_acc: 1.0000 - val_loss: 0.9004 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 222/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5493 - accuracy: 0.7694 - top3_acc: 1.0000 - val_loss: 0.8928 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 223/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5359 - accuracy: 0.7658 - top3_acc: 1.0000 - val_loss: 0.9138 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 224/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5438 - accuracy: 0.7651 - top3_acc: 1.0000 - val_loss: 0.8715 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 225/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5420 - accuracy: 0.7852 - top3_acc: 1.0000 - val_loss: 0.8749 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 226/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5367 - accuracy: 0.7694 - top3_acc: 1.0000 - val_loss: 0.8962 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 227/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5404 - accuracy: 0.7680 - top3_acc: 1.0000 - val_loss: 0.8963 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 228/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5257 - accuracy: 0.7780 - top3_acc: 1.0000 - val_loss: 0.8918 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 229/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5298 - accuracy: 0.7780 - top3_acc: 1.0000 - val_loss: 0.8985 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 230/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5635 - accuracy: 0.7622 - top3_acc: 1.0000 - val_loss: 0.9743 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 231/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5472 - accuracy: 0.7744 - top3_acc: 1.0000 - val_loss: 0.9349 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 232/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5537 - accuracy: 0.7723 - top3_acc: 1.0000 - val_loss: 0.9798 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 233/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5513 - accuracy: 0.7708 - top3_acc: 1.0000 - val_loss: 0.9380 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 234/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5367 - accuracy: 0.7694 - top3_acc: 1.0000 - val_loss: 0.8946 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 235/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5368 - accuracy: 0.7902 - top3_acc: 1.0000 - val_loss: 0.8865 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 236/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5525 - accuracy: 0.7730 - top3_acc: 1.0000 - val_loss: 0.8701 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 237/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5471 - accuracy: 0.7694 - top3_acc: 1.0000 - val_loss: 0.9179 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 238/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5612 - accuracy: 0.7514 - top3_acc: 1.0000 - val_loss: 0.9480 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 239/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5432 - accuracy: 0.7744 - top3_acc: 1.0000 - val_loss: 0.9025 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 240/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5336 - accuracy: 0.7845 - top3_acc: 1.0000 - val_loss: 0.8866 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 241/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.5252 - accuracy: 0.7866 - top3_acc: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 242/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5270 - accuracy: 0.7917 - top3_acc: 1.0000 - val_loss: 0.9124 - val_accuracy: 0.6086 - val_top3_acc: 1.0000\n",
      "Epoch 243/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5406 - accuracy: 0.7830 - top3_acc: 1.0000 - val_loss: 0.9192 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 244/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5349 - accuracy: 0.7802 - top3_acc: 1.0000 - val_loss: 0.9765 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 245/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5440 - accuracy: 0.7672 - top3_acc: 1.0000 - val_loss: 0.8799 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 246/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5248 - accuracy: 0.7866 - top3_acc: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.6000 - val_top3_acc: 1.0000\n",
      "Epoch 247/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5368 - accuracy: 0.7802 - top3_acc: 1.0000 - val_loss: 0.8752 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 248/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5375 - accuracy: 0.7780 - top3_acc: 1.0000 - val_loss: 0.9156 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 249/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5273 - accuracy: 0.7830 - top3_acc: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 250/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5322 - accuracy: 0.7780 - top3_acc: 1.0000 - val_loss: 0.8969 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 251/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5428 - accuracy: 0.7780 - top3_acc: 1.0000 - val_loss: 0.8678 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 252/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5315 - accuracy: 0.7866 - top3_acc: 1.0000 - val_loss: 0.9003 - val_accuracy: 0.6086 - val_top3_acc: 1.0000\n",
      "Epoch 253/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5222 - accuracy: 0.7859 - top3_acc: 1.0000 - val_loss: 0.9331 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 254/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5134 - accuracy: 0.7924 - top3_acc: 1.0000 - val_loss: 0.9034 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 255/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5003 - accuracy: 0.7996 - top3_acc: 1.0000 - val_loss: 0.8954 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 256/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5179 - accuracy: 0.7852 - top3_acc: 1.0000 - val_loss: 0.8805 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 257/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5236 - accuracy: 0.7795 - top3_acc: 1.0000 - val_loss: 0.9615 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 258/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5340 - accuracy: 0.7809 - top3_acc: 1.0000 - val_loss: 0.9904 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 259/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5274 - accuracy: 0.7895 - top3_acc: 1.0000 - val_loss: 0.8936 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 260/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5424 - accuracy: 0.7759 - top3_acc: 1.0000 - val_loss: 0.8893 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 261/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5125 - accuracy: 0.7967 - top3_acc: 1.0000 - val_loss: 0.9233 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 262/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5321 - accuracy: 0.7845 - top3_acc: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 263/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5243 - accuracy: 0.7823 - top3_acc: 1.0000 - val_loss: 0.8819 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 264/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5324 - accuracy: 0.7701 - top3_acc: 1.0000 - val_loss: 0.9002 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 265/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5074 - accuracy: 0.7909 - top3_acc: 1.0000 - val_loss: 0.9434 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 266/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5190 - accuracy: 0.7809 - top3_acc: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 267/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5161 - accuracy: 0.7881 - top3_acc: 1.0000 - val_loss: 0.9007 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 268/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5133 - accuracy: 0.7938 - top3_acc: 1.0000 - val_loss: 0.8698 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 269/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5140 - accuracy: 0.7974 - top3_acc: 1.0000 - val_loss: 0.9346 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 270/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5248 - accuracy: 0.7838 - top3_acc: 1.0000 - val_loss: 0.9334 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 271/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5249 - accuracy: 0.7823 - top3_acc: 1.0000 - val_loss: 0.9451 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 272/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5015 - accuracy: 0.7953 - top3_acc: 1.0000 - val_loss: 0.9168 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 273/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4894 - accuracy: 0.7938 - top3_acc: 1.0000 - val_loss: 0.9108 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 274/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4957 - accuracy: 0.7953 - top3_acc: 1.0000 - val_loss: 0.9425 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 275/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5071 - accuracy: 0.7909 - top3_acc: 1.0000 - val_loss: 0.8895 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 276/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5073 - accuracy: 0.8017 - top3_acc: 1.0000 - val_loss: 0.9060 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 277/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4960 - accuracy: 0.7909 - top3_acc: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 278/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4968 - accuracy: 0.8003 - top3_acc: 1.0000 - val_loss: 0.9378 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 279/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5003 - accuracy: 0.8060 - top3_acc: 1.0000 - val_loss: 0.8934 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 280/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4847 - accuracy: 0.8024 - top3_acc: 1.0000 - val_loss: 0.9018 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 281/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4951 - accuracy: 0.7981 - top3_acc: 1.0000 - val_loss: 0.9019 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 282/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5077 - accuracy: 0.7996 - top3_acc: 1.0000 - val_loss: 0.9547 - val_accuracy: 0.5800 - val_top3_acc: 1.0000\n",
      "Epoch 283/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5168 - accuracy: 0.7823 - top3_acc: 1.0000 - val_loss: 0.9398 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 284/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4930 - accuracy: 0.8111 - top3_acc: 1.0000 - val_loss: 0.9070 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 285/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5002 - accuracy: 0.7924 - top3_acc: 1.0000 - val_loss: 0.9354 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 286/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.4951 - accuracy: 0.8010 - top3_acc: 1.0000 - val_loss: 0.9015 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 287/400\n",
      "1392/1392 [==============================] - 12s 9ms/step - loss: 0.5008 - accuracy: 0.7981 - top3_acc: 1.0000 - val_loss: 0.8964 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 288/400\n",
      "1392/1392 [==============================] - 12s 8ms/step - loss: 0.4838 - accuracy: 0.8024 - top3_acc: 1.0000 - val_loss: 0.8927 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 289/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5031 - accuracy: 0.7902 - top3_acc: 1.0000 - val_loss: 0.9749 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 290/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4934 - accuracy: 0.7996 - top3_acc: 1.0000 - val_loss: 0.9353 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 291/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5001 - accuracy: 0.7895 - top3_acc: 1.0000 - val_loss: 0.9474 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 292/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5156 - accuracy: 0.7823 - top3_acc: 1.0000 - val_loss: 0.9311 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 293/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4964 - accuracy: 0.7989 - top3_acc: 1.0000 - val_loss: 0.9530 - val_accuracy: 0.5886 - val_top3_acc: 1.0000\n",
      "Epoch 294/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5027 - accuracy: 0.8010 - top3_acc: 1.0000 - val_loss: 0.8855 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 295/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4871 - accuracy: 0.7953 - top3_acc: 1.0000 - val_loss: 0.9258 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 296/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4849 - accuracy: 0.8010 - top3_acc: 1.0000 - val_loss: 0.9140 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 297/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4812 - accuracy: 0.8046 - top3_acc: 1.0000 - val_loss: 0.9511 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 298/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.5089 - accuracy: 0.8060 - top3_acc: 1.0000 - val_loss: 0.9037 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 299/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4900 - accuracy: 0.8053 - top3_acc: 1.0000 - val_loss: 0.9408 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 300/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4901 - accuracy: 0.8046 - top3_acc: 1.0000 - val_loss: 0.8907 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 301/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4719 - accuracy: 0.7967 - top3_acc: 1.0000 - val_loss: 0.9349 - val_accuracy: 0.6086 - val_top3_acc: 1.0000\n",
      "Epoch 302/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5091 - accuracy: 0.7989 - top3_acc: 1.0000 - val_loss: 1.0136 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 303/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4975 - accuracy: 0.7909 - top3_acc: 1.0000 - val_loss: 0.9161 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 304/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4932 - accuracy: 0.7989 - top3_acc: 1.0000 - val_loss: 0.8881 - val_accuracy: 0.6200 - val_top3_acc: 1.0000\n",
      "Epoch 305/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4830 - accuracy: 0.8003 - top3_acc: 1.0000 - val_loss: 0.9352 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 306/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4981 - accuracy: 0.7981 - top3_acc: 1.0000 - val_loss: 0.9327 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 307/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4729 - accuracy: 0.7981 - top3_acc: 1.0000 - val_loss: 0.8953 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 308/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4959 - accuracy: 0.7953 - top3_acc: 1.0000 - val_loss: 0.9827 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 309/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5135 - accuracy: 0.7895 - top3_acc: 1.0000 - val_loss: 0.9283 - val_accuracy: 0.5943 - val_top3_acc: 1.0000\n",
      "Epoch 310/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4759 - accuracy: 0.8060 - top3_acc: 1.0000 - val_loss: 0.9048 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 311/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4979 - accuracy: 0.7881 - top3_acc: 1.0000 - val_loss: 0.9405 - val_accuracy: 0.6457 - val_top3_acc: 1.0000\n",
      "Epoch 312/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4964 - accuracy: 0.7967 - top3_acc: 1.0000 - val_loss: 0.8970 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 313/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4752 - accuracy: 0.8132 - top3_acc: 1.0000 - val_loss: 0.9212 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 314/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4745 - accuracy: 0.7996 - top3_acc: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 315/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.5044 - accuracy: 0.7895 - top3_acc: 1.0000 - val_loss: 0.9127 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 316/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4904 - accuracy: 0.8010 - top3_acc: 1.0000 - val_loss: 0.9548 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 317/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4769 - accuracy: 0.7989 - top3_acc: 1.0000 - val_loss: 0.9020 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 318/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4723 - accuracy: 0.8125 - top3_acc: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 319/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4919 - accuracy: 0.7974 - top3_acc: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 320/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4841 - accuracy: 0.7953 - top3_acc: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 321/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4819 - accuracy: 0.8089 - top3_acc: 1.0000 - val_loss: 0.9291 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 322/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4822 - accuracy: 0.8125 - top3_acc: 1.0000 - val_loss: 0.9444 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 323/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4477 - accuracy: 0.8384 - top3_acc: 1.0000 - val_loss: 0.9111 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 324/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4666 - accuracy: 0.8060 - top3_acc: 1.0000 - val_loss: 0.9393 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 325/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4853 - accuracy: 0.8017 - top3_acc: 1.0000 - val_loss: 0.9582 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 326/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4740 - accuracy: 0.8046 - top3_acc: 1.0000 - val_loss: 0.9011 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 327/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4710 - accuracy: 0.8190 - top3_acc: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.6086 - val_top3_acc: 1.0000\n",
      "Epoch 328/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4633 - accuracy: 0.8147 - top3_acc: 1.0000 - val_loss: 0.9317 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 329/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4536 - accuracy: 0.8139 - top3_acc: 1.0000 - val_loss: 0.8969 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 330/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.4731 - accuracy: 0.8075 - top3_acc: 1.0000 - val_loss: 0.9409 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 331/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4820 - accuracy: 0.8039 - top3_acc: 1.0000 - val_loss: 0.9248 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 332/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4848 - accuracy: 0.8132 - top3_acc: 1.0000 - val_loss: 0.9025 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 333/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4802 - accuracy: 0.7967 - top3_acc: 1.0000 - val_loss: 0.9396 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 334/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4684 - accuracy: 0.8103 - top3_acc: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 335/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4672 - accuracy: 0.7953 - top3_acc: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 336/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4610 - accuracy: 0.8204 - top3_acc: 1.0000 - val_loss: 0.9197 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 337/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4580 - accuracy: 0.8032 - top3_acc: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 338/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4470 - accuracy: 0.8247 - top3_acc: 1.0000 - val_loss: 0.9230 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 339/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4617 - accuracy: 0.8053 - top3_acc: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 340/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4634 - accuracy: 0.8182 - top3_acc: 1.0000 - val_loss: 0.9247 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 341/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4506 - accuracy: 0.8190 - top3_acc: 1.0000 - val_loss: 0.9169 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 342/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4644 - accuracy: 0.8024 - top3_acc: 1.0000 - val_loss: 0.9499 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 343/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4706 - accuracy: 0.8017 - top3_acc: 1.0000 - val_loss: 0.9054 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 344/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4680 - accuracy: 0.8060 - top3_acc: 1.0000 - val_loss: 0.9693 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 345/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4713 - accuracy: 0.8161 - top3_acc: 1.0000 - val_loss: 0.9485 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 346/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4605 - accuracy: 0.8103 - top3_acc: 1.0000 - val_loss: 0.8992 - val_accuracy: 0.6143 - val_top3_acc: 1.0000\n",
      "Epoch 347/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4719 - accuracy: 0.8060 - top3_acc: 1.0000 - val_loss: 0.9856 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 348/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4569 - accuracy: 0.8254 - top3_acc: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 349/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4563 - accuracy: 0.8168 - top3_acc: 1.0000 - val_loss: 0.9545 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 350/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4578 - accuracy: 0.8168 - top3_acc: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.6086 - val_top3_acc: 1.0000\n",
      "Epoch 351/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4523 - accuracy: 0.8147 - top3_acc: 1.0000 - val_loss: 0.9201 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 352/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4451 - accuracy: 0.8204 - top3_acc: 1.0000 - val_loss: 0.9357 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 353/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4595 - accuracy: 0.8197 - top3_acc: 1.0000 - val_loss: 0.9243 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 354/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.4687 - accuracy: 0.8103 - top3_acc: 1.0000 - val_loss: 0.9026 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 355/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.4585 - accuracy: 0.8211 - top3_acc: 1.0000 - val_loss: 0.9530 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 356/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.4436 - accuracy: 0.8254 - top3_acc: 1.0000 - val_loss: 0.9100 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 357/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.4413 - accuracy: 0.8211 - top3_acc: 1.0000 - val_loss: 0.9501 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 358/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4423 - accuracy: 0.8312 - top3_acc: 1.0000 - val_loss: 0.9301 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 359/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.4652 - accuracy: 0.8111 - top3_acc: 1.0000 - val_loss: 0.9122 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 360/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4423 - accuracy: 0.8154 - top3_acc: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 361/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4655 - accuracy: 0.8039 - top3_acc: 1.0000 - val_loss: 0.9259 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 362/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4410 - accuracy: 0.8168 - top3_acc: 1.0000 - val_loss: 0.9338 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 363/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.4479 - accuracy: 0.8175 - top3_acc: 1.0000 - val_loss: 0.9204 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 364/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.4320 - accuracy: 0.8398 - top3_acc: 1.0000 - val_loss: 0.9312 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 365/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4593 - accuracy: 0.8111 - top3_acc: 1.0000 - val_loss: 0.9651 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 366/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4781 - accuracy: 0.8010 - top3_acc: 1.0000 - val_loss: 0.9439 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 367/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4464 - accuracy: 0.8132 - top3_acc: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 368/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4458 - accuracy: 0.8175 - top3_acc: 1.0000 - val_loss: 0.9661 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 369/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4592 - accuracy: 0.8240 - top3_acc: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 370/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4462 - accuracy: 0.8175 - top3_acc: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.6029 - val_top3_acc: 1.0000\n",
      "Epoch 371/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4450 - accuracy: 0.8247 - top3_acc: 1.0000 - val_loss: 0.9220 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 372/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4551 - accuracy: 0.8154 - top3_acc: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.6229 - val_top3_acc: 1.0000\n",
      "Epoch 373/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4419 - accuracy: 0.8161 - top3_acc: 1.0000 - val_loss: 0.9473 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 374/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4602 - accuracy: 0.8111 - top3_acc: 1.0000 - val_loss: 0.9598 - val_accuracy: 0.5971 - val_top3_acc: 1.0000\n",
      "Epoch 375/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4464 - accuracy: 0.8132 - top3_acc: 1.0000 - val_loss: 0.9212 - val_accuracy: 0.6257 - val_top3_acc: 1.0000\n",
      "Epoch 376/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4272 - accuracy: 0.8297 - top3_acc: 1.0000 - val_loss: 0.9614 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 377/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4751 - accuracy: 0.8096 - top3_acc: 1.0000 - val_loss: 0.9937 - val_accuracy: 0.5829 - val_top3_acc: 1.0000\n",
      "Epoch 378/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4729 - accuracy: 0.8082 - top3_acc: 1.0000 - val_loss: 0.8969 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 379/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4489 - accuracy: 0.8168 - top3_acc: 1.0000 - val_loss: 1.0072 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 380/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4643 - accuracy: 0.8197 - top3_acc: 1.0000 - val_loss: 0.9302 - val_accuracy: 0.6400 - val_top3_acc: 1.0000\n",
      "Epoch 381/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4539 - accuracy: 0.8125 - top3_acc: 1.0000 - val_loss: 0.9292 - val_accuracy: 0.5886 - val_top3_acc: 1.0000\n",
      "Epoch 382/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4755 - accuracy: 0.8053 - top3_acc: 1.0000 - val_loss: 0.9583 - val_accuracy: 0.6314 - val_top3_acc: 1.0000\n",
      "Epoch 383/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4606 - accuracy: 0.8154 - top3_acc: 1.0000 - val_loss: 0.9185 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 384/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4391 - accuracy: 0.8276 - top3_acc: 1.0000 - val_loss: 0.9392 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 385/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4433 - accuracy: 0.8240 - top3_acc: 1.0000 - val_loss: 0.9779 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 386/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4526 - accuracy: 0.8247 - top3_acc: 1.0000 - val_loss: 0.9071 - val_accuracy: 0.6114 - val_top3_acc: 1.0000\n",
      "Epoch 387/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4494 - accuracy: 0.8276 - top3_acc: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.6286 - val_top3_acc: 1.0000\n",
      "Epoch 388/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4241 - accuracy: 0.8362 - top3_acc: 1.0000 - val_loss: 0.9075 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 389/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4442 - accuracy: 0.8261 - top3_acc: 1.0000 - val_loss: 0.9465 - val_accuracy: 0.6086 - val_top3_acc: 1.0000\n",
      "Epoch 390/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4426 - accuracy: 0.8391 - top3_acc: 1.0000 - val_loss: 0.9493 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 391/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4502 - accuracy: 0.8218 - top3_acc: 1.0000 - val_loss: 0.9342 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 392/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4492 - accuracy: 0.8233 - top3_acc: 1.0000 - val_loss: 0.9244 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 393/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4520 - accuracy: 0.8060 - top3_acc: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 394/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4365 - accuracy: 0.8211 - top3_acc: 1.0000 - val_loss: 0.9215 - val_accuracy: 0.6343 - val_top3_acc: 1.0000\n",
      "Epoch 395/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4313 - accuracy: 0.8254 - top3_acc: 1.0000 - val_loss: 0.9436 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 396/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4523 - accuracy: 0.8204 - top3_acc: 1.0000 - val_loss: 0.9120 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n",
      "Epoch 397/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4344 - accuracy: 0.8290 - top3_acc: 1.0000 - val_loss: 0.9480 - val_accuracy: 0.6057 - val_top3_acc: 1.0000\n",
      "Epoch 398/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4349 - accuracy: 0.8276 - top3_acc: 1.0000 - val_loss: 0.9225 - val_accuracy: 0.6429 - val_top3_acc: 1.0000\n",
      "Epoch 399/400\n",
      "1392/1392 [==============================] - 10s 7ms/step - loss: 0.4233 - accuracy: 0.8247 - top3_acc: 1.0000 - val_loss: 0.9670 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 400/400\n",
      "1392/1392 [==============================] - 11s 8ms/step - loss: 0.4389 - accuracy: 0.8240 - top3_acc: 1.0000 - val_loss: 0.9348 - val_accuracy: 0.6371 - val_top3_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Define bath and epochs\n",
    "batch_size = 256\n",
    "epochs = 400\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.0000001)\n",
    "mcp_save = ModelCheckpoint('../models/model_checkpoints/smote_test.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "cnnhistory=model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, y_test), callbacks=[mcp_save, lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 542, 15, 32)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 271, 7, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 271, 7, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 270, 6, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 135, 3, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 135, 3, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 134, 2, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 67, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 67, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 41,699\n",
      "Trainable params: 41,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model Summary\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# PLT History info\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
