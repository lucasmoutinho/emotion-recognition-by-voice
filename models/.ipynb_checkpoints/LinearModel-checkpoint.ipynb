{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and program variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split # to split dataset into train and test\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from time_series_dataset_loader import TimeSeriesDatasetLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../src/Features/2secsplit/MFCC_5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = TimeSeriesDatasetLoader(DATASET_PATH)\n",
    "X, y = dataset_loader.get_dataset(type_='emotion_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completing with zeros\n",
    "max_len = len(X[0])\n",
    "for row in X:\n",
    "        if len(row) > max_len:\n",
    "            max_len = len(row)\n",
    "\n",
    "X = pad_sequences(X, maxlen=max_len, padding='post', dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' More Preprocessing '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scalers = {}\n",
    "for i in range(X.shape[1]):\n",
    "    scalers[i] = RobustScaler()\n",
    "    X[:, i, :] = scalers[i].fit_transform(X[:, i, :]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scalers = {}\n",
    "for i in range(X.shape[1]):\n",
    "    scalers[i] = Normalizer()\n",
    "    X[:, i, :] = scalers[i].fit_transform(X[:, i, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.28221284,  0.08020835, -0.09187018,\n",
       "       -0.10788761,  0.62792463,  0.3675004 ,  0.16599244,  0.18636285,\n",
       "       -0.35420188,  0.19850305, -0.14629544, -0.18601133, -0.21646694,\n",
       "        0.18571278])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Finishing Preprocessing '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See X and y details\n",
    "print(X[:2])\n",
    "print(X.shape)\n",
    "\n",
    "print(y[:3])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "[ 0.          0.         -0.3985426   0.17236121  0.20710554  0.53951168\n",
      "  0.27022806 -0.17698213  0.18097142  0.38447591  0.21333375  0.25933594\n",
      "  0.13973263  0.14389864  0.19873753 -0.00874916]\n",
      "(1364, 36, 16)\n",
      "\n",
      "X_test:\n",
      "\n",
      "[ 0.          0.         -0.16368215 -0.23263857  0.33593844 -0.11182846\n",
      " -0.25904659  0.15678226 -0.4559063   0.39848814 -0.35079627  0.0575968\n",
      " -0.30985801  0.03822592  0.13462599  0.30565546]\n",
      "(585, 36, 16)\n",
      "\n",
      "y_train:\n",
      "\n",
      "[2 2 1]\n",
      "(1364,)\n",
      "\n",
      "y_test:\n",
      "\n",
      "[2 1 2]\n",
      "(585,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3)\n",
    "\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train[0][0])\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(X_test[0][0])\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"\\ny_train:\\n\")\n",
    "print(y_train[:3])\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\ny_test:\\n\")\n",
    "print(y_test[:3])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical matrices\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "[[ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.3985426 ]\n",
      " [ 0.17236121]\n",
      " [ 0.20710554]\n",
      " [ 0.53951168]\n",
      " [ 0.27022806]\n",
      " [-0.17698213]\n",
      " [ 0.18097142]\n",
      " [ 0.38447591]\n",
      " [ 0.21333375]\n",
      " [ 0.25933594]\n",
      " [ 0.13973263]\n",
      " [ 0.14389864]\n",
      " [ 0.19873753]\n",
      " [-0.00874916]]\n",
      "(1364, 36, 16, 1)\n",
      "\n",
      "X_test:\n",
      "\n",
      "[[ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.16368215]\n",
      " [-0.23263857]\n",
      " [ 0.33593844]\n",
      " [-0.11182846]\n",
      " [-0.25904659]\n",
      " [ 0.15678226]\n",
      " [-0.4559063 ]\n",
      " [ 0.39848814]\n",
      " [-0.35079627]\n",
      " [ 0.0575968 ]\n",
      " [-0.30985801]\n",
      " [ 0.03822592]\n",
      " [ 0.13462599]\n",
      " [ 0.30565546]]\n",
      "(585, 36, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "num_rows = X[0].shape[0]\n",
    "num_columns = X[0].shape[1]\n",
    "num_channels = 1\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train[0][0])\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(X_test[0][0])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model 1\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-k category accuracy\n",
    "import functools\n",
    "import keras\n",
    "top3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gabriel/.pyenv/versions/3.6.4/envs/machine-learning/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1364 samples, validate on 585 samples\n",
      "Epoch 1/400\n",
      "1364/1364 [==============================] - 4s 3ms/step - loss: 1.0346 - accuracy: 0.5301 - top3_acc: 1.0000 - val_loss: 0.9845 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 2/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9813 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 3/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9726 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9705 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 4/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9723 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9676 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 5/400\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.9662 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9622 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 6/400\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.9645 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9567 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 7/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9644 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9574 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 8/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9603 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9603 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 9/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.9567 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9565 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 10/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9572 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9496 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 11/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9551 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 12/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9570 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9531 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 13/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9547 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 14/400\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.9548 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9482 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 15/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.9544 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9454 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 16/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9527 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9519 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 17/400\n",
      "1364/1364 [==============================] - 1s 807us/step - loss: 0.9524 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9502 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 18/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9541 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9493 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 19/400\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.9521 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 20/400\n",
      "1364/1364 [==============================] - 1s 833us/step - loss: 0.9505 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9449 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 21/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9516 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9499 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 22/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.9534 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9543 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 23/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9510 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9456 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 24/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9503 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9454 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 25/400\n",
      "1364/1364 [==============================] - 1s 913us/step - loss: 0.9514 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 26/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9503 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9456 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 27/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9474 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9436 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 28/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9487 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 29/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9461 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9455 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 30/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9462 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9410 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 31/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9467 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9420 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 32/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9443 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9435 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 33/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9466 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9345 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 34/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9470 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9434 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 35/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9438 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9383 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 36/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9403 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9352 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 37/400\n",
      "1364/1364 [==============================] - 1s 948us/step - loss: 0.9430 - accuracy: 0.5733 - top3_acc: 1.0000 - val_loss: 0.9374 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 38/400\n",
      "1364/1364 [==============================] - 1s 945us/step - loss: 0.9377 - accuracy: 0.5726 - top3_acc: 1.0000 - val_loss: 0.9336 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 39/400\n",
      "1364/1364 [==============================] - 1s 958us/step - loss: 0.9375 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9315 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 40/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9357 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9327 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 41/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9338 - accuracy: 0.5726 - top3_acc: 1.0000 - val_loss: 0.9302 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 42/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9300 - accuracy: 0.5726 - top3_acc: 1.0000 - val_loss: 0.9257 - val_accuracy: 0.5897 - val_top3_acc: 1.0000\n",
      "Epoch 43/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9264 - accuracy: 0.5755 - top3_acc: 1.0000 - val_loss: 0.9231 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 44/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9260 - accuracy: 0.5748 - top3_acc: 1.0000 - val_loss: 0.9254 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 45/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9265 - accuracy: 0.5806 - top3_acc: 1.0000 - val_loss: 0.9309 - val_accuracy: 0.5897 - val_top3_acc: 1.0000\n",
      "Epoch 46/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9259 - accuracy: 0.5718 - top3_acc: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.5897 - val_top3_acc: 1.0000\n",
      "Epoch 47/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9206 - accuracy: 0.5792 - top3_acc: 1.0000 - val_loss: 0.9227 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 48/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9191 - accuracy: 0.5748 - top3_acc: 1.0000 - val_loss: 0.9203 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 49/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9204 - accuracy: 0.5836 - top3_acc: 1.0000 - val_loss: 0.9160 - val_accuracy: 0.5897 - val_top3_acc: 1.0000\n",
      "Epoch 50/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9168 - accuracy: 0.5814 - top3_acc: 1.0000 - val_loss: 0.9221 - val_accuracy: 0.5949 - val_top3_acc: 1.0000\n",
      "Epoch 51/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9238 - accuracy: 0.5711 - top3_acc: 1.0000 - val_loss: 0.9421 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 52/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9224 - accuracy: 0.5696 - top3_acc: 1.0000 - val_loss: 0.9128 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n",
      "Epoch 53/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9142 - accuracy: 0.5799 - top3_acc: 1.0000 - val_loss: 0.9145 - val_accuracy: 0.5949 - val_top3_acc: 1.0000\n",
      "Epoch 54/400\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.9120 - accuracy: 0.5784 - top3_acc: 1.0000 - val_loss: 0.9163 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 55/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9122 - accuracy: 0.5850 - top3_acc: 1.0000 - val_loss: 0.9080 - val_accuracy: 0.5949 - val_top3_acc: 1.0000\n",
      "Epoch 56/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9082 - accuracy: 0.5850 - top3_acc: 1.0000 - val_loss: 0.9271 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 57/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9096 - accuracy: 0.5784 - top3_acc: 1.0000 - val_loss: 0.9058 - val_accuracy: 0.5949 - val_top3_acc: 1.0000\n",
      "Epoch 58/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9097 - accuracy: 0.5799 - top3_acc: 1.0000 - val_loss: 0.9225 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 59/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9000 - accuracy: 0.5865 - top3_acc: 1.0000 - val_loss: 0.9041 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n",
      "Epoch 60/400\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.9053 - accuracy: 0.5821 - top3_acc: 1.0000 - val_loss: 0.9099 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 61/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.8941 - accuracy: 0.5916 - top3_acc: 1.0000 - val_loss: 0.9049 - val_accuracy: 0.5983 - val_top3_acc: 1.0000\n",
      "Epoch 62/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8974 - accuracy: 0.5806 - top3_acc: 1.0000 - val_loss: 0.9097 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n",
      "Epoch 63/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8926 - accuracy: 0.5836 - top3_acc: 1.0000 - val_loss: 0.9074 - val_accuracy: 0.5897 - val_top3_acc: 1.0000\n",
      "Epoch 64/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.8951 - accuracy: 0.5792 - top3_acc: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.5949 - val_top3_acc: 1.0000\n",
      "Epoch 65/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.8995 - accuracy: 0.5887 - top3_acc: 1.0000 - val_loss: 0.9067 - val_accuracy: 0.5983 - val_top3_acc: 1.0000\n",
      "Epoch 66/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.8895 - accuracy: 0.5916 - top3_acc: 1.0000 - val_loss: 0.9069 - val_accuracy: 0.6051 - val_top3_acc: 1.0000\n",
      "Epoch 67/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.9050 - accuracy: 0.5828 - top3_acc: 1.0000 - val_loss: 0.9046 - val_accuracy: 0.5949 - val_top3_acc: 1.0000\n",
      "Epoch 68/400\n",
      "1364/1364 [==============================] - 3s 2ms/step - loss: 0.8991 - accuracy: 0.5762 - top3_acc: 1.0000 - val_loss: 0.9248 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 69/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.8965 - accuracy: 0.5887 - top3_acc: 1.0000 - val_loss: 0.9015 - val_accuracy: 0.6085 - val_top3_acc: 1.0000\n",
      "Epoch 70/400\n",
      "1364/1364 [==============================] - 2s 2ms/step - loss: 0.9002 - accuracy: 0.5894 - top3_acc: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 71/400\n",
      "1364/1364 [==============================] - 1s 952us/step - loss: 0.8946 - accuracy: 0.5902 - top3_acc: 1.0000 - val_loss: 0.9078 - val_accuracy: 0.5983 - val_top3_acc: 1.0000\n",
      "Epoch 72/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.8910 - accuracy: 0.5843 - top3_acc: 1.0000 - val_loss: 0.8958 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 73/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.8960 - accuracy: 0.5916 - top3_acc: 1.0000 - val_loss: 0.9122 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 74/400\n",
      "1364/1364 [==============================] - 1s 800us/step - loss: 0.8869 - accuracy: 0.5902 - top3_acc: 1.0000 - val_loss: 0.8996 - val_accuracy: 0.6034 - val_top3_acc: 1.0000\n",
      "Epoch 75/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8854 - accuracy: 0.5909 - top3_acc: 1.0000 - val_loss: 0.9080 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 76/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.8833 - accuracy: 0.5924 - top3_acc: 1.0000 - val_loss: 0.9048 - val_accuracy: 0.6051 - val_top3_acc: 1.0000\n",
      "Epoch 77/400\n",
      "1364/1364 [==============================] - 1s 767us/step - loss: 0.8824 - accuracy: 0.5894 - top3_acc: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.5983 - val_top3_acc: 1.0000\n",
      "Epoch 78/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8862 - accuracy: 0.5946 - top3_acc: 1.0000 - val_loss: 0.9043 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 79/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8784 - accuracy: 0.5990 - top3_acc: 1.0000 - val_loss: 0.9039 - val_accuracy: 0.6000 - val_top3_acc: 1.0000\n",
      "Epoch 80/400\n",
      "1364/1364 [==============================] - 1s 766us/step - loss: 0.8790 - accuracy: 0.5880 - top3_acc: 1.0000 - val_loss: 0.8979 - val_accuracy: 0.6034 - val_top3_acc: 1.0000\n",
      "Epoch 81/400\n",
      "1364/1364 [==============================] - 1s 778us/step - loss: 0.8779 - accuracy: 0.5909 - top3_acc: 1.0000 - val_loss: 0.9049 - val_accuracy: 0.6068 - val_top3_acc: 1.0000\n",
      "Epoch 82/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8712 - accuracy: 0.5968 - top3_acc: 1.0000 - val_loss: 0.9005 - val_accuracy: 0.5983 - val_top3_acc: 1.0000\n",
      "Epoch 83/400\n",
      "1364/1364 [==============================] - 1s 995us/step - loss: 0.8781 - accuracy: 0.5909 - top3_acc: 1.0000 - val_loss: 0.9068 - val_accuracy: 0.6017 - val_top3_acc: 1.0000\n",
      "Epoch 84/400\n",
      "1364/1364 [==============================] - 1s 744us/step - loss: 0.8735 - accuracy: 0.6004 - top3_acc: 1.0000 - val_loss: 0.8986 - val_accuracy: 0.6120 - val_top3_acc: 1.0000\n",
      "Epoch 85/400\n",
      "1364/1364 [==============================] - 1s 686us/step - loss: 0.8669 - accuracy: 0.5931 - top3_acc: 1.0000 - val_loss: 0.8952 - val_accuracy: 0.6068 - val_top3_acc: 1.0000\n",
      "Epoch 86/400\n",
      "1364/1364 [==============================] - 1s 777us/step - loss: 0.8613 - accuracy: 0.6041 - top3_acc: 1.0000 - val_loss: 0.9046 - val_accuracy: 0.6068 - val_top3_acc: 1.0000\n",
      "Epoch 87/400\n",
      "1364/1364 [==============================] - 1s 787us/step - loss: 0.8704 - accuracy: 0.5938 - top3_acc: 1.0000 - val_loss: 0.8958 - val_accuracy: 0.6188 - val_top3_acc: 1.0000\n",
      "Epoch 88/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8649 - accuracy: 0.5990 - top3_acc: 1.0000 - val_loss: 0.8992 - val_accuracy: 0.6137 - val_top3_acc: 1.0000\n",
      "Epoch 89/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8673 - accuracy: 0.5968 - top3_acc: 1.0000 - val_loss: 0.8959 - val_accuracy: 0.6051 - val_top3_acc: 1.0000\n",
      "Epoch 90/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.8630 - accuracy: 0.5997 - top3_acc: 1.0000 - val_loss: 0.9051 - val_accuracy: 0.6068 - val_top3_acc: 1.0000\n",
      "Epoch 91/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.8668 - accuracy: 0.5982 - top3_acc: 1.0000 - val_loss: 0.8967 - val_accuracy: 0.6120 - val_top3_acc: 1.0000\n",
      "Epoch 92/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.8715 - accuracy: 0.5902 - top3_acc: 1.0000 - val_loss: 0.8939 - val_accuracy: 0.6120 - val_top3_acc: 1.0000\n",
      "Epoch 93/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8722 - accuracy: 0.5990 - top3_acc: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.6085 - val_top3_acc: 1.0000\n",
      "Epoch 94/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8545 - accuracy: 0.6056 - top3_acc: 1.0000 - val_loss: 0.8961 - val_accuracy: 0.6154 - val_top3_acc: 1.0000\n",
      "Epoch 95/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.8635 - accuracy: 0.5990 - top3_acc: 1.0000 - val_loss: 0.9179 - val_accuracy: 0.5897 - val_top3_acc: 1.0000\n",
      "Epoch 96/400\n",
      "1364/1364 [==============================] - 1s 902us/step - loss: 0.8673 - accuracy: 0.5916 - top3_acc: 1.0000 - val_loss: 0.9038 - val_accuracy: 0.6051 - val_top3_acc: 1.0000\n",
      "Epoch 97/400\n",
      "1364/1364 [==============================] - 1s 954us/step - loss: 0.8647 - accuracy: 0.5982 - top3_acc: 1.0000 - val_loss: 0.8957 - val_accuracy: 0.6154 - val_top3_acc: 1.0000\n",
      "Epoch 98/400\n",
      "1364/1364 [==============================] - 1s 880us/step - loss: 0.8598 - accuracy: 0.5960 - top3_acc: 1.0000 - val_loss: 0.9019 - val_accuracy: 0.6051 - val_top3_acc: 1.0000\n",
      "Epoch 99/400\n",
      "1364/1364 [==============================] - 1s 895us/step - loss: 0.8470 - accuracy: 0.6166 - top3_acc: 1.0000 - val_loss: 0.8908 - val_accuracy: 0.6137 - val_top3_acc: 1.0000\n",
      "Epoch 100/400\n",
      "1364/1364 [==============================] - 1s 837us/step - loss: 0.8426 - accuracy: 0.6085 - top3_acc: 1.0000 - val_loss: 0.8942 - val_accuracy: 0.6103 - val_top3_acc: 1.0000\n",
      "Epoch 101/400\n",
      "1364/1364 [==============================] - 1s 945us/step - loss: 0.8506 - accuracy: 0.5997 - top3_acc: 1.0000 - val_loss: 0.9038 - val_accuracy: 0.6120 - val_top3_acc: 1.0000\n",
      "Epoch 102/400\n",
      "1364/1364 [==============================] - 1s 909us/step - loss: 0.8408 - accuracy: 0.6151 - top3_acc: 1.0000 - val_loss: 0.8962 - val_accuracy: 0.6137 - val_top3_acc: 1.0000\n",
      "Epoch 103/400\n",
      "1364/1364 [==============================] - 1s 935us/step - loss: 0.8468 - accuracy: 0.5982 - top3_acc: 1.0000 - val_loss: 0.8982 - val_accuracy: 0.6103 - val_top3_acc: 1.0000\n",
      "Epoch 104/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8461 - accuracy: 0.6166 - top3_acc: 1.0000 - val_loss: 0.8927 - val_accuracy: 0.6103 - val_top3_acc: 1.0000\n",
      "Epoch 105/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8418 - accuracy: 0.6041 - top3_acc: 1.0000 - val_loss: 0.8983 - val_accuracy: 0.6188 - val_top3_acc: 1.0000\n",
      "Epoch 106/400\n",
      "1364/1364 [==============================] - 1s 861us/step - loss: 0.8418 - accuracy: 0.6085 - top3_acc: 1.0000 - val_loss: 0.9039 - val_accuracy: 0.6085 - val_top3_acc: 1.0000\n",
      "Epoch 107/400\n",
      "1364/1364 [==============================] - 1s 708us/step - loss: 0.8437 - accuracy: 0.6129 - top3_acc: 1.0000 - val_loss: 0.9037 - val_accuracy: 0.6085 - val_top3_acc: 1.0000\n",
      "Epoch 108/400\n",
      "1364/1364 [==============================] - 1s 561us/step - loss: 0.8377 - accuracy: 0.6217 - top3_acc: 1.0000 - val_loss: 0.9040 - val_accuracy: 0.6068 - val_top3_acc: 1.0000\n",
      "Epoch 109/400\n",
      "1364/1364 [==============================] - 1s 543us/step - loss: 0.8458 - accuracy: 0.6122 - top3_acc: 1.0000 - val_loss: 0.8997 - val_accuracy: 0.6154 - val_top3_acc: 1.0000\n",
      "Epoch 110/400\n",
      "1364/1364 [==============================] - 1s 937us/step - loss: 0.8447 - accuracy: 0.6034 - top3_acc: 1.0000 - val_loss: 0.9049 - val_accuracy: 0.6103 - val_top3_acc: 1.0000\n",
      "Epoch 111/400\n",
      "1364/1364 [==============================] - 1s 601us/step - loss: 0.8301 - accuracy: 0.6276 - top3_acc: 1.0000 - val_loss: 0.8952 - val_accuracy: 0.6051 - val_top3_acc: 1.0000\n",
      "Epoch 112/400\n",
      "1364/1364 [==============================] - 1s 599us/step - loss: 0.8266 - accuracy: 0.6114 - top3_acc: 1.0000 - val_loss: 0.9017 - val_accuracy: 0.6188 - val_top3_acc: 1.0000\n",
      "Epoch 113/400\n",
      "1364/1364 [==============================] - 1s 591us/step - loss: 0.8245 - accuracy: 0.6261 - top3_acc: 1.0000 - val_loss: 0.9006 - val_accuracy: 0.6068 - val_top3_acc: 1.0000\n",
      "Epoch 114/400\n",
      "1364/1364 [==============================] - 1s 584us/step - loss: 0.8293 - accuracy: 0.6202 - top3_acc: 1.0000 - val_loss: 0.8995 - val_accuracy: 0.6103 - val_top3_acc: 1.0000\n",
      "Epoch 115/400\n",
      "1364/1364 [==============================] - 1s 571us/step - loss: 0.8297 - accuracy: 0.6136 - top3_acc: 1.0000 - val_loss: 0.8994 - val_accuracy: 0.6137 - val_top3_acc: 1.0000\n",
      "Epoch 116/400\n",
      "1364/1364 [==============================] - 1s 542us/step - loss: 0.8150 - accuracy: 0.6320 - top3_acc: 1.0000 - val_loss: 0.9055 - val_accuracy: 0.6034 - val_top3_acc: 1.0000\n",
      "Epoch 117/400\n",
      "1364/1364 [==============================] - 1s 552us/step - loss: 0.8292 - accuracy: 0.6158 - top3_acc: 1.0000 - val_loss: 0.8988 - val_accuracy: 0.6085 - val_top3_acc: 1.0000\n",
      "Epoch 118/400\n",
      "1364/1364 [==============================] - 1s 554us/step - loss: 0.8258 - accuracy: 0.6232 - top3_acc: 1.0000 - val_loss: 0.9006 - val_accuracy: 0.6051 - val_top3_acc: 1.0000\n",
      "Epoch 119/400\n",
      "1364/1364 [==============================] - 1s 691us/step - loss: 0.8228 - accuracy: 0.6312 - top3_acc: 1.0000 - val_loss: 0.9075 - val_accuracy: 0.6085 - val_top3_acc: 1.0000\n",
      "Epoch 120/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.8219 - accuracy: 0.6261 - top3_acc: 1.0000 - val_loss: 0.8976 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 121/400\n",
      "1364/1364 [==============================] - 1s 622us/step - loss: 0.8269 - accuracy: 0.6210 - top3_acc: 1.0000 - val_loss: 0.8921 - val_accuracy: 0.6239 - val_top3_acc: 1.0000\n",
      "Epoch 122/400\n",
      "1364/1364 [==============================] - 1s 578us/step - loss: 0.8253 - accuracy: 0.6268 - top3_acc: 1.0000 - val_loss: 0.9124 - val_accuracy: 0.6017 - val_top3_acc: 1.0000\n",
      "Epoch 123/400\n",
      "1364/1364 [==============================] - 1s 577us/step - loss: 0.8163 - accuracy: 0.6312 - top3_acc: 1.0000 - val_loss: 0.8925 - val_accuracy: 0.6171 - val_top3_acc: 1.0000\n",
      "Epoch 124/400\n",
      "1364/1364 [==============================] - 1s 602us/step - loss: 0.8185 - accuracy: 0.6195 - top3_acc: 1.0000 - val_loss: 0.8936 - val_accuracy: 0.6034 - val_top3_acc: 1.0000\n",
      "Epoch 125/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.8228 - accuracy: 0.6129 - top3_acc: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.6000 - val_top3_acc: 1.0000\n",
      "Epoch 126/400\n",
      "1364/1364 [==============================] - 1s 820us/step - loss: 0.8303 - accuracy: 0.6114 - top3_acc: 1.0000 - val_loss: 0.8987 - val_accuracy: 0.6120 - val_top3_acc: 1.0000\n",
      "Epoch 127/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8358 - accuracy: 0.6246 - top3_acc: 1.0000 - val_loss: 0.9200 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 128/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.8094 - accuracy: 0.6327 - top3_acc: 1.0000 - val_loss: 0.8920 - val_accuracy: 0.5949 - val_top3_acc: 1.0000\n",
      "Epoch 129/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1364/1364 [==============================] - 1s 763us/step - loss: 0.8071 - accuracy: 0.6254 - top3_acc: 1.0000 - val_loss: 0.9033 - val_accuracy: 0.6068 - val_top3_acc: 1.0000\n",
      "Epoch 130/400\n",
      "1364/1364 [==============================] - 1s 808us/step - loss: 0.8036 - accuracy: 0.6305 - top3_acc: 1.0000 - val_loss: 0.9026 - val_accuracy: 0.6000 - val_top3_acc: 1.0000\n",
      "Epoch 131/400\n",
      "1364/1364 [==============================] - 1s 657us/step - loss: 0.8083 - accuracy: 0.6283 - top3_acc: 1.0000 - val_loss: 0.8953 - val_accuracy: 0.6154 - val_top3_acc: 1.0000\n",
      "Epoch 132/400\n",
      "1364/1364 [==============================] - 1s 552us/step - loss: 0.7971 - accuracy: 0.6298 - top3_acc: 1.0000 - val_loss: 0.9099 - val_accuracy: 0.6000 - val_top3_acc: 1.0000\n",
      "Epoch 133/400\n",
      "1364/1364 [==============================] - 1s 557us/step - loss: 0.7976 - accuracy: 0.6327 - top3_acc: 1.0000 - val_loss: 0.8947 - val_accuracy: 0.6103 - val_top3_acc: 1.0000\n",
      "Epoch 134/400\n",
      "1364/1364 [==============================] - 1s 574us/step - loss: 0.7974 - accuracy: 0.6349 - top3_acc: 1.0000 - val_loss: 0.8993 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n",
      "Epoch 135/400\n",
      "1364/1364 [==============================] - 1s 572us/step - loss: 0.8002 - accuracy: 0.6400 - top3_acc: 1.0000 - val_loss: 0.9106 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 136/400\n",
      "1364/1364 [==============================] - 1s 557us/step - loss: 0.7989 - accuracy: 0.6290 - top3_acc: 1.0000 - val_loss: 0.8984 - val_accuracy: 0.6188 - val_top3_acc: 1.0000\n",
      "Epoch 137/400\n",
      "1364/1364 [==============================] - 1s 990us/step - loss: 0.7931 - accuracy: 0.6452 - top3_acc: 1.0000 - val_loss: 0.8986 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 138/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.7966 - accuracy: 0.6400 - top3_acc: 1.0000 - val_loss: 0.9016 - val_accuracy: 0.6034 - val_top3_acc: 1.0000\n",
      "Epoch 139/400\n",
      "1364/1364 [==============================] - 1s 798us/step - loss: 0.7946 - accuracy: 0.6452 - top3_acc: 1.0000 - val_loss: 0.9047 - val_accuracy: 0.6000 - val_top3_acc: 1.0000\n",
      "Epoch 140/400\n",
      "1364/1364 [==============================] - 1s 638us/step - loss: 0.7856 - accuracy: 0.6474 - top3_acc: 1.0000 - val_loss: 0.8994 - val_accuracy: 0.6068 - val_top3_acc: 1.0000\n",
      "Epoch 141/400\n",
      "1364/1364 [==============================] - 1s 782us/step - loss: 0.7846 - accuracy: 0.6466 - top3_acc: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n",
      "Epoch 142/400\n",
      "1364/1364 [==============================] - 1s 559us/step - loss: 0.7893 - accuracy: 0.6371 - top3_acc: 1.0000 - val_loss: 0.8960 - val_accuracy: 0.6137 - val_top3_acc: 1.0000\n",
      "Epoch 143/400\n",
      "1364/1364 [==============================] - 1s 582us/step - loss: 0.7884 - accuracy: 0.6488 - top3_acc: 1.0000 - val_loss: 0.9136 - val_accuracy: 0.5983 - val_top3_acc: 1.0000\n",
      "Epoch 144/400\n",
      "1364/1364 [==============================] - 1s 572us/step - loss: 0.7714 - accuracy: 0.6532 - top3_acc: 1.0000 - val_loss: 0.8985 - val_accuracy: 0.6137 - val_top3_acc: 1.0000\n",
      "Epoch 145/400\n",
      "1364/1364 [==============================] - 1s 587us/step - loss: 0.7796 - accuracy: 0.6554 - top3_acc: 1.0000 - val_loss: 0.9123 - val_accuracy: 0.6017 - val_top3_acc: 1.0000\n",
      "Epoch 146/400\n",
      "1364/1364 [==============================] - 1s 580us/step - loss: 0.7802 - accuracy: 0.6437 - top3_acc: 1.0000 - val_loss: 0.8999 - val_accuracy: 0.6051 - val_top3_acc: 1.0000\n",
      "Epoch 147/400\n",
      "1364/1364 [==============================] - 1s 563us/step - loss: 0.7761 - accuracy: 0.6532 - top3_acc: 1.0000 - val_loss: 0.8976 - val_accuracy: 0.6154 - val_top3_acc: 1.0000\n",
      "Epoch 148/400\n",
      "1364/1364 [==============================] - 1s 573us/step - loss: 0.7710 - accuracy: 0.6525 - top3_acc: 1.0000 - val_loss: 0.9082 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 149/400\n",
      "1364/1364 [==============================] - 1s 556us/step - loss: 0.7754 - accuracy: 0.6452 - top3_acc: 1.0000 - val_loss: 0.9028 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 150/400\n",
      "1364/1364 [==============================] - 1s 556us/step - loss: 0.7735 - accuracy: 0.6562 - top3_acc: 1.0000 - val_loss: 0.9016 - val_accuracy: 0.6034 - val_top3_acc: 1.0000\n",
      "Epoch 151/400\n",
      "1364/1364 [==============================] - 1s 711us/step - loss: 0.7777 - accuracy: 0.6496 - top3_acc: 1.0000 - val_loss: 0.9064 - val_accuracy: 0.5983 - val_top3_acc: 1.0000\n",
      "Epoch 152/400\n",
      "1364/1364 [==============================] - 1s 574us/step - loss: 0.7786 - accuracy: 0.6503 - top3_acc: 1.0000 - val_loss: 0.8980 - val_accuracy: 0.6137 - val_top3_acc: 1.0000\n",
      "Epoch 153/400\n",
      "1364/1364 [==============================] - 1s 706us/step - loss: 0.7689 - accuracy: 0.6503 - top3_acc: 1.0000 - val_loss: 0.9212 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n",
      "Epoch 154/400\n",
      "1364/1364 [==============================] - 1s 872us/step - loss: 0.7756 - accuracy: 0.6562 - top3_acc: 1.0000 - val_loss: 0.8960 - val_accuracy: 0.6188 - val_top3_acc: 1.0000\n",
      "Epoch 155/400\n",
      "1364/1364 [==============================] - 1s 673us/step - loss: 0.7804 - accuracy: 0.6488 - top3_acc: 1.0000 - val_loss: 0.9026 - val_accuracy: 0.6017 - val_top3_acc: 1.0000\n",
      "Epoch 156/400\n",
      "1364/1364 [==============================] - 1s 624us/step - loss: 0.7704 - accuracy: 0.6591 - top3_acc: 1.0000 - val_loss: 0.9131 - val_accuracy: 0.6034 - val_top3_acc: 1.0000\n",
      "Epoch 157/400\n",
      "1364/1364 [==============================] - 1s 706us/step - loss: 0.7631 - accuracy: 0.6606 - top3_acc: 1.0000 - val_loss: 0.9028 - val_accuracy: 0.6000 - val_top3_acc: 1.0000\n",
      "Epoch 158/400\n",
      "1364/1364 [==============================] - 1s 578us/step - loss: 0.7588 - accuracy: 0.6606 - top3_acc: 1.0000 - val_loss: 0.9007 - val_accuracy: 0.6034 - val_top3_acc: 1.0000\n",
      "Epoch 159/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.7611 - accuracy: 0.6672 - top3_acc: 1.0000 - val_loss: 0.9134 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n",
      "Epoch 160/400\n",
      "1364/1364 [==============================] - 1s 940us/step - loss: 0.7648 - accuracy: 0.6576 - top3_acc: 1.0000 - val_loss: 0.8982 - val_accuracy: 0.6154 - val_top3_acc: 1.0000\n",
      "Epoch 161/400\n",
      "1364/1364 [==============================] - 1s 821us/step - loss: 0.7704 - accuracy: 0.6503 - top3_acc: 1.0000 - val_loss: 0.9054 - val_accuracy: 0.5983 - val_top3_acc: 1.0000\n",
      "Epoch 162/400\n",
      "1364/1364 [==============================] - 1s 822us/step - loss: 0.7588 - accuracy: 0.6672 - top3_acc: 1.0000 - val_loss: 0.9007 - val_accuracy: 0.6017 - val_top3_acc: 1.0000\n",
      "Epoch 163/400\n",
      "1364/1364 [==============================] - 1s 863us/step - loss: 0.7455 - accuracy: 0.6745 - top3_acc: 1.0000 - val_loss: 0.9080 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 164/400\n",
      "1364/1364 [==============================] - 1s 786us/step - loss: 0.7510 - accuracy: 0.6657 - top3_acc: 1.0000 - val_loss: 0.9088 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 165/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.7820 - accuracy: 0.6576 - top3_acc: 1.0000 - val_loss: 0.9100 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 166/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.7594 - accuracy: 0.6657 - top3_acc: 1.0000 - val_loss: 0.8993 - val_accuracy: 0.6034 - val_top3_acc: 1.0000\n",
      "Epoch 167/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.7504 - accuracy: 0.6532 - top3_acc: 1.0000 - val_loss: 0.9036 - val_accuracy: 0.6051 - val_top3_acc: 1.0000\n",
      "Epoch 168/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.7495 - accuracy: 0.6818 - top3_acc: 1.0000 - val_loss: 0.9143 - val_accuracy: 0.5983 - val_top3_acc: 1.0000\n",
      "Epoch 169/400\n",
      "1364/1364 [==============================] - 1s 633us/step - loss: 0.7463 - accuracy: 0.6576 - top3_acc: 1.0000 - val_loss: 0.9022 - val_accuracy: 0.6034 - val_top3_acc: 1.0000\n",
      "Epoch 170/400\n",
      "1364/1364 [==============================] - 1s 606us/step - loss: 0.7419 - accuracy: 0.6664 - top3_acc: 1.0000 - val_loss: 0.9102 - val_accuracy: 0.5897 - val_top3_acc: 1.0000\n",
      "Epoch 171/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.7390 - accuracy: 0.6738 - top3_acc: 1.0000 - val_loss: 0.9068 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n",
      "Epoch 172/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1364/1364 [==============================] - 1s 904us/step - loss: 0.7426 - accuracy: 0.6745 - top3_acc: 1.0000 - val_loss: 0.9170 - val_accuracy: 0.5778 - val_top3_acc: 1.0000\n",
      "Epoch 173/400\n",
      "1364/1364 [==============================] - 1s 826us/step - loss: 0.7543 - accuracy: 0.6701 - top3_acc: 1.0000 - val_loss: 0.9152 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n",
      "Epoch 174/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.7320 - accuracy: 0.6782 - top3_acc: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.5812 - val_top3_acc: 1.0000\n",
      "Epoch 175/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.7630 - accuracy: 0.6672 - top3_acc: 1.0000 - val_loss: 0.9117 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 176/400\n",
      "1364/1364 [==============================] - 1s 770us/step - loss: 0.7423 - accuracy: 0.6679 - top3_acc: 1.0000 - val_loss: 0.9169 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 177/400\n",
      "1364/1364 [==============================] - 1s 641us/step - loss: 0.7391 - accuracy: 0.6723 - top3_acc: 1.0000 - val_loss: 0.9040 - val_accuracy: 0.5949 - val_top3_acc: 1.0000\n",
      "Epoch 178/400\n",
      "1364/1364 [==============================] - 1s 834us/step - loss: 0.7403 - accuracy: 0.6679 - top3_acc: 1.0000 - val_loss: 0.9049 - val_accuracy: 0.5983 - val_top3_acc: 1.0000\n",
      "Epoch 179/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.7441 - accuracy: 0.6804 - top3_acc: 1.0000 - val_loss: 0.9221 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n",
      "Epoch 180/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.7281 - accuracy: 0.6650 - top3_acc: 1.0000 - val_loss: 0.9113 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 181/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.7335 - accuracy: 0.6694 - top3_acc: 1.0000 - val_loss: 0.9132 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 182/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.7302 - accuracy: 0.6760 - top3_acc: 1.0000 - val_loss: 0.9045 - val_accuracy: 0.5983 - val_top3_acc: 1.0000\n",
      "Epoch 183/400\n",
      "1364/1364 [==============================] - 1s 800us/step - loss: 0.7257 - accuracy: 0.6738 - top3_acc: 1.0000 - val_loss: 0.9142 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 184/400\n",
      "1364/1364 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.6727 - top3_acc: 1.000 - 2s 1ms/step - loss: 0.7300 - accuracy: 0.6701 - top3_acc: 1.0000 - val_loss: 0.9073 - val_accuracy: 0.6034 - val_top3_acc: 1.0000\n",
      "Epoch 185/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.7376 - accuracy: 0.6855 - top3_acc: 1.0000 - val_loss: 0.9451 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 186/400\n",
      "1364/1364 [==============================] - 1s 795us/step - loss: 0.7475 - accuracy: 0.6540 - top3_acc: 1.0000 - val_loss: 0.9213 - val_accuracy: 0.5744 - val_top3_acc: 1.0000\n",
      "Epoch 187/400\n",
      "1364/1364 [==============================] - 1s 870us/step - loss: 0.7525 - accuracy: 0.6620 - top3_acc: 1.0000 - val_loss: 0.9210 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 188/400\n",
      "1364/1364 [==============================] - 1s 899us/step - loss: 0.7274 - accuracy: 0.6782 - top3_acc: 1.0000 - val_loss: 0.9117 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 189/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.7240 - accuracy: 0.6796 - top3_acc: 1.0000 - val_loss: 0.9034 - val_accuracy: 0.6051 - val_top3_acc: 1.0000\n",
      "Epoch 190/400\n",
      "1364/1364 [==============================] - 1s 775us/step - loss: 0.7200 - accuracy: 0.6738 - top3_acc: 1.0000 - val_loss: 0.9316 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 191/400\n",
      "1364/1364 [==============================] - 1s 616us/step - loss: 0.7187 - accuracy: 0.6789 - top3_acc: 1.0000 - val_loss: 0.9074 - val_accuracy: 0.5949 - val_top3_acc: 1.0000\n",
      "Epoch 192/400\n",
      "1364/1364 [==============================] - 1s 617us/step - loss: 0.7164 - accuracy: 0.6774 - top3_acc: 1.0000 - val_loss: 0.9092 - val_accuracy: 0.6017 - val_top3_acc: 1.0000\n",
      "Epoch 193/400\n",
      "1364/1364 [==============================] - 1s 659us/step - loss: 0.7309 - accuracy: 0.6738 - top3_acc: 1.0000 - val_loss: 0.9222 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n",
      "Epoch 194/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.7355 - accuracy: 0.6840 - top3_acc: 1.0000 - val_loss: 0.9118 - val_accuracy: 0.5966 - val_top3_acc: 1.0000\n",
      "Epoch 195/400\n",
      "1364/1364 [==============================] - 1s 681us/step - loss: 0.7226 - accuracy: 0.6899 - top3_acc: 1.0000 - val_loss: 0.9070 - val_accuracy: 0.5949 - val_top3_acc: 1.0000\n",
      "Epoch 196/400\n",
      "1364/1364 [==============================] - 1s 583us/step - loss: 0.7135 - accuracy: 0.6826 - top3_acc: 1.0000 - val_loss: 0.9123 - val_accuracy: 0.5897 - val_top3_acc: 1.0000\n",
      "Epoch 197/400\n",
      "1364/1364 [==============================] - 1s 593us/step - loss: 0.7105 - accuracy: 0.6979 - top3_acc: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.5846 - val_top3_acc: 1.0000\n",
      "Epoch 198/400\n",
      "1364/1364 [==============================] - 1s 641us/step - loss: 0.7296 - accuracy: 0.6620 - top3_acc: 1.0000 - val_loss: 0.9073 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 199/400\n",
      "1364/1364 [==============================] - 1s 615us/step - loss: 0.7240 - accuracy: 0.6884 - top3_acc: 1.0000 - val_loss: 0.9287 - val_accuracy: 0.5692 - val_top3_acc: 1.0000\n",
      "Epoch 200/400\n",
      "1364/1364 [==============================] - 1s 578us/step - loss: 0.7162 - accuracy: 0.6774 - top3_acc: 1.0000 - val_loss: 0.9100 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 201/400\n",
      "1364/1364 [==============================] - 1s 597us/step - loss: 0.7101 - accuracy: 0.7001 - top3_acc: 1.0000 - val_loss: 0.9519 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n",
      "Epoch 202/400\n",
      "1364/1364 [==============================] - 1s 735us/step - loss: 0.7083 - accuracy: 0.6877 - top3_acc: 1.0000 - val_loss: 0.9095 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 203/400\n",
      "1364/1364 [==============================] - 1s 585us/step - loss: 0.7080 - accuracy: 0.6884 - top3_acc: 1.0000 - val_loss: 0.9190 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 204/400\n",
      "1364/1364 [==============================] - 1s 696us/step - loss: 0.6923 - accuracy: 0.6979 - top3_acc: 1.0000 - val_loss: 0.9103 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n",
      "Epoch 205/400\n",
      "1364/1364 [==============================] - 1s 680us/step - loss: 0.7027 - accuracy: 0.6826 - top3_acc: 1.0000 - val_loss: 0.9168 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 206/400\n",
      "1364/1364 [==============================] - 1s 804us/step - loss: 0.7016 - accuracy: 0.6935 - top3_acc: 1.0000 - val_loss: 0.9227 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 207/400\n",
      "1364/1364 [==============================] - 1s 801us/step - loss: 0.6897 - accuracy: 0.6943 - top3_acc: 1.0000 - val_loss: 0.9205 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 208/400\n",
      "1364/1364 [==============================] - 1s 772us/step - loss: 0.7005 - accuracy: 0.6921 - top3_acc: 1.0000 - val_loss: 0.9211 - val_accuracy: 0.5726 - val_top3_acc: 1.0000\n",
      "Epoch 209/400\n",
      "1364/1364 [==============================] - 1s 673us/step - loss: 0.7026 - accuracy: 0.7001 - top3_acc: 1.0000 - val_loss: 0.9272 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 210/400\n",
      "1364/1364 [==============================] - 1s 852us/step - loss: 0.6865 - accuracy: 0.7031 - top3_acc: 1.0000 - val_loss: 0.9160 - val_accuracy: 0.5829 - val_top3_acc: 1.0000\n",
      "Epoch 211/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.6901 - accuracy: 0.7104 - top3_acc: 1.0000 - val_loss: 0.9264 - val_accuracy: 0.5897 - val_top3_acc: 1.0000\n",
      "Epoch 212/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.6941 - accuracy: 0.7001 - top3_acc: 1.0000 - val_loss: 0.9238 - val_accuracy: 0.5726 - val_top3_acc: 1.0000\n",
      "Epoch 213/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.6914 - accuracy: 0.6921 - top3_acc: 1.0000 - val_loss: 0.9171 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 214/400\n",
      "1364/1364 [==============================] - 1s 837us/step - loss: 0.6812 - accuracy: 0.7031 - top3_acc: 1.0000 - val_loss: 0.9217 - val_accuracy: 0.5932 - val_top3_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/400\n",
      "1364/1364 [==============================] - 1s 821us/step - loss: 0.6760 - accuracy: 0.7053 - top3_acc: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.5897 - val_top3_acc: 1.0000\n",
      "Epoch 216/400\n",
      "1364/1364 [==============================] - 1s 699us/step - loss: 0.7011 - accuracy: 0.7045 - top3_acc: 1.0000 - val_loss: 0.9255 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 217/400\n",
      "1364/1364 [==============================] - 1s 598us/step - loss: 0.6940 - accuracy: 0.6877 - top3_acc: 1.0000 - val_loss: 0.9205 - val_accuracy: 0.5949 - val_top3_acc: 1.0000\n",
      "Epoch 218/400\n",
      "1364/1364 [==============================] - 1s 599us/step - loss: 0.6832 - accuracy: 0.7001 - top3_acc: 1.0000 - val_loss: 0.9193 - val_accuracy: 0.5778 - val_top3_acc: 1.0000\n",
      "Epoch 219/400\n",
      "1364/1364 [==============================] - 1s 565us/step - loss: 0.6893 - accuracy: 0.6928 - top3_acc: 1.0000 - val_loss: 0.9320 - val_accuracy: 0.5761 - val_top3_acc: 1.0000\n",
      "Epoch 220/400\n",
      "1364/1364 [==============================] - 1s 576us/step - loss: 0.6750 - accuracy: 0.6928 - top3_acc: 1.0000 - val_loss: 0.9253 - val_accuracy: 0.5744 - val_top3_acc: 1.0000\n",
      "Epoch 221/400\n",
      "1364/1364 [==============================] - 1s 592us/step - loss: 0.6844 - accuracy: 0.7053 - top3_acc: 1.0000 - val_loss: 0.9337 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 222/400\n",
      "1364/1364 [==============================] - 1s 608us/step - loss: 0.6985 - accuracy: 0.6928 - top3_acc: 1.0000 - val_loss: 0.9299 - val_accuracy: 0.5709 - val_top3_acc: 1.0000\n",
      "Epoch 223/400\n",
      "1364/1364 [==============================] - 1s 879us/step - loss: 0.6852 - accuracy: 0.6950 - top3_acc: 1.0000 - val_loss: 0.9424 - val_accuracy: 0.5846 - val_top3_acc: 1.0000\n",
      "Epoch 224/400\n",
      "1364/1364 [==============================] - 1s 773us/step - loss: 0.6814 - accuracy: 0.6972 - top3_acc: 1.0000 - val_loss: 0.9315 - val_accuracy: 0.5744 - val_top3_acc: 1.0000\n",
      "Epoch 225/400\n",
      "1364/1364 [==============================] - 1s 923us/step - loss: 0.7013 - accuracy: 0.6899 - top3_acc: 1.0000 - val_loss: 0.9371 - val_accuracy: 0.5829 - val_top3_acc: 1.0000\n",
      "Epoch 226/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.6867 - accuracy: 0.6913 - top3_acc: 1.0000 - val_loss: 0.9303 - val_accuracy: 0.5675 - val_top3_acc: 1.0000\n",
      "Epoch 227/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.6738 - accuracy: 0.7192 - top3_acc: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.5915 - val_top3_acc: 1.0000\n",
      "Epoch 228/400\n",
      "1364/1364 [==============================] - 1s 789us/step - loss: 0.6938 - accuracy: 0.7053 - top3_acc: 1.0000 - val_loss: 0.9334 - val_accuracy: 0.5761 - val_top3_acc: 1.0000\n",
      "Epoch 229/400\n",
      "1364/1364 [==============================] - 1s 952us/step - loss: 0.6761 - accuracy: 0.7082 - top3_acc: 1.0000 - val_loss: 0.9262 - val_accuracy: 0.5880 - val_top3_acc: 1.0000\n",
      "Epoch 230/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.6649 - accuracy: 0.7251 - top3_acc: 1.0000 - val_loss: 0.9367 - val_accuracy: 0.5658 - val_top3_acc: 1.0000\n",
      "Epoch 231/400\n",
      "1364/1364 [==============================] - 1s 824us/step - loss: 0.6649 - accuracy: 0.7155 - top3_acc: 1.0000 - val_loss: 0.9290 - val_accuracy: 0.5846 - val_top3_acc: 1.0000\n",
      "Epoch 232/400\n",
      "1364/1364 [==============================] - 1s 752us/step - loss: 0.6708 - accuracy: 0.6943 - top3_acc: 1.0000 - val_loss: 0.9333 - val_accuracy: 0.5675 - val_top3_acc: 1.0000\n",
      "Epoch 233/400\n",
      "1364/1364 [==============================] - 1s 960us/step - loss: 0.6821 - accuracy: 0.7001 - top3_acc: 1.0000 - val_loss: 0.9394 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 234/400\n",
      "1364/1364 [==============================] - 1s 901us/step - loss: 0.6550 - accuracy: 0.7023 - top3_acc: 1.0000 - val_loss: 0.9288 - val_accuracy: 0.5761 - val_top3_acc: 1.0000\n",
      "Epoch 235/400\n",
      "1364/1364 [==============================] - 1s 814us/step - loss: 0.6681 - accuracy: 0.7089 - top3_acc: 1.0000 - val_loss: 0.9600 - val_accuracy: 0.5726 - val_top3_acc: 1.0000\n",
      "Epoch 236/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.6808 - accuracy: 0.7001 - top3_acc: 1.0000 - val_loss: 0.9348 - val_accuracy: 0.5658 - val_top3_acc: 1.0000\n",
      "Epoch 237/400\n",
      "1364/1364 [==============================] - 1s 741us/step - loss: 0.6859 - accuracy: 0.6957 - top3_acc: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.5726 - val_top3_acc: 1.0000\n",
      "Epoch 238/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.6679 - accuracy: 0.7163 - top3_acc: 1.0000 - val_loss: 0.9308 - val_accuracy: 0.5744 - val_top3_acc: 1.0000\n",
      "Epoch 239/400\n",
      "1364/1364 [==============================] - 1s 799us/step - loss: 0.6495 - accuracy: 0.7192 - top3_acc: 1.0000 - val_loss: 0.9400 - val_accuracy: 0.5863 - val_top3_acc: 1.0000\n",
      "Epoch 240/400\n",
      "1364/1364 [==============================] - 1s 785us/step - loss: 0.6556 - accuracy: 0.7214 - top3_acc: 1.0000 - val_loss: 0.9374 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 241/400\n",
      "1364/1364 [==============================] - 1s 723us/step - loss: 0.6546 - accuracy: 0.7141 - top3_acc: 1.0000 - val_loss: 0.9397 - val_accuracy: 0.5778 - val_top3_acc: 1.0000\n",
      "Epoch 242/400\n",
      "1364/1364 [==============================] - 1s 688us/step - loss: 0.6556 - accuracy: 0.7273 - top3_acc: 1.0000 - val_loss: 0.9356 - val_accuracy: 0.5641 - val_top3_acc: 1.0000\n",
      "Epoch 243/400\n",
      "1364/1364 [==============================] - 1s 654us/step - loss: 0.6539 - accuracy: 0.7192 - top3_acc: 1.0000 - val_loss: 0.9349 - val_accuracy: 0.5829 - val_top3_acc: 1.0000\n",
      "Epoch 244/400\n",
      "1364/1364 [==============================] - 1s 585us/step - loss: 0.6468 - accuracy: 0.7185 - top3_acc: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.5846 - val_top3_acc: 1.0000\n",
      "Epoch 245/400\n",
      "1364/1364 [==============================] - 1s 619us/step - loss: 0.6611 - accuracy: 0.7258 - top3_acc: 1.0000 - val_loss: 0.9484 - val_accuracy: 0.5487 - val_top3_acc: 1.0000\n",
      "Epoch 246/400\n",
      "1364/1364 [==============================] - 1s 917us/step - loss: 0.6448 - accuracy: 0.7265 - top3_acc: 1.0000 - val_loss: 0.9360 - val_accuracy: 0.5641 - val_top3_acc: 1.0000\n",
      "Epoch 247/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.6702 - accuracy: 0.7082 - top3_acc: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.5744 - val_top3_acc: 1.0000\n",
      "Epoch 248/400\n",
      "1364/1364 [==============================] - 1s 916us/step - loss: 0.6561 - accuracy: 0.7214 - top3_acc: 1.0000 - val_loss: 0.9450 - val_accuracy: 0.5692 - val_top3_acc: 1.0000\n",
      "Epoch 249/400\n",
      "1364/1364 [==============================] - 1s 648us/step - loss: 0.6534 - accuracy: 0.7119 - top3_acc: 1.0000 - val_loss: 0.9395 - val_accuracy: 0.5658 - val_top3_acc: 1.0000\n",
      "Epoch 250/400\n",
      "1364/1364 [==============================] - 1s 855us/step - loss: 0.6511 - accuracy: 0.7192 - top3_acc: 1.0000 - val_loss: 0.9452 - val_accuracy: 0.5744 - val_top3_acc: 1.0000\n",
      "Epoch 251/400\n",
      "1364/1364 [==============================] - 1s 792us/step - loss: 0.6411 - accuracy: 0.7185 - top3_acc: 1.0000 - val_loss: 0.9483 - val_accuracy: 0.5795 - val_top3_acc: 1.0000\n",
      "Epoch 252/400\n",
      "1364/1364 [==============================] - 1s 805us/step - loss: 0.6534 - accuracy: 0.7067 - top3_acc: 1.0000 - val_loss: 0.9401 - val_accuracy: 0.5658 - val_top3_acc: 1.0000\n",
      "Epoch 253/400\n",
      "1364/1364 [==============================] - 1s 977us/step - loss: 0.6463 - accuracy: 0.7280 - top3_acc: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 254/400\n",
      "1364/1364 [==============================] - 1s 795us/step - loss: 0.6562 - accuracy: 0.7170 - top3_acc: 1.0000 - val_loss: 0.9422 - val_accuracy: 0.5692 - val_top3_acc: 1.0000\n",
      "Epoch 255/400\n",
      "1364/1364 [==============================] - 1s 757us/step - loss: 0.6637 - accuracy: 0.7023 - top3_acc: 1.0000 - val_loss: 0.9482 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 256/400\n",
      "1364/1364 [==============================] - 1s 600us/step - loss: 0.6577 - accuracy: 0.7155 - top3_acc: 1.0000 - val_loss: 0.9505 - val_accuracy: 0.5795 - val_top3_acc: 1.0000\n",
      "Epoch 257/400\n",
      "1364/1364 [==============================] - 1s 702us/step - loss: 0.6617 - accuracy: 0.7207 - top3_acc: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.5538 - val_top3_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258/400\n",
      "1364/1364 [==============================] - 1s 574us/step - loss: 0.6555 - accuracy: 0.7148 - top3_acc: 1.0000 - val_loss: 0.9408 - val_accuracy: 0.5692 - val_top3_acc: 1.0000\n",
      "Epoch 259/400\n",
      "1364/1364 [==============================] - 1s 580us/step - loss: 0.6584 - accuracy: 0.7119 - top3_acc: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.5641 - val_top3_acc: 1.0000\n",
      "Epoch 260/400\n",
      "1364/1364 [==============================] - 1s 626us/step - loss: 0.6675 - accuracy: 0.7097 - top3_acc: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 261/400\n",
      "1364/1364 [==============================] - 1s 708us/step - loss: 0.6562 - accuracy: 0.7251 - top3_acc: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.5829 - val_top3_acc: 1.0000\n",
      "Epoch 262/400\n",
      "1364/1364 [==============================] - 1s 633us/step - loss: 0.6392 - accuracy: 0.7339 - top3_acc: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 263/400\n",
      "1364/1364 [==============================] - 1s 593us/step - loss: 0.6521 - accuracy: 0.7126 - top3_acc: 1.0000 - val_loss: 0.9407 - val_accuracy: 0.5726 - val_top3_acc: 1.0000\n",
      "Epoch 264/400\n",
      "1364/1364 [==============================] - 1s 583us/step - loss: 0.6507 - accuracy: 0.7302 - top3_acc: 1.0000 - val_loss: 0.9520 - val_accuracy: 0.5744 - val_top3_acc: 1.0000\n",
      "Epoch 265/400\n",
      "1364/1364 [==============================] - 1s 599us/step - loss: 0.6436 - accuracy: 0.7097 - top3_acc: 1.0000 - val_loss: 0.9483 - val_accuracy: 0.5675 - val_top3_acc: 1.0000\n",
      "Epoch 266/400\n",
      "1364/1364 [==============================] - 1s 772us/step - loss: 0.6383 - accuracy: 0.7207 - top3_acc: 1.0000 - val_loss: 0.9447 - val_accuracy: 0.5692 - val_top3_acc: 1.0000\n",
      "Epoch 267/400\n",
      "1364/1364 [==============================] - 1s 644us/step - loss: 0.6445 - accuracy: 0.7243 - top3_acc: 1.0000 - val_loss: 0.9608 - val_accuracy: 0.5744 - val_top3_acc: 1.0000\n",
      "Epoch 268/400\n",
      "1364/1364 [==============================] - 1s 551us/step - loss: 0.6374 - accuracy: 0.7207 - top3_acc: 1.0000 - val_loss: 0.9473 - val_accuracy: 0.5658 - val_top3_acc: 1.0000\n",
      "Epoch 269/400\n",
      "1364/1364 [==============================] - 1s 600us/step - loss: 0.6350 - accuracy: 0.7295 - top3_acc: 1.0000 - val_loss: 0.9694 - val_accuracy: 0.5709 - val_top3_acc: 1.0000\n",
      "Epoch 270/400\n",
      "1364/1364 [==============================] - 1s 650us/step - loss: 0.6487 - accuracy: 0.7170 - top3_acc: 1.0000 - val_loss: 0.9461 - val_accuracy: 0.5658 - val_top3_acc: 1.0000\n",
      "Epoch 271/400\n",
      "1364/1364 [==============================] - 1s 668us/step - loss: 0.6386 - accuracy: 0.7339 - top3_acc: 1.0000 - val_loss: 0.9628 - val_accuracy: 0.5726 - val_top3_acc: 1.0000\n",
      "Epoch 272/400\n",
      "1364/1364 [==============================] - 1s 616us/step - loss: 0.6378 - accuracy: 0.7390 - top3_acc: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.5761 - val_top3_acc: 1.0000\n",
      "Epoch 273/400\n",
      "1364/1364 [==============================] - 1s 809us/step - loss: 0.6319 - accuracy: 0.7405 - top3_acc: 1.0000 - val_loss: 0.9629 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n",
      "Epoch 274/400\n",
      "1364/1364 [==============================] - 1s 919us/step - loss: 0.6319 - accuracy: 0.7353 - top3_acc: 1.0000 - val_loss: 0.9430 - val_accuracy: 0.5778 - val_top3_acc: 1.0000\n",
      "Epoch 275/400\n",
      "1364/1364 [==============================] - 1s 952us/step - loss: 0.6320 - accuracy: 0.7251 - top3_acc: 1.0000 - val_loss: 0.9542 - val_accuracy: 0.5658 - val_top3_acc: 1.0000\n",
      "Epoch 276/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.6492 - accuracy: 0.7126 - top3_acc: 1.0000 - val_loss: 0.9495 - val_accuracy: 0.5709 - val_top3_acc: 1.0000\n",
      "Epoch 277/400\n",
      "1364/1364 [==============================] - 1s 982us/step - loss: 0.6304 - accuracy: 0.7258 - top3_acc: 1.0000 - val_loss: 0.9531 - val_accuracy: 0.5675 - val_top3_acc: 1.0000\n",
      "Epoch 278/400\n",
      "1364/1364 [==============================] - 1s 932us/step - loss: 0.6238 - accuracy: 0.7265 - top3_acc: 1.0000 - val_loss: 0.9519 - val_accuracy: 0.5692 - val_top3_acc: 1.0000\n",
      "Epoch 279/400\n",
      "1364/1364 [==============================] - 1s 641us/step - loss: 0.6181 - accuracy: 0.7441 - top3_acc: 1.0000 - val_loss: 0.9599 - val_accuracy: 0.5795 - val_top3_acc: 1.0000\n",
      "Epoch 280/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.6393 - accuracy: 0.7111 - top3_acc: 1.0000 - val_loss: 0.9530 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 281/400\n",
      "1364/1364 [==============================] - 1s 643us/step - loss: 0.6435 - accuracy: 0.7368 - top3_acc: 1.0000 - val_loss: 0.9667 - val_accuracy: 0.5726 - val_top3_acc: 1.0000\n",
      "Epoch 282/400\n",
      "1364/1364 [==============================] - 1s 844us/step - loss: 0.6256 - accuracy: 0.7287 - top3_acc: 1.0000 - val_loss: 0.9501 - val_accuracy: 0.5744 - val_top3_acc: 1.0000\n",
      "Epoch 283/400\n",
      "1364/1364 [==============================] - 1s 827us/step - loss: 0.6175 - accuracy: 0.7273 - top3_acc: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.5778 - val_top3_acc: 1.0000\n",
      "Epoch 284/400\n",
      "1364/1364 [==============================] - 1s 989us/step - loss: 0.6160 - accuracy: 0.7309 - top3_acc: 1.0000 - val_loss: 0.9508 - val_accuracy: 0.5709 - val_top3_acc: 1.0000\n",
      "Epoch 285/400\n",
      "1364/1364 [==============================] - 1s 709us/step - loss: 0.6225 - accuracy: 0.7397 - top3_acc: 1.0000 - val_loss: 0.9594 - val_accuracy: 0.5744 - val_top3_acc: 1.0000\n",
      "Epoch 286/400\n",
      "1364/1364 [==============================] - 1s 788us/step - loss: 0.6231 - accuracy: 0.7287 - top3_acc: 1.0000 - val_loss: 0.9610 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n",
      "Epoch 287/400\n",
      "1364/1364 [==============================] - 1s 679us/step - loss: 0.6150 - accuracy: 0.7243 - top3_acc: 1.0000 - val_loss: 0.9582 - val_accuracy: 0.5744 - val_top3_acc: 1.0000\n",
      "Epoch 288/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.6128 - accuracy: 0.7302 - top3_acc: 1.0000 - val_loss: 0.9628 - val_accuracy: 0.5538 - val_top3_acc: 1.0000\n",
      "Epoch 289/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.6134 - accuracy: 0.7449 - top3_acc: 1.0000 - val_loss: 0.9577 - val_accuracy: 0.5658 - val_top3_acc: 1.0000\n",
      "Epoch 290/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.6087 - accuracy: 0.7368 - top3_acc: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n",
      "Epoch 291/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.6263 - accuracy: 0.7280 - top3_acc: 1.0000 - val_loss: 0.9607 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 292/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.6000 - accuracy: 0.7361 - top3_acc: 1.0000 - val_loss: 0.9575 - val_accuracy: 0.5692 - val_top3_acc: 1.0000\n",
      "Epoch 293/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.6159 - accuracy: 0.7236 - top3_acc: 1.0000 - val_loss: 0.9688 - val_accuracy: 0.5641 - val_top3_acc: 1.0000\n",
      "Epoch 294/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.6066 - accuracy: 0.7493 - top3_acc: 1.0000 - val_loss: 0.9687 - val_accuracy: 0.5538 - val_top3_acc: 1.0000\n",
      "Epoch 295/400\n",
      "1364/1364 [==============================] - 1s 655us/step - loss: 0.6114 - accuracy: 0.7383 - top3_acc: 1.0000 - val_loss: 0.9594 - val_accuracy: 0.5761 - val_top3_acc: 1.0000\n",
      "Epoch 296/400\n",
      "1364/1364 [==============================] - 1s 688us/step - loss: 0.6028 - accuracy: 0.7339 - top3_acc: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n",
      "Epoch 297/400\n",
      "1364/1364 [==============================] - 1s 849us/step - loss: 0.6306 - accuracy: 0.7280 - top3_acc: 1.0000 - val_loss: 0.9613 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 298/400\n",
      "1364/1364 [==============================] - 1s 614us/step - loss: 0.6154 - accuracy: 0.7368 - top3_acc: 1.0000 - val_loss: 0.9679 - val_accuracy: 0.5709 - val_top3_acc: 1.0000\n",
      "Epoch 299/400\n",
      "1364/1364 [==============================] - 1s 826us/step - loss: 0.6132 - accuracy: 0.7441 - top3_acc: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n",
      "Epoch 300/400\n",
      "1364/1364 [==============================] - 1s 935us/step - loss: 0.6177 - accuracy: 0.7353 - top3_acc: 1.0000 - val_loss: 0.9724 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/400\n",
      "1364/1364 [==============================] - 1s 949us/step - loss: 0.6153 - accuracy: 0.7265 - top3_acc: 1.0000 - val_loss: 0.9621 - val_accuracy: 0.5521 - val_top3_acc: 1.0000\n",
      "Epoch 302/400\n",
      "1364/1364 [==============================] - 1s 582us/step - loss: 0.6059 - accuracy: 0.7449 - top3_acc: 1.0000 - val_loss: 0.9682 - val_accuracy: 0.5675 - val_top3_acc: 1.0000\n",
      "Epoch 303/400\n",
      "1364/1364 [==============================] - 1s 593us/step - loss: 0.6235 - accuracy: 0.7251 - top3_acc: 1.0000 - val_loss: 0.9678 - val_accuracy: 0.5556 - val_top3_acc: 1.0000\n",
      "Epoch 304/400\n",
      "1364/1364 [==============================] - 1s 582us/step - loss: 0.6149 - accuracy: 0.7243 - top3_acc: 1.0000 - val_loss: 0.9676 - val_accuracy: 0.5692 - val_top3_acc: 1.0000\n",
      "Epoch 305/400\n",
      "1364/1364 [==============================] - 1s 585us/step - loss: 0.6221 - accuracy: 0.7258 - top3_acc: 1.0000 - val_loss: 0.9684 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 306/400\n",
      "1364/1364 [==============================] - 1s 582us/step - loss: 0.6142 - accuracy: 0.7375 - top3_acc: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.5675 - val_top3_acc: 1.0000\n",
      "Epoch 307/400\n",
      "1364/1364 [==============================] - 1s 557us/step - loss: 0.5961 - accuracy: 0.7434 - top3_acc: 1.0000 - val_loss: 0.9737 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 308/400\n",
      "1364/1364 [==============================] - 1s 577us/step - loss: 0.6047 - accuracy: 0.7353 - top3_acc: 1.0000 - val_loss: 0.9667 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n",
      "Epoch 309/400\n",
      "1364/1364 [==============================] - 1s 555us/step - loss: 0.6087 - accuracy: 0.7405 - top3_acc: 1.0000 - val_loss: 0.9657 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 310/400\n",
      "1364/1364 [==============================] - 1s 570us/step - loss: 0.6094 - accuracy: 0.7441 - top3_acc: 1.0000 - val_loss: 0.9793 - val_accuracy: 0.5521 - val_top3_acc: 1.0000\n",
      "Epoch 311/400\n",
      "1364/1364 [==============================] - 1s 592us/step - loss: 0.5999 - accuracy: 0.7471 - top3_acc: 1.0000 - val_loss: 0.9754 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 312/400\n",
      "1364/1364 [==============================] - 1s 558us/step - loss: 0.5888 - accuracy: 0.7471 - top3_acc: 1.0000 - val_loss: 0.9669 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 313/400\n",
      "1364/1364 [==============================] - 1s 576us/step - loss: 0.6041 - accuracy: 0.7478 - top3_acc: 1.0000 - val_loss: 0.9915 - val_accuracy: 0.5761 - val_top3_acc: 1.0000\n",
      "Epoch 314/400\n",
      "1364/1364 [==============================] - 1s 587us/step - loss: 0.5894 - accuracy: 0.7559 - top3_acc: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 315/400\n",
      "1364/1364 [==============================] - 1s 582us/step - loss: 0.5959 - accuracy: 0.7463 - top3_acc: 1.0000 - val_loss: 0.9799 - val_accuracy: 0.5692 - val_top3_acc: 1.0000\n",
      "Epoch 316/400\n",
      "1364/1364 [==============================] - 1s 547us/step - loss: 0.6063 - accuracy: 0.7353 - top3_acc: 1.0000 - val_loss: 0.9709 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 317/400\n",
      "1364/1364 [==============================] - 1s 581us/step - loss: 0.6058 - accuracy: 0.7397 - top3_acc: 1.0000 - val_loss: 0.9787 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 318/400\n",
      "1364/1364 [==============================] - 1s 663us/step - loss: 0.6066 - accuracy: 0.7346 - top3_acc: 1.0000 - val_loss: 0.9729 - val_accuracy: 0.5556 - val_top3_acc: 1.0000\n",
      "Epoch 319/400\n",
      "1364/1364 [==============================] - 1s 665us/step - loss: 0.6257 - accuracy: 0.7368 - top3_acc: 1.0000 - val_loss: 0.9788 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n",
      "Epoch 320/400\n",
      "1364/1364 [==============================] - 1s 741us/step - loss: 0.5977 - accuracy: 0.7471 - top3_acc: 1.0000 - val_loss: 0.9686 - val_accuracy: 0.5692 - val_top3_acc: 1.0000\n",
      "Epoch 321/400\n",
      "1364/1364 [==============================] - 1s 760us/step - loss: 0.6182 - accuracy: 0.7295 - top3_acc: 1.0000 - val_loss: 0.9802 - val_accuracy: 0.5504 - val_top3_acc: 1.0000\n",
      "Epoch 322/400\n",
      "1364/1364 [==============================] - 1s 693us/step - loss: 0.6050 - accuracy: 0.7427 - top3_acc: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.5709 - val_top3_acc: 1.0000\n",
      "Epoch 323/400\n",
      "1364/1364 [==============================] - 1s 641us/step - loss: 0.5916 - accuracy: 0.7405 - top3_acc: 1.0000 - val_loss: 0.9700 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 324/400\n",
      "1364/1364 [==============================] - 1s 711us/step - loss: 0.6084 - accuracy: 0.7566 - top3_acc: 1.0000 - val_loss: 0.9880 - val_accuracy: 0.5641 - val_top3_acc: 1.0000\n",
      "Epoch 325/400\n",
      "1364/1364 [==============================] - 1s 900us/step - loss: 0.5934 - accuracy: 0.7500 - top3_acc: 1.0000 - val_loss: 0.9661 - val_accuracy: 0.5744 - val_top3_acc: 1.0000\n",
      "Epoch 326/400\n",
      "1364/1364 [==============================] - 1s 726us/step - loss: 0.5907 - accuracy: 0.7515 - top3_acc: 1.0000 - val_loss: 0.9750 - val_accuracy: 0.5641 - val_top3_acc: 1.0000\n",
      "Epoch 327/400\n",
      "1364/1364 [==============================] - 1s 899us/step - loss: 0.5950 - accuracy: 0.7566 - top3_acc: 1.0000 - val_loss: 0.9762 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 328/400\n",
      "1364/1364 [==============================] - 1s 672us/step - loss: 0.5855 - accuracy: 0.7478 - top3_acc: 1.0000 - val_loss: 0.9709 - val_accuracy: 0.5675 - val_top3_acc: 1.0000\n",
      "Epoch 329/400\n",
      "1364/1364 [==============================] - 1s 631us/step - loss: 0.6081 - accuracy: 0.7353 - top3_acc: 1.0000 - val_loss: 0.9735 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 330/400\n",
      "1364/1364 [==============================] - 1s 648us/step - loss: 0.5980 - accuracy: 0.7463 - top3_acc: 1.0000 - val_loss: 0.9747 - val_accuracy: 0.5675 - val_top3_acc: 1.0000\n",
      "Epoch 331/400\n",
      "1364/1364 [==============================] - 1s 700us/step - loss: 0.5815 - accuracy: 0.7654 - top3_acc: 1.0000 - val_loss: 0.9671 - val_accuracy: 0.5658 - val_top3_acc: 1.0000\n",
      "Epoch 332/400\n",
      "1364/1364 [==============================] - 1s 610us/step - loss: 0.5732 - accuracy: 0.7603 - top3_acc: 1.0000 - val_loss: 0.9826 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n",
      "Epoch 333/400\n",
      "1364/1364 [==============================] - 1s 643us/step - loss: 0.5864 - accuracy: 0.7544 - top3_acc: 1.0000 - val_loss: 0.9805 - val_accuracy: 0.5641 - val_top3_acc: 1.0000\n",
      "Epoch 334/400\n",
      "1364/1364 [==============================] - 1s 570us/step - loss: 0.5906 - accuracy: 0.7595 - top3_acc: 1.0000 - val_loss: 0.9709 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n",
      "Epoch 335/400\n",
      "1364/1364 [==============================] - 1s 562us/step - loss: 0.5892 - accuracy: 0.7485 - top3_acc: 1.0000 - val_loss: 0.9857 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 336/400\n",
      "1364/1364 [==============================] - 1s 602us/step - loss: 0.5884 - accuracy: 0.7412 - top3_acc: 1.0000 - val_loss: 0.9800 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n",
      "Epoch 337/400\n",
      "1364/1364 [==============================] - 1s 559us/step - loss: 0.5956 - accuracy: 0.7493 - top3_acc: 1.0000 - val_loss: 0.9791 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 338/400\n",
      "1364/1364 [==============================] - 1s 628us/step - loss: 0.5756 - accuracy: 0.7500 - top3_acc: 1.0000 - val_loss: 1.0013 - val_accuracy: 0.5658 - val_top3_acc: 1.0000\n",
      "Epoch 339/400\n",
      "1364/1364 [==============================] - 1s 553us/step - loss: 0.5915 - accuracy: 0.7449 - top3_acc: 1.0000 - val_loss: 0.9766 - val_accuracy: 0.5487 - val_top3_acc: 1.0000\n",
      "Epoch 340/400\n",
      "1364/1364 [==============================] - 1s 637us/step - loss: 0.5898 - accuracy: 0.7434 - top3_acc: 1.0000 - val_loss: 0.9883 - val_accuracy: 0.5641 - val_top3_acc: 1.0000\n",
      "Epoch 341/400\n",
      "1364/1364 [==============================] - 1s 948us/step - loss: 0.5839 - accuracy: 0.7559 - top3_acc: 1.0000 - val_loss: 0.9822 - val_accuracy: 0.5556 - val_top3_acc: 1.0000\n",
      "Epoch 342/400\n",
      "1364/1364 [==============================] - 1s 704us/step - loss: 0.5874 - accuracy: 0.7493 - top3_acc: 1.0000 - val_loss: 0.9815 - val_accuracy: 0.5709 - val_top3_acc: 1.0000\n",
      "Epoch 343/400\n",
      "1364/1364 [==============================] - 1s 802us/step - loss: 0.5723 - accuracy: 0.7507 - top3_acc: 1.0000 - val_loss: 0.9792 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/400\n",
      "1364/1364 [==============================] - 1s 763us/step - loss: 0.5876 - accuracy: 0.7507 - top3_acc: 1.0000 - val_loss: 0.9878 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 345/400\n",
      "1364/1364 [==============================] - 1s 819us/step - loss: 0.5836 - accuracy: 0.7603 - top3_acc: 1.0000 - val_loss: 0.9895 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 346/400\n",
      "1364/1364 [==============================] - 1s 808us/step - loss: 0.5820 - accuracy: 0.7507 - top3_acc: 1.0000 - val_loss: 0.9857 - val_accuracy: 0.5538 - val_top3_acc: 1.0000\n",
      "Epoch 347/400\n",
      "1364/1364 [==============================] - 1s 676us/step - loss: 0.5780 - accuracy: 0.7463 - top3_acc: 1.0000 - val_loss: 0.9859 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 348/400\n",
      "1364/1364 [==============================] - 1s 900us/step - loss: 0.5653 - accuracy: 0.7581 - top3_acc: 1.0000 - val_loss: 0.9802 - val_accuracy: 0.5675 - val_top3_acc: 1.0000\n",
      "Epoch 349/400\n",
      "1364/1364 [==============================] - 1s 664us/step - loss: 0.5722 - accuracy: 0.7500 - top3_acc: 1.0000 - val_loss: 0.9876 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 350/400\n",
      "1364/1364 [==============================] - 1s 538us/step - loss: 0.5722 - accuracy: 0.7544 - top3_acc: 1.0000 - val_loss: 0.9914 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 351/400\n",
      "1364/1364 [==============================] - 1s 576us/step - loss: 0.5816 - accuracy: 0.7478 - top3_acc: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.5538 - val_top3_acc: 1.0000\n",
      "Epoch 352/400\n",
      "1364/1364 [==============================] - 1s 827us/step - loss: 0.5718 - accuracy: 0.7493 - top3_acc: 1.0000 - val_loss: 0.9864 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 353/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.5746 - accuracy: 0.7588 - top3_acc: 1.0000 - val_loss: 1.0076 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 354/400\n",
      "1364/1364 [==============================] - 1s 684us/step - loss: 0.5855 - accuracy: 0.7485 - top3_acc: 1.0000 - val_loss: 0.9822 - val_accuracy: 0.5658 - val_top3_acc: 1.0000\n",
      "Epoch 355/400\n",
      "1364/1364 [==============================] - 1s 504us/step - loss: 0.5759 - accuracy: 0.7529 - top3_acc: 1.0000 - val_loss: 0.9984 - val_accuracy: 0.5521 - val_top3_acc: 1.0000\n",
      "Epoch 356/400\n",
      "1364/1364 [==============================] - 1s 493us/step - loss: 0.5743 - accuracy: 0.7639 - top3_acc: 1.0000 - val_loss: 0.9906 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 357/400\n",
      "1364/1364 [==============================] - 1s 470us/step - loss: 0.5721 - accuracy: 0.7551 - top3_acc: 1.0000 - val_loss: 0.9836 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 358/400\n",
      "1364/1364 [==============================] - 1s 932us/step - loss: 0.5589 - accuracy: 0.7595 - top3_acc: 1.0000 - val_loss: 1.0099 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 359/400\n",
      "1364/1364 [==============================] - 1s 525us/step - loss: 0.5824 - accuracy: 0.7441 - top3_acc: 1.0000 - val_loss: 0.9837 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 360/400\n",
      "1364/1364 [==============================] - 1s 697us/step - loss: 0.5900 - accuracy: 0.7500 - top3_acc: 1.0000 - val_loss: 0.9925 - val_accuracy: 0.5692 - val_top3_acc: 1.0000\n",
      "Epoch 361/400\n",
      "1364/1364 [==============================] - 1s 790us/step - loss: 0.5609 - accuracy: 0.7669 - top3_acc: 1.0000 - val_loss: 0.9967 - val_accuracy: 0.5521 - val_top3_acc: 1.0000\n",
      "Epoch 362/400\n",
      "1364/1364 [==============================] - 1s 579us/step - loss: 0.5798 - accuracy: 0.7581 - top3_acc: 1.0000 - val_loss: 0.9923 - val_accuracy: 0.5641 - val_top3_acc: 1.0000\n",
      "Epoch 363/400\n",
      "1364/1364 [==============================] - 1s 601us/step - loss: 0.5869 - accuracy: 0.7522 - top3_acc: 1.0000 - val_loss: 0.9897 - val_accuracy: 0.5709 - val_top3_acc: 1.0000\n",
      "Epoch 364/400\n",
      "1364/1364 [==============================] - 1s 485us/step - loss: 0.5655 - accuracy: 0.7544 - top3_acc: 1.0000 - val_loss: 0.9916 - val_accuracy: 0.5504 - val_top3_acc: 1.0000\n",
      "Epoch 365/400\n",
      "1364/1364 [==============================] - 1s 573us/step - loss: 0.5736 - accuracy: 0.7500 - top3_acc: 1.0000 - val_loss: 0.9962 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 366/400\n",
      "1364/1364 [==============================] - 1s 888us/step - loss: 0.5902 - accuracy: 0.7441 - top3_acc: 1.0000 - val_loss: 0.9851 - val_accuracy: 0.5607 - val_top3_acc: 1.0000\n",
      "Epoch 367/400\n",
      "1364/1364 [==============================] - 1s 553us/step - loss: 0.5609 - accuracy: 0.7691 - top3_acc: 1.0000 - val_loss: 0.9896 - val_accuracy: 0.5658 - val_top3_acc: 1.0000\n",
      "Epoch 368/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.5777 - accuracy: 0.7471 - top3_acc: 1.0000 - val_loss: 0.9944 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 369/400\n",
      "1364/1364 [==============================] - 1s 768us/step - loss: 0.5743 - accuracy: 0.7581 - top3_acc: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.5538 - val_top3_acc: 1.0000\n",
      "Epoch 370/400\n",
      "1364/1364 [==============================] - 1s 836us/step - loss: 0.5798 - accuracy: 0.7405 - top3_acc: 1.0000 - val_loss: 0.9978 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 371/400\n",
      "1364/1364 [==============================] - 1s 778us/step - loss: 0.5820 - accuracy: 0.7515 - top3_acc: 1.0000 - val_loss: 0.9914 - val_accuracy: 0.5538 - val_top3_acc: 1.0000\n",
      "Epoch 372/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.5664 - accuracy: 0.7735 - top3_acc: 1.0000 - val_loss: 0.9937 - val_accuracy: 0.5521 - val_top3_acc: 1.0000\n",
      "Epoch 373/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.5621 - accuracy: 0.7566 - top3_acc: 1.0000 - val_loss: 0.9944 - val_accuracy: 0.5556 - val_top3_acc: 1.0000\n",
      "Epoch 374/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.5689 - accuracy: 0.7639 - top3_acc: 1.0000 - val_loss: 0.9917 - val_accuracy: 0.5538 - val_top3_acc: 1.0000\n",
      "Epoch 375/400\n",
      "1364/1364 [==============================] - 1s 940us/step - loss: 0.5706 - accuracy: 0.7566 - top3_acc: 1.0000 - val_loss: 0.9941 - val_accuracy: 0.5641 - val_top3_acc: 1.0000\n",
      "Epoch 376/400\n",
      "1364/1364 [==============================] - 1s 655us/step - loss: 0.5803 - accuracy: 0.7515 - top3_acc: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 377/400\n",
      "1364/1364 [==============================] - 1s 571us/step - loss: 0.5636 - accuracy: 0.7691 - top3_acc: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 378/400\n",
      "1364/1364 [==============================] - 1s 571us/step - loss: 0.5508 - accuracy: 0.7669 - top3_acc: 1.0000 - val_loss: 0.9917 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 379/400\n",
      "1364/1364 [==============================] - 1s 524us/step - loss: 0.5645 - accuracy: 0.7551 - top3_acc: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.5521 - val_top3_acc: 1.0000\n",
      "Epoch 380/400\n",
      "1364/1364 [==============================] - 1s 624us/step - loss: 0.5732 - accuracy: 0.7463 - top3_acc: 1.0000 - val_loss: 1.0006 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 381/400\n",
      "1364/1364 [==============================] - 1s 549us/step - loss: 0.5546 - accuracy: 0.7764 - top3_acc: 1.0000 - val_loss: 0.9931 - val_accuracy: 0.5470 - val_top3_acc: 1.0000\n",
      "Epoch 382/400\n",
      "1364/1364 [==============================] - 1s 537us/step - loss: 0.5545 - accuracy: 0.7639 - top3_acc: 1.0000 - val_loss: 1.0013 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 383/400\n",
      "1364/1364 [==============================] - 1s 513us/step - loss: 0.5722 - accuracy: 0.7456 - top3_acc: 1.0000 - val_loss: 1.0010 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 384/400\n",
      "1364/1364 [==============================] - 1s 539us/step - loss: 0.5778 - accuracy: 0.7566 - top3_acc: 1.0000 - val_loss: 0.9932 - val_accuracy: 0.5538 - val_top3_acc: 1.0000\n",
      "Epoch 385/400\n",
      "1364/1364 [==============================] - 1s 699us/step - loss: 0.5582 - accuracy: 0.7647 - top3_acc: 1.0000 - val_loss: 1.0045 - val_accuracy: 0.5538 - val_top3_acc: 1.0000\n",
      "Epoch 386/400\n",
      "1364/1364 [==============================] - 1s 1ms/step - loss: 0.5522 - accuracy: 0.7610 - top3_acc: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.5504 - val_top3_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/400\n",
      "1364/1364 [==============================] - 1s 893us/step - loss: 0.5667 - accuracy: 0.7515 - top3_acc: 1.0000 - val_loss: 1.0009 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 388/400\n",
      "1364/1364 [==============================] - 1s 551us/step - loss: 0.5428 - accuracy: 0.7801 - top3_acc: 1.0000 - val_loss: 1.0058 - val_accuracy: 0.5504 - val_top3_acc: 1.0000\n",
      "Epoch 389/400\n",
      "1364/1364 [==============================] - 1s 539us/step - loss: 0.5822 - accuracy: 0.7537 - top3_acc: 1.0000 - val_loss: 0.9985 - val_accuracy: 0.5556 - val_top3_acc: 1.0000\n",
      "Epoch 390/400\n",
      "1364/1364 [==============================] - 1s 530us/step - loss: 0.5612 - accuracy: 0.7595 - top3_acc: 1.0000 - val_loss: 0.9944 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 391/400\n",
      "1364/1364 [==============================] - 1s 526us/step - loss: 0.5512 - accuracy: 0.7727 - top3_acc: 1.0000 - val_loss: 0.9993 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 392/400\n",
      "1364/1364 [==============================] - 1s 540us/step - loss: 0.5449 - accuracy: 0.7669 - top3_acc: 1.0000 - val_loss: 1.0003 - val_accuracy: 0.5590 - val_top3_acc: 1.0000\n",
      "Epoch 393/400\n",
      "1364/1364 [==============================] - 1s 541us/step - loss: 0.5661 - accuracy: 0.7735 - top3_acc: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 394/400\n",
      "1364/1364 [==============================] - 1s 762us/step - loss: 0.5873 - accuracy: 0.7405 - top3_acc: 1.0000 - val_loss: 0.9990 - val_accuracy: 0.5641 - val_top3_acc: 1.0000\n",
      "Epoch 395/400\n",
      "1364/1364 [==============================] - 2s 1ms/step - loss: 0.5610 - accuracy: 0.7713 - top3_acc: 1.0000 - val_loss: 1.0006 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 396/400\n",
      "1364/1364 [==============================] - 1s 587us/step - loss: 0.5572 - accuracy: 0.7661 - top3_acc: 1.0000 - val_loss: 1.0017 - val_accuracy: 0.5573 - val_top3_acc: 1.0000\n",
      "Epoch 397/400\n",
      "1364/1364 [==============================] - 1s 507us/step - loss: 0.5666 - accuracy: 0.7595 - top3_acc: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.5624 - val_top3_acc: 1.0000\n",
      "Epoch 398/400\n",
      "1364/1364 [==============================] - 1s 735us/step - loss: 0.5717 - accuracy: 0.7529 - top3_acc: 1.0000 - val_loss: 1.0068 - val_accuracy: 0.5556 - val_top3_acc: 1.0000\n",
      "Epoch 399/400\n",
      "1364/1364 [==============================] - 1s 585us/step - loss: 0.5621 - accuracy: 0.7478 - top3_acc: 1.0000 - val_loss: 0.9999 - val_accuracy: 0.5538 - val_top3_acc: 1.0000\n",
      "Epoch 400/400\n",
      "1364/1364 [==============================] - 1s 563us/step - loss: 0.5644 - accuracy: 0.7573 - top3_acc: 1.0000 - val_loss: 0.9988 - val_accuracy: 0.5538 - val_top3_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Define bath and epochs\n",
    "batch_size = 256\n",
    "epochs = 400\n",
    "checkpoint_file = '../models/model_checkpoints/original_window_2.h5'\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.0000001)\n",
    "mcp_save = ModelCheckpoint('../models/model_checkpoints/two_split.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "cnnhistory=model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, y_test), callbacks=[mcp_save, lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6239316463470459\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = cnnhistory.history['val_accuracy']\n",
    "highest_index = cnnhistory.history['val_accuracy'].index(np.sort(cnnhistory.history['val_accuracy'])[-1])\n",
    "print(cnnhistory.history['val_accuracy'][highest_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without prepocessing: 0.5863248109817505\n",
    "# robust preprocessing: 0.6034188270568848\n",
    "# normalization: 0.6239316463470459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model Summary\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# PLT History info\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
