{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network imports\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt('voice-emotion-database.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.          0.          0.          7.244975   -8.158391   -6.804606\n",
      "   -5.95105    16.04601     4.259685    2.918404    3.899431   -8.787468\n",
      "    2.029931   -9.035371   -1.614401   -9.214661    0.          5.\n",
      "    1.          4.       ]\n",
      " [  1.          0.          0.          3.385026    9.644617   -3.468472\n",
      "    6.205656   13.31692     4.477325   -3.002632  -21.12964    -4.892778\n",
      "  -11.55352     6.817298    5.058506  -30.31255     0.          5.\n",
      "    1.          4.       ]\n",
      " [  2.          0.          0.          5.719598    5.727946    6.571836\n",
      "   19.76121    17.95665    12.09366    -0.2149866  -4.745448   -3.547788\n",
      "   -9.468735   -1.699346   -1.552975  -29.19722     0.          5.\n",
      "    1.          1.       ]]\n",
      "(1066, 20)\n"
     ]
    }
   ],
   "source": [
    "# See dataset details\n",
    "print(dataset[:3])\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.244975   -8.158391   -6.804606   -5.95105    16.04601     4.259685\n",
      "    2.918404    3.899431   -8.787468    2.029931   -9.035371   -1.614401 ]\n",
      " [  3.385026    9.644617   -3.468472    6.205656   13.31692     4.477325\n",
      "   -3.002632  -21.12964    -4.892778  -11.55352     6.817298    5.058506 ]\n",
      " [  5.719598    5.727946    6.571836   19.76121    17.95665    12.09366\n",
      "   -0.2149866  -4.745448   -3.547788   -9.468735   -1.699346   -1.552975 ]]\n",
      "(1066, 12)\n",
      "[4. 4. 1.]\n",
      "(1066,)\n"
     ]
    }
   ],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,3:15] # Only the MFCC features\n",
    "y = dataset[:,19] # Emotion label\n",
    "\n",
    "# See X and y details\n",
    "print(X[:3])\n",
    "print(X.shape)\n",
    "\n",
    "print(y[:3])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      "\n",
      "[[[[  7.597784  ]\n",
      "   [ -1.239229  ]\n",
      "   [ -5.716656  ]\n",
      "   [ -0.4919763 ]]\n",
      "\n",
      "  [[  3.44356   ]\n",
      "   [ -8.118807  ]\n",
      "   [-10.71575   ]\n",
      "   [  5.137786  ]]\n",
      "\n",
      "  [[  9.765226  ]\n",
      "   [ -0.897294  ]\n",
      "   [ -4.969833  ]\n",
      "   [  5.458729  ]]]\n",
      "\n",
      "\n",
      " [[[ -8.35018   ]\n",
      "   [ -4.232736  ]\n",
      "   [ -7.289896  ]\n",
      "   [  7.297876  ]]\n",
      "\n",
      "  [[  7.090691  ]\n",
      "   [  4.183091  ]\n",
      "   [ 22.40577   ]\n",
      "   [  1.659072  ]]\n",
      "\n",
      "  [[ -1.148264  ]\n",
      "   [ -1.077869  ]\n",
      "   [  0.5369895 ]\n",
      "   [  3.897543  ]]]\n",
      "\n",
      "\n",
      " [[[ -2.121447  ]\n",
      "   [ -3.403038  ]\n",
      "   [-10.06158   ]\n",
      "   [  0.03766751]]\n",
      "\n",
      "  [[  1.512137  ]\n",
      "   [  9.728447  ]\n",
      "   [  5.861569  ]\n",
      "   [  1.140742  ]]\n",
      "\n",
      "  [[ -3.326549  ]\n",
      "   [  0.2873299 ]\n",
      "   [  3.116914  ]\n",
      "   [ -1.941562  ]]]]\n",
      "(746, 3, 4, 1)\n",
      "\n",
      "X_test:\n",
      "\n",
      "[[[[10.05547  ]\n",
      "   [ 2.840231 ]\n",
      "   [ 2.3077   ]\n",
      "   [ 9.461814 ]]\n",
      "\n",
      "  [[ 6.389001 ]\n",
      "   [-9.577552 ]\n",
      "   [-0.6508675]\n",
      "   [-6.458837 ]]\n",
      "\n",
      "  [[-5.338608 ]\n",
      "   [-8.909947 ]\n",
      "   [ 1.430915 ]\n",
      "   [-0.8559995]]]\n",
      "\n",
      "\n",
      " [[[14.76785  ]\n",
      "   [ 3.077632 ]\n",
      "   [-1.814265 ]\n",
      "   [-5.141767 ]]\n",
      "\n",
      "  [[ 5.943084 ]\n",
      "   [ 1.561537 ]\n",
      "   [10.57407  ]\n",
      "   [-1.903708 ]]\n",
      "\n",
      "  [[ 9.460924 ]\n",
      "   [-2.128923 ]\n",
      "   [ 0.6419849]\n",
      "   [-9.755523 ]]]\n",
      "\n",
      "\n",
      " [[[-1.781799 ]\n",
      "   [-5.894026 ]\n",
      "   [ 1.116361 ]\n",
      "   [ 4.931706 ]]\n",
      "\n",
      "  [[18.62703  ]\n",
      "   [14.55638  ]\n",
      "   [16.05984  ]\n",
      "   [ 9.687832 ]]\n",
      "\n",
      "  [[ 7.934808 ]\n",
      "   [ 6.470327 ]\n",
      "   [ 0.0757184]\n",
      "   [ 3.847457 ]]]]\n",
      "(320, 3, 4, 1)\n",
      "\n",
      "y_train:\n",
      "\n",
      "[2. 5. 6.]\n",
      "(746,)\n",
      "\n",
      "y_test:\n",
      "\n",
      "[5. 4. 0.]\n",
      "(320,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # to split dataset into train and test\n",
    "\n",
    "# Split the dataset in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3)\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 3, 4\n",
    "\n",
    "# Reshape inputs to 3D-matrices for the convolutional layers\n",
    "X_train = X_train.reshape(X_train.shape[0],img_rows,img_cols,1).astype( 'float32' )\n",
    "X_test = X_test.reshape(X_test.shape[0],img_rows,img_cols,1).astype( 'float32' )\n",
    "\n",
    "# See Details\n",
    "print(\"\\nX_train:\\n\")\n",
    "print(X_train[:3])\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_test:\\n\")\n",
    "print(X_test[:3])\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"\\ny_train:\\n\")\n",
    "print(y_train[:3])\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\ny_test:\\n\")\n",
    "print(y_test[:3])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_train:\n",
      "\n",
      "[[0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1]]\n",
      "(746, 7)\n",
      "\n",
      "y_test:\n",
      "\n",
      "[[0 0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0 0]]\n",
      "(320, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Binarize labels\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.fit_transform(y_test)\n",
    "\n",
    "# See Details\n",
    "print(\"\\ny_train:\\n\")\n",
    "print(y_train[:3])\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\ny_test:\\n\")\n",
    "print(y_test[:3])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input_shape\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(30, kernel_size=(2, 2),activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(15, activation= 'relu' ))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bath and epochs\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 746 samples, validate on 320 samples\n",
      "Epoch 1/100\n",
      "746/746 [==============================] - 0s 630us/step - loss: 0.5811 - accuracy: 0.8231 - val_loss: 0.4595 - val_accuracy: 0.8531\n",
      "Epoch 2/100\n",
      "746/746 [==============================] - 0s 54us/step - loss: 0.4709 - accuracy: 0.8474 - val_loss: 0.4210 - val_accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "746/746 [==============================] - 0s 58us/step - loss: 0.4274 - accuracy: 0.8560 - val_loss: 0.4116 - val_accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "746/746 [==============================] - 0s 57us/step - loss: 0.4182 - accuracy: 0.8564 - val_loss: 0.4092 - val_accuracy: 0.8571\n",
      "Epoch 5/100\n",
      "746/746 [==============================] - 0s 63us/step - loss: 0.4131 - accuracy: 0.8571 - val_loss: 0.4087 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "746/746 [==============================] - 0s 67us/step - loss: 0.4098 - accuracy: 0.8571 - val_loss: 0.4085 - val_accuracy: 0.8571\n",
      "Epoch 7/100\n",
      "746/746 [==============================] - 0s 62us/step - loss: 0.4099 - accuracy: 0.8571 - val_loss: 0.4084 - val_accuracy: 0.8571\n",
      "Epoch 8/100\n",
      "746/746 [==============================] - 0s 55us/step - loss: 0.4078 - accuracy: 0.8571 - val_loss: 0.4083 - val_accuracy: 0.8571\n",
      "Epoch 9/100\n",
      "746/746 [==============================] - 0s 64us/step - loss: 0.4078 - accuracy: 0.8571 - val_loss: 0.4082 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "746/746 [==============================] - 0s 63us/step - loss: 0.4091 - accuracy: 0.8570 - val_loss: 0.4081 - val_accuracy: 0.8571\n",
      "Epoch 11/100\n",
      "746/746 [==============================] - 0s 64us/step - loss: 0.4083 - accuracy: 0.8571 - val_loss: 0.4082 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "746/746 [==============================] - 0s 63us/step - loss: 0.4055 - accuracy: 0.8571 - val_loss: 0.4079 - val_accuracy: 0.8571\n",
      "Epoch 13/100\n",
      "746/746 [==============================] - 0s 66us/step - loss: 0.4069 - accuracy: 0.8571 - val_loss: 0.4078 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "746/746 [==============================] - 0s 66us/step - loss: 0.4047 - accuracy: 0.8571 - val_loss: 0.4078 - val_accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "746/746 [==============================] - 0s 85us/step - loss: 0.4031 - accuracy: 0.8571 - val_loss: 0.4077 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "746/746 [==============================] - 0s 77us/step - loss: 0.4030 - accuracy: 0.8573 - val_loss: 0.4080 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "746/746 [==============================] - 0s 74us/step - loss: 0.4042 - accuracy: 0.8571 - val_loss: 0.4081 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "746/746 [==============================] - 0s 62us/step - loss: 0.4031 - accuracy: 0.8571 - val_loss: 0.4078 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "746/746 [==============================] - 0s 57us/step - loss: 0.4032 - accuracy: 0.8571 - val_loss: 0.4077 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "746/746 [==============================] - 0s 51us/step - loss: 0.4034 - accuracy: 0.8573 - val_loss: 0.4078 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "746/746 [==============================] - 0s 64us/step - loss: 0.4032 - accuracy: 0.8571 - val_loss: 0.4077 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "746/746 [==============================] - 0s 62us/step - loss: 0.4018 - accuracy: 0.8573 - val_loss: 0.4079 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "746/746 [==============================] - 0s 66us/step - loss: 0.4004 - accuracy: 0.8573 - val_loss: 0.4081 - val_accuracy: 0.8571\n",
      "Epoch 24/100\n",
      "746/746 [==============================] - 0s 62us/step - loss: 0.3995 - accuracy: 0.8575 - val_loss: 0.4081 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "746/746 [==============================] - 0s 74us/step - loss: 0.3974 - accuracy: 0.8571 - val_loss: 0.4090 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 0.4000 - accuracy: 0.8570 - val_loss: 0.4093 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "746/746 [==============================] - 0s 86us/step - loss: 0.3969 - accuracy: 0.8577 - val_loss: 0.4096 - val_accuracy: 0.8567\n",
      "Epoch 28/100\n",
      "746/746 [==============================] - 0s 87us/step - loss: 0.3965 - accuracy: 0.8577 - val_loss: 0.4095 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "746/746 [==============================] - 0s 61us/step - loss: 0.3957 - accuracy: 0.8570 - val_loss: 0.4096 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "746/746 [==============================] - 0s 62us/step - loss: 0.3950 - accuracy: 0.8581 - val_loss: 0.4097 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "746/746 [==============================] - 0s 65us/step - loss: 0.3948 - accuracy: 0.8573 - val_loss: 0.4095 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "746/746 [==============================] - 0s 66us/step - loss: 0.3928 - accuracy: 0.8577 - val_loss: 0.4091 - val_accuracy: 0.8571\n",
      "Epoch 33/100\n",
      "746/746 [==============================] - 0s 83us/step - loss: 0.3950 - accuracy: 0.8571 - val_loss: 0.4092 - val_accuracy: 0.8567\n",
      "Epoch 34/100\n",
      "746/746 [==============================] - 0s 67us/step - loss: 0.3908 - accuracy: 0.8579 - val_loss: 0.4100 - val_accuracy: 0.8567\n",
      "Epoch 35/100\n",
      "746/746 [==============================] - 0s 69us/step - loss: 0.3930 - accuracy: 0.8577 - val_loss: 0.4104 - val_accuracy: 0.8562\n",
      "Epoch 36/100\n",
      "746/746 [==============================] - 0s 61us/step - loss: 0.3889 - accuracy: 0.8577 - val_loss: 0.4104 - val_accuracy: 0.8567\n",
      "Epoch 37/100\n",
      "746/746 [==============================] - 0s 57us/step - loss: 0.3922 - accuracy: 0.8568 - val_loss: 0.4095 - val_accuracy: 0.8567\n",
      "Epoch 38/100\n",
      "746/746 [==============================] - 0s 60us/step - loss: 0.3890 - accuracy: 0.8581 - val_loss: 0.4098 - val_accuracy: 0.8567\n",
      "Epoch 39/100\n",
      "746/746 [==============================] - 0s 59us/step - loss: 0.3891 - accuracy: 0.8579 - val_loss: 0.4107 - val_accuracy: 0.8567\n",
      "Epoch 40/100\n",
      "746/746 [==============================] - 0s 56us/step - loss: 0.3869 - accuracy: 0.8581 - val_loss: 0.4117 - val_accuracy: 0.8562\n",
      "Epoch 41/100\n",
      "746/746 [==============================] - 0s 54us/step - loss: 0.3891 - accuracy: 0.8581 - val_loss: 0.4117 - val_accuracy: 0.8562\n",
      "Epoch 42/100\n",
      "746/746 [==============================] - 0s 61us/step - loss: 0.3863 - accuracy: 0.8581 - val_loss: 0.4114 - val_accuracy: 0.8562\n",
      "Epoch 43/100\n",
      "746/746 [==============================] - 0s 49us/step - loss: 0.3879 - accuracy: 0.8575 - val_loss: 0.4120 - val_accuracy: 0.8558\n",
      "Epoch 44/100\n",
      "746/746 [==============================] - 0s 63us/step - loss: 0.3885 - accuracy: 0.8575 - val_loss: 0.4119 - val_accuracy: 0.8554\n",
      "Epoch 45/100\n",
      "746/746 [==============================] - 0s 44us/step - loss: 0.3858 - accuracy: 0.8589 - val_loss: 0.4117 - val_accuracy: 0.8554\n",
      "Epoch 46/100\n",
      "746/746 [==============================] - 0s 56us/step - loss: 0.3861 - accuracy: 0.8579 - val_loss: 0.4130 - val_accuracy: 0.8554\n",
      "Epoch 47/100\n",
      "746/746 [==============================] - 0s 41us/step - loss: 0.3841 - accuracy: 0.8592 - val_loss: 0.4138 - val_accuracy: 0.8558\n",
      "Epoch 48/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 0.3856 - accuracy: 0.8583 - val_loss: 0.4138 - val_accuracy: 0.8558\n",
      "Epoch 49/100\n",
      "746/746 [==============================] - 0s 67us/step - loss: 0.3820 - accuracy: 0.8581 - val_loss: 0.4136 - val_accuracy: 0.8554\n",
      "Epoch 50/100\n",
      "746/746 [==============================] - 0s 66us/step - loss: 0.3834 - accuracy: 0.8575 - val_loss: 0.4141 - val_accuracy: 0.8554\n",
      "Epoch 51/100\n",
      "746/746 [==============================] - 0s 73us/step - loss: 0.3844 - accuracy: 0.8583 - val_loss: 0.4135 - val_accuracy: 0.8554\n",
      "Epoch 52/100\n",
      "746/746 [==============================] - 0s 67us/step - loss: 0.3800 - accuracy: 0.8591 - val_loss: 0.4139 - val_accuracy: 0.8549\n",
      "Epoch 53/100\n",
      "746/746 [==============================] - 0s 65us/step - loss: 0.3841 - accuracy: 0.8581 - val_loss: 0.4146 - val_accuracy: 0.8545\n",
      "Epoch 54/100\n",
      "746/746 [==============================] - 0s 64us/step - loss: 0.3804 - accuracy: 0.8600 - val_loss: 0.4144 - val_accuracy: 0.8549\n",
      "Epoch 55/100\n",
      "746/746 [==============================] - 0s 68us/step - loss: 0.3851 - accuracy: 0.8587 - val_loss: 0.4144 - val_accuracy: 0.8549\n",
      "Epoch 56/100\n",
      "746/746 [==============================] - 0s 51us/step - loss: 0.3832 - accuracy: 0.8587 - val_loss: 0.4138 - val_accuracy: 0.8545\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 0s 69us/step - loss: 0.3841 - accuracy: 0.8600 - val_loss: 0.4139 - val_accuracy: 0.8540\n",
      "Epoch 58/100\n",
      "746/746 [==============================] - 0s 67us/step - loss: 0.3787 - accuracy: 0.8596 - val_loss: 0.4139 - val_accuracy: 0.8545\n",
      "Epoch 59/100\n",
      "746/746 [==============================] - 0s 95us/step - loss: 0.3750 - accuracy: 0.8596 - val_loss: 0.4142 - val_accuracy: 0.8554\n",
      "Epoch 60/100\n",
      "746/746 [==============================] - 0s 109us/step - loss: 0.3841 - accuracy: 0.8589 - val_loss: 0.4145 - val_accuracy: 0.8554\n",
      "Epoch 61/100\n",
      "746/746 [==============================] - 0s 95us/step - loss: 0.3818 - accuracy: 0.8571 - val_loss: 0.4139 - val_accuracy: 0.8554\n",
      "Epoch 62/100\n",
      "746/746 [==============================] - 0s 70us/step - loss: 0.3806 - accuracy: 0.8594 - val_loss: 0.4135 - val_accuracy: 0.8554\n",
      "Epoch 63/100\n",
      "746/746 [==============================] - 0s 50us/step - loss: 0.3798 - accuracy: 0.8583 - val_loss: 0.4143 - val_accuracy: 0.8545\n",
      "Epoch 64/100\n",
      "746/746 [==============================] - 0s 61us/step - loss: 0.3811 - accuracy: 0.8592 - val_loss: 0.4143 - val_accuracy: 0.8540\n",
      "Epoch 65/100\n",
      "746/746 [==============================] - 0s 66us/step - loss: 0.3763 - accuracy: 0.8606 - val_loss: 0.4142 - val_accuracy: 0.8545\n",
      "Epoch 66/100\n",
      "746/746 [==============================] - 0s 60us/step - loss: 0.3745 - accuracy: 0.8612 - val_loss: 0.4146 - val_accuracy: 0.8536\n",
      "Epoch 67/100\n",
      "746/746 [==============================] - 0s 50us/step - loss: 0.3758 - accuracy: 0.8606 - val_loss: 0.4142 - val_accuracy: 0.8545\n",
      "Epoch 68/100\n",
      "746/746 [==============================] - 0s 45us/step - loss: 0.3758 - accuracy: 0.8596 - val_loss: 0.4137 - val_accuracy: 0.8545\n",
      "Epoch 69/100\n",
      "746/746 [==============================] - 0s 55us/step - loss: 0.3736 - accuracy: 0.8602 - val_loss: 0.4135 - val_accuracy: 0.8545\n",
      "Epoch 70/100\n",
      "746/746 [==============================] - 0s 88us/step - loss: 0.3760 - accuracy: 0.8600 - val_loss: 0.4137 - val_accuracy: 0.8545\n",
      "Epoch 71/100\n",
      "746/746 [==============================] - 0s 75us/step - loss: 0.3771 - accuracy: 0.8592 - val_loss: 0.4148 - val_accuracy: 0.8545\n",
      "Epoch 72/100\n",
      "746/746 [==============================] - 0s 72us/step - loss: 0.3744 - accuracy: 0.8585 - val_loss: 0.4152 - val_accuracy: 0.8549\n",
      "Epoch 73/100\n",
      "746/746 [==============================] - 0s 63us/step - loss: 0.3754 - accuracy: 0.8602 - val_loss: 0.4159 - val_accuracy: 0.8536\n",
      "Epoch 74/100\n",
      "746/746 [==============================] - 0s 49us/step - loss: 0.3754 - accuracy: 0.8608 - val_loss: 0.4166 - val_accuracy: 0.8536\n",
      "Epoch 75/100\n",
      "746/746 [==============================] - 0s 42us/step - loss: 0.3737 - accuracy: 0.8608 - val_loss: 0.4176 - val_accuracy: 0.8540\n",
      "Epoch 76/100\n",
      "746/746 [==============================] - 0s 65us/step - loss: 0.3744 - accuracy: 0.8602 - val_loss: 0.4163 - val_accuracy: 0.8536\n",
      "Epoch 77/100\n",
      "746/746 [==============================] - 0s 43us/step - loss: 0.3739 - accuracy: 0.8612 - val_loss: 0.4166 - val_accuracy: 0.8536\n",
      "Epoch 78/100\n",
      "746/746 [==============================] - 0s 66us/step - loss: 0.3748 - accuracy: 0.8589 - val_loss: 0.4168 - val_accuracy: 0.8545\n",
      "Epoch 79/100\n",
      "746/746 [==============================] - 0s 64us/step - loss: 0.3733 - accuracy: 0.8612 - val_loss: 0.4167 - val_accuracy: 0.8545\n",
      "Epoch 80/100\n",
      "746/746 [==============================] - 0s 86us/step - loss: 0.3748 - accuracy: 0.8594 - val_loss: 0.4164 - val_accuracy: 0.8540\n",
      "Epoch 81/100\n",
      "746/746 [==============================] - 0s 95us/step - loss: 0.3693 - accuracy: 0.8602 - val_loss: 0.4155 - val_accuracy: 0.8540\n",
      "Epoch 82/100\n",
      "746/746 [==============================] - 0s 72us/step - loss: 0.3737 - accuracy: 0.8608 - val_loss: 0.4170 - val_accuracy: 0.8531\n",
      "Epoch 83/100\n",
      "746/746 [==============================] - 0s 57us/step - loss: 0.3712 - accuracy: 0.8608 - val_loss: 0.4190 - val_accuracy: 0.8545\n",
      "Epoch 84/100\n",
      "746/746 [==============================] - 0s 56us/step - loss: 0.3692 - accuracy: 0.8606 - val_loss: 0.4176 - val_accuracy: 0.8545\n",
      "Epoch 85/100\n",
      "746/746 [==============================] - 0s 54us/step - loss: 0.3696 - accuracy: 0.8623 - val_loss: 0.4169 - val_accuracy: 0.8554\n",
      "Epoch 86/100\n",
      "746/746 [==============================] - 0s 67us/step - loss: 0.3707 - accuracy: 0.8604 - val_loss: 0.4171 - val_accuracy: 0.8549\n",
      "Epoch 87/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 0.3695 - accuracy: 0.8617 - val_loss: 0.4178 - val_accuracy: 0.8554\n",
      "Epoch 88/100\n",
      "746/746 [==============================] - 0s 67us/step - loss: 0.3694 - accuracy: 0.8604 - val_loss: 0.4168 - val_accuracy: 0.8545\n",
      "Epoch 89/100\n",
      "746/746 [==============================] - 0s 62us/step - loss: 0.3716 - accuracy: 0.8612 - val_loss: 0.4179 - val_accuracy: 0.8545\n",
      "Epoch 90/100\n",
      "746/746 [==============================] - 0s 72us/step - loss: 0.3707 - accuracy: 0.8604 - val_loss: 0.4175 - val_accuracy: 0.8549\n",
      "Epoch 91/100\n",
      "746/746 [==============================] - 0s 66us/step - loss: 0.3681 - accuracy: 0.8612 - val_loss: 0.4159 - val_accuracy: 0.8549\n",
      "Epoch 92/100\n",
      "746/746 [==============================] - 0s 71us/step - loss: 0.3687 - accuracy: 0.8612 - val_loss: 0.4167 - val_accuracy: 0.8549\n",
      "Epoch 93/100\n",
      "746/746 [==============================] - 0s 94us/step - loss: 0.3611 - accuracy: 0.8627 - val_loss: 0.4178 - val_accuracy: 0.8545\n",
      "Epoch 94/100\n",
      "746/746 [==============================] - 0s 103us/step - loss: 0.3658 - accuracy: 0.8627 - val_loss: 0.4173 - val_accuracy: 0.8545\n",
      "Epoch 95/100\n",
      "746/746 [==============================] - 0s 115us/step - loss: 0.3735 - accuracy: 0.8604 - val_loss: 0.4172 - val_accuracy: 0.8549\n",
      "Epoch 96/100\n",
      "746/746 [==============================] - 0s 56us/step - loss: 0.3652 - accuracy: 0.8623 - val_loss: 0.4189 - val_accuracy: 0.8549\n",
      "Epoch 97/100\n",
      "746/746 [==============================] - 0s 78us/step - loss: 0.3691 - accuracy: 0.8631 - val_loss: 0.4199 - val_accuracy: 0.8545\n",
      "Epoch 98/100\n",
      "746/746 [==============================] - 0s 71us/step - loss: 0.3660 - accuracy: 0.8629 - val_loss: 0.4202 - val_accuracy: 0.8549\n",
      "Epoch 99/100\n",
      "746/746 [==============================] - 0s 90us/step - loss: 0.3726 - accuracy: 0.8608 - val_loss: 0.4175 - val_accuracy: 0.8554\n",
      "Epoch 100/100\n",
      "746/746 [==============================] - 0s 85us/step - loss: 0.3662 - accuracy: 0.8612 - val_loss: 0.4148 - val_accuracy: 0.8558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f1e346a5e10>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 65us/step\n",
      "Test loss: 0.4148042440414429\n",
      "Test accuracy: 0.8558036088943481\n"
     ]
    }
   ],
   "source": [
    "# Score Model\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 2, 3, 30)          150       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 3, 30)          0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2, 3, 30)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 15)                2715      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 7)                 112       \n",
      "=================================================================\n",
      "Total params: 2,977\n",
      "Trainable params: 2,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Summary\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
